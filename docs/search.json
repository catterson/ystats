[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Why Statistics?",
    "section": "",
    "text": "Hello (An Introduction)!",
    "crumbs": [
      "List of R Code",
      "Hello (An Introduction)!"
    ]
  },
  {
    "objectID": "index.html#hey-its-a-check-in",
    "href": "index.html#hey-its-a-check-in",
    "title": "Why Statistics?",
    "section": "Hey, it‚Äôs a check-in!",
    "text": "Hey, it‚Äôs a check-in!\nLoading‚Ä¶",
    "crumbs": [
      "Home",
      "Welcome"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html",
    "href": "chapters/1R_WhyStats.html",
    "title": "Why Statistics?",
    "section": "",
    "text": "Part 1 : Why Statistics in Psychology?\nIn this week‚Äôs reading, you‚Äôll learn why students like you are required to learn the statistics, programming language, and research methods required of modern psychology.\nAs y‚Äôall know, this class is a requirement for students who want to be psychology majors. This is exciting for me (your professor), and probably some students too. However, over the years I have learned this can be frustrating and stressful for students who wonder why-the-f*%@ they are required to take a math class when all they just want to learn about people (or other non-human animals), ya know!??!\nI agree that people (or non-human animals) are interesting. And we all have this interest in people (or non-human animals) because we are complex1. While people are similar in many ways, we also differ in radical ways; from superficial features like age and race, to more complex ways like our personality or emotions, to highly specific behaviors such as whether all students in the class are reading these words or not, or how bored or excited (or any emotional experience) students are while reading these words.\nI hope that you have an interest in people (or non-human animals), and that this class helps you learn how to think about those interests through a psychological, and statistical lens. You don‚Äôt always need this lens - and as we will discuss there can sometimes be dangers in viewing people through this lens - but it‚Äôs useful to be able to wear these ‚Äúglasses‚Äù when needed.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#to-do-list",
    "href": "chapters/1R_WhyStats.html#to-do-list",
    "title": "Why Statistics?",
    "section": "",
    "text": "Read this document and watch the four (4) videos.\nTake the on-boarding survey and save the code you get at the end for the quiz.\nSubmit the code to the quiz on bCourses.",
    "crumbs": [
      "Home",
      "Why?",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#why-statistics-in-psychology",
    "href": "chapters/1R_WhyStats.html#why-statistics-in-psychology",
    "title": "Why Statistics?",
    "section": "Why Statistics in Psychology?",
    "text": "Why Statistics in Psychology?\nAs y‚Äôall know, this class is a requirement for students who want to be psychology majors. This is exciting for me (your professor), and probably some students too. However, over the years I have learned this can be frustrating and stressful for students who wonder why-the-flip they are required to take a math class when all they just want to learn about people (or other non-human animals), ya know!??!\nI agree that people (or non-human animals) are interesting. And we all have this interest in people (or non-human animals) because we are complex1. While people are similar in many ways, we also differ in radical ways; from superficial features like age and race, to more complex ways like our personality or emotions, to highly specific behaviors such as whether all students in the class are reading these words or not, or how bored or excited (or any emotional experience) students are while reading these words.\nI hope that you have an interest in people (or non-human animals), and that this class helps you learn how to think about those interests through a psychological, and statistical lens. You don‚Äôt always need this lens - and as we will discuss there can sometimes be dangers in viewing people through this lens - but it‚Äôs useful to be able to wear these ‚Äúglasses‚Äù when needed.\n\nStatistics as a Language\nStatistics is a language that scientists use to describe this complexity. While psychology uses this language to better understand differences in people (or non-human animals), other scientific disciplines focus on their own domains; physicists seek to understand differences (and similarities) in matter and energy, chemists seek to understand differences (and similarities) in elements and compounds, botanists seek to understand differences in plants, and economists seek to understand money.\n\nVariables and Variation\nVariation is at the heart of statistics, and is defined by differences, change, and complexity.\n\n\n\n\n\n\n\nBetween-Person Variation describes how individuals differ from each other. Think about ways that you differ from others; not everybody wears glasses, has the same level of silliness / seriousness / desire to cause mischief / fascination with horses.\n\n\n\nWithin-Person Variation describes how one individual changes over time or across different situations. Think about the person you are today - are you exactly the same as you were yesterday? A year ago? You‚Äôve changed (varied) in ways both small (hunger, exhaustion, number of words you‚Äôve read for this class) and large (personality, love interests, identity, etc.)\n\n\n\nNo variation would describe a situation in which everyone is exactly the same. I can‚Äôt think of too many situations where there is no variation; let me know on Discord if you can think of one? And while there‚Äôs no theoretical limit to the amount of variation that there can be, one major task of this class will be to learn to quantify the amount of variation that we observe in our role as psychologists.\n\nüåûüåûüåû\nüåûüåûüåû\n\n\n\n\nA Variable is a label for some psychological phenomenon that has variation. I‚Äôm not sure where I first heard this, but psychologists often focus on what they call the ‚ÄúABCs‚Äù.¬†\n\nA is for Affect = the emotions that you feel.\nB is for Behavior = the actions that you do.\nC is for cognition = the thoughts you have.\n\nThese are not rigid categories, and psychologists often debate the definitions of these terms. But they can be useful ways to think about how to think about people, and help break down a complex phenomenon into more specific components.\n\n\nPractice : Variables and Variation\nFor example, think about how affect, behavior, and cognition might be relevant if I ask you to think about an upcoming exam (your first exam is in just a few weeks!)¬†\n\n\n\n\n\n\n\n\nhighlight the cells below to see my ideas / check your understanding\n\n\nAffect Example\nthe feeling of anxiety or dread you have thinking about being assessed, or maybe a feeling of excitement about the opportunity to demonstrate your hard work / effort / knowledge!\n\n\nBehavior Example\nimmediately checking your calendar to see when exams are; or maybe avoiding your classes with a nice procrastination session on the ol‚Äô infinite scroll machine.\n\n\nCognition Example\nthinking about all the work you have to do; wondering why the professor would choose this example when he could have thought about the ways that affect, behavior, and cognition would be triggered when you see a puppy or kitten or something like that‚Ä¶\n\n\n\n(Here‚Äôs a cat video I like for students needing a distraction from thinking about exams. I promise your exams in this class will be chill and I‚Äôll do my best to prepare y‚Äôall.)\n\n\nLanguage is More than Vocabulary\nStatistics is a language that scientists use to describe this complexity. While psychology uses this language to better understand variation in people (or non-human animals), other scientific disciplines focus on their own domains; physicists seek to understand differences (and similarities) in matter and energy, chemists seek to understand differences (and similarities) in elements and compounds, botanists seek to understand differences in plants, and economists seek to understand money.\n\nVocabulary. Equations like ‚Äúthe mean‚Äù or ‚Äústandard deviation‚Äù or ‚Äúcronbach‚Äôs alpha‚Äù or ‚Äúp-value‚Äù are precise vocabulary terms that define some feature of variation. Some of these vocabulary words are easier to understand and remember than others, and like all languages, sometimes people disagree on the definition, and sometimes misuse these words.\nGrammar and Syntax. The way we organize words also matters when learning languages. Saying ‚Äúthe professor graded the students‚Äú has a very different meaning than ‚Äúthe students graded the professor‚Äù, even though these share the exact same words. Statistics (and research methods) also requires precision in the way we organize the ideas, terms, and processes. We‚Äôll learn more about this as we discuss the scientific method (a highly structured and organized approach to doing research), but also as we learn how to navigate doing data analysis.\nCultural Immersion. A good language class will also help students to understand the ways that the language is connected to people, places, and history2. In this class, we‚Äôll think about the ways we can immerse ourselves in the culture of statistics and research methods, from the cultural practices that inform which methods or tools to use, to the ways that the culture of statistics and research might needlessly create barriers for certain types of people or studies.\nPractice and Past Experiences. And yes, in order to gain fluency in a language, you need to practice! Attendance and regular engagement with this class will ensure that you are able to get the practice that you need. It‚Äôs also good to note that people differ in terms of their past experiences with computers and math, and are bringing those experiences (for better or worse) with them into this class.\n\n\n\n\nCulture in Statistics : Me-Search\n\n\n\n\n\n\n\n\nHiya folks! Everyone‚Äôs favorite Open-Source Mickey Mouse here. I‚Äôll be popping up in the book from time to time to critically engage with the idea that statistics has a culture that is socially constructed by people like you!\n\n\n\nAll psychologists are interested in questions sparked by their own observations or experiences. This is sometimes called ‚Äúme-search‚Äù - the idea that a person‚Äôs research interests reflect their own experience.\nMe-search can be an important way for researchers to use their statistics and research methods training to address questions and issues that are relevant to their lives and communities.\nBelow are a few examples of research questions that are related to a person‚Äôs real-life experiences.\n\n\n\nReal Life Experience\nResearch Question\n\n\nA researcher develops vision problems due to his studies of light, and had to live in a completely darkened room, where he became completely isolated from most of reality.3\nDoes reality exist, or can it only be known through our perceptions?\n\n\nA black graduate student at the University of Chicago realizes that white people cross the street to avoid him, and finds himself whistling classical music to signal that he does not fit their negative stereotypes of a black male.4\nHow do people respond and react to others‚Äô negative stereotypes?\n\n\n\nHowever, me-search also serves as a form of potential bias in research - not only will a researcher‚Äôs own biases and beliefs influence the way they conduct research, but the types of questions that are asked will be influenced by the types of people doing research.\nFor example, a survey of over 26,000 research articles in psychology documented just how rarely the topic of race is studied in psychology (see figure below).\n\n\n\n\n\nAs we‚Äôll discuss throughout this class, life is complex and there is never one explanation for any phenomenon. However, it‚Äôs important to note that psychology as a field has historically been dominated by white authors (researchers who write scientific papers) and white editors (researchers who decide what papers get published or not).\n\n\n\n\n\nThese trends are important to reflect on, because they reveal a bias in who becomes a psychologist, and what types of questions these researchers are interested in pursuing.\nIt‚Äôs also a goal of this class to not only highlight the important contributions of non-white researchers and statisticians, but also make sure that all students in this diverse classroom feels empowered to use statistics, research methods, and R skills to ask (and answer) research questions that matter to them!5",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#why-r",
    "href": "chapters/1R_WhyStats.html#why-r",
    "title": "Why Statistics?",
    "section": "Why R?",
    "text": "Why R?\nThis semester, we will also learn how to use the computer programming language R to work with data, conduct analyses, and make graphs. R can be intimidating to work with at first, and is more confusing than it needs to be sometimes (as you‚Äôll quickly find out haha), but I promise you will learn! In fact, that‚Äôs the point of this class. It‚Äôs totally okay (and expected) for you to feel frustrated at times; this is part of the learning process. So please embrace the ‚ÄúI HAVE NO IDEA WHAT I‚ÄôM DOING‚Äù dog meme energy (and look how happy the doggy looks!) as you embark on your R journey.\n\n\n\n\n\n\n\n\n\n\nInstalling R\nUse this link to Download and Install the Programs R and RStudio Desktop\nNote : You must download both R and RStudio Desktop (these are two separate programs). Make sure to download the most recent version of R and RStudio to avoid issues in the future.\n\nR is the powerful, free, and somewhat intimidating computer program that we will use to analyze data in this class. This website is not super friendly - choose the operating system you have (Windows, MacOS, or Linux) and then download the ‚Äúlatest release‚Äù on the next page. If you have a chromebook or iPad / tablet, you will need to use posit.cloud.\nRStudio is an Integrated Development Environment (IDE) - basically a ‚Äúhome‚Äù for R to live in, with rooms and this program is not 100% necessary, but makes it a little easier to navigate R. Note that you will need to install R first in order for RStudio to work.\n\nHaving trouble getting these programs to work?\n\nHere‚Äôs one YouTube video someone made to show you how to download and install.\nTry posit.cloud. This is a web-based version of RStudio, and has a free option but limits you to 15-hours of work a month. There‚Äôs a paid option for $5/month that you can use; former students pointed out that you can always create a new ‚Äúfree‚Äù account if you run over the 15-hour limit.\nPost on our class Discord / go to section / office hours! The professor, other students, or your TA can help get everything working properly.\n\n\n\nNavigating R\nWatch the two videos below for a quick introduction to R - the program we will be using to analyze data.\n\nVIDEO : Navigating R\n\n\nwhat R looks like when you open it\nbasic math in the¬†console\nindexing and output\n\n\n\nVIDEO : Navigating RStudio\n\n\nwhat RStudio/Posit looks like; navigating the program\nbasic math in the console\nthe¬†source file¬†(makes life easier and saves your work!)",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#why-research-methods",
    "href": "chapters/1R_WhyStats.html#why-research-methods",
    "title": "Why Statistics?",
    "section": "Why Research Methods?",
    "text": "Why Research Methods?\n\nPsychology as a SCIENCE TM of People (and Non-Human Animals)\nPsychology desperately wants to establish itself as a REAL SCIENCE ‚Ñ¢. You don‚Äôt have to take my word for it, just look at the definitions of some common sources of psychological knowledge - introductory textbooks :¬†¬†\n\n‚ÄúToday, we define psychology as the science of behavior and mental processes.‚Äù (Myers, 2011)\n‚Äú‚Ä¶the science of behavior and the mind.‚Äù (Grey, 2010)\n‚Äú‚Ä¶the scientific study of mind, brain, and behavior.‚Äù (Gazzaniga, 2010)\n‚Äú‚Ä¶We now define psychologyas the science of behavior and mental processes.‚Äù (Myers & DeWall, 2018)\n\nI‚Äôm probably showing my age looking to textbooks, so let‚Äôs check in with ChatGPT to see whether the algorithmic summary of large piles of data suggests that psychology is, in fact, a ‚Äúreal science‚Äù :¬†\n\n\nPerhaps more authoritatively, the American Psychological Association (APA) confirms that psychology is, ‚Äúthe study of the mind and behavior‚Ä¶a diverse scientific discipline comprising several major branches of research.‚Äù (APA, 2024).¬†\nThe consistent emphasis on science (and ‚Äúrigorous‚Äù methods!) in these definitions is an attempt to elevate psychology to the status of other ‚Äúhard‚Äù sciences, like physics and chemistry. But inclusion of the term ‚Äúscience‚Äù also seeks to differentiate psychology from its less scientific heritage and past, defend itself from accusations from other scientists / talking heads (if not some of your friends in STEM majors‚Ä¶or parents) that it is not actually REAL SCIENCE ‚Ñ¢.¬†\n\n\nScientific Prediction (and Error)\nAnd so, here we are. In this document, in this required class, learning how to DO REAL SCIENCE. With statistics. Oh yeah, and we‚Äôll also be learning to use this computer programming language called R¬† üòà",
    "crumbs": [
      "Lab Assignments",
      "Why?",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#footnotes",
    "href": "chapters/1R_WhyStats.html#footnotes",
    "title": "Chapter 1 | Why?",
    "section": "",
    "text": "And usually food, though I‚Äôm not sure if there‚Äôs cultural food norms about statistics or research methods.‚Ü©Ô∏é\nThis happened to Gustav Fechner, one of the early psychologists who pioneered the study of psychophysics, which tested theories that our perceptions do not always match reality (seen in many examples, such as the dress). FWIW I see it as blue and black.‚Ü©Ô∏é\nThis anecdote (as reported here) inspired Claude Steele‚Äôs research on stereotype threat.‚Ü©Ô∏é\nThis is the purpose of your final project! We‚Äôll talk more about this throughout the class.‚Ü©Ô∏é\nSee the syllabus for the course ChatGPT policy. You may also be interested to read on the ethical and environmental issues surrounding this emerging technology.‚Ü©Ô∏é\nYou can see when scientists predict Halley‚Äôs comet to come closest to earth here. While this is fairly accurate, I‚Äôve seen the exact prediction change over the years - there is still some error in this prediction.‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Chapter 1 \\| Why?</span>"
    ]
  },
  {
    "objectID": "chapters/2R_WhyResearch.html",
    "href": "chapters/2R_WhyResearch.html",
    "title": "Why Research Methods?",
    "section": "",
    "text": "Part 1.",
    "crumbs": [
      "Home",
      "Why?",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Data.html",
    "href": "chapters/3R_Data.html",
    "title": "Data",
    "section": "",
    "text": "Hi! Stay tuned for reading materials. Thanks!",
    "crumbs": [
      "Home",
      "Describing Data",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Description.html",
    "href": "chapters/4R_Description.html",
    "title": "Description",
    "section": "",
    "text": "Part 1.",
    "crumbs": [
      "Home",
      "Describing Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/5R_Scales.html",
    "href": "chapters/5R_Scales.html",
    "title": "Scales",
    "section": "",
    "text": "Hi! Stay tuned for reading materials. Thanks!",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Scales</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html",
    "href": "chapters/6R_LinearModels.html",
    "title": "The Linear Model",
    "section": "",
    "text": "Part 1 : Making Predictions\nAt the beginning of the semester, we talked about how the goal of psychological science is to make predictions about people, while recognizing that our predictions will not perfectly match what actually happens (which we call error).\nConceptually, we can think of a person‚Äôs actual score on y (some variable) as the sum of our prediction and the error in our prediction (with the goal to minimize error as much as possible).\nAs an equation, we would write this as: actual.score = our.prediction + error\nGreat! But the real question is WHAT should define our prediction?",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>The Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html",
    "href": "chapters/7R_CategoricalIV.html",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "",
    "text": "Part 1 : The Linear Model with a Categorical IV with Two Levels",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/8R_Assumptions.html",
    "href": "chapters/8R_Assumptions.html",
    "title": "More Levels and Experiments",
    "section": "",
    "text": "Part 1 : The Linear Model with a Categorical IV‚Ä¶with THREE+ Levels\nIn Chapter 7, we showed how the linear model could be adapted to predict a numeric DV when the IV was a categorical variable with two levels. And guess what? When the IV has more than three levels, we can use the same linear model. Hooray! The only difference is now you have multiple levels that differ from the intercept (or ‚Äúreference group‚Äù).\nLet‚Äôs mix it up, and see if some good ol‚Äô fashioned YOUTUBE VIDEOS OF A DISEMBODIED VOICE can explain this.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/9R_SamplingError.html",
    "href": "chapters/9R_SamplingError.html",
    "title": "Sampling Error and Bias",
    "section": "",
    "text": "Is This The Real Life? Is This Just Fantasy? (Inferential Statistics)",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sampling Error and Bias</span>"
    ]
  },
  {
    "objectID": "chapters/10R_NHSTPower.html",
    "href": "chapters/10R_NHSTPower.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "The Purpose of Multiple Regression\nKey Questions : What is redundant covariation and how does this relate to the idea of a 3rd variable?\n‚ÄúThe Whole is Greater Than the Sum of Its Parts‚Äù\nI like the above work by Max Ernst; like all evocative art it manages to transcend the individual brush strokes and colors to express a sense of terror. But if you were to isolate each line and color into its separate components - canvas; blue; brown; red - the sum of those different parts wouldn‚Äôt equal the work as a whole.\nThe idea behind a multiple regression is the same - by combining two separate independent variables into one integrated model, researchers can understand more about the phenomenon than they would understand if they just examined the results of two separate bivariate models.\nSpecifically, there are two main benefits to the multiple regression :\nThis first benefit to a multiple regression may sound familiar; we talked about it (briefly) in the beginning of the semester in the context of confound vs.¬†control variables.\nConfound vs.¬†Control Variables\nThe basic idea was that many variables explain human life, and it‚Äôs hard to know whether the relationships we find between one independent variable and the dependent variable are specific to that one independent variable, or whether there‚Äôs some other variable that might be influencing the relationship. We talked about this earlier in the semester when we talked about the idea behind a confound variable - a variable that is not part of your model, but would influence the results. The classic example is that ice cream sales are related to murder rates. Of course, ice cream does not really contribute to people getting murdered. There‚Äôs a confound variable - heat - that is related to both how much ice cream is sold (the more heat, the more people eat ice cream) and murder (the hotter it is, the more likely people are to kill each other‚Ä¶apparently.) And if you account for that confound variable by including it in your model, then you‚Äôd find that the relationship between ice cream and murder goes away‚Ä¶it‚Äôs explained by the relationship between heat and murder.\nRecap : The Principle of Covariation\nOur goal with multiple linear regression is the same goal we‚Äôve been working with so far this semester - to explain complexity. To achieve this goal, we‚Äôve been relying on something that I think of as the ‚Äúprinciple of covariation‚Äù. With a bivariate linear regression (what we‚Äôve been doing so far this semester), this involves explaining variation on one psychological dimension (the dependent variable) based on variation on another psychological dimension (the independent variable). In other words, making predictions about Y based on information in X.\nWe wrote out this bivariate model like so :\n\\[\\huge y_i = a + b_1*X_{1i} + {\\epsilon}_i\\]\nTo make sure we are all on the same page1, let‚Äôs recap what‚Äôs going on with this model. On the left-hand side, we are making predictions for some variable (y : the dependent variable) - specifically an individual‚Äôs score on that variable (yi : the tiny i represents some specific individual in the dataset). On the right-hand side of the equation, we have a starting place for our predictions (a : the intercept), and then a slope (b1) that describes how we adjust our predictions of Y based on the individual‚Äôs specific value of some other variable (X1i : the first independent variable). And since human life is complex, our predictions will not be perfect, but will have error (ei) which we define as the difference between the individual‚Äôs actual score (yi) and our predictions for that person‚Äôs score (a + b1X1i). Neat.\nSo far, we‚Äôve used the linear model to make predictions of continuous variables based on categorical variables. For example, in the Prestige dataset (download HERE) we predicted prestige from job type (a categorical factor with three levels - blue collar, professional, and white collar).\nlibrary(car)\n\nLoading required package: carData\n\nlibrary(gplots)\n\n\nAttaching package: 'gplots'\n\n\nThe following object is masked from 'package:stats':\n\n    lowess\n\nmod1 &lt;- lm(prestige ~ type, data = Prestige)\nplotmeans(prestige ~ type, data = Prestige, connect = F, ylab = \"Prestige\", xlab = \"Job Type\")\n\n\n\n\n\n\n\nsummary(mod1)\n\n\nCall:\nlm(formula = prestige ~ type, data = Prestige)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.2273  -7.1773  -0.0854   6.1174  25.2565 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   35.527      1.432  24.810  &lt; 2e-16 ***\ntypeprof      32.321      2.227  14.511  &lt; 2e-16 ***\ntypewc         6.716      2.444   2.748  0.00718 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.499 on 95 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.6976,    Adjusted R-squared:  0.6913 \nF-statistic: 109.6 on 2 and 95 DF,  p-value: &lt; 2.2e-16\nWe also used this linear model to make predictions of continuous variables (e.g., prestige) based on other continuous variables (e.g., education).\nmod2 &lt;- lm(prestige ~ education, data = Prestige)\nplot(prestige ~ education, data = Prestige, xlab = \"Years of Education\", ylab = \"Prestige\")\nabline(mod2, lwd = 5, col = 'red')\n\n\n\n\n\n\n\nsummary(mod2)\n\n\nCall:\nlm(formula = prestige ~ education, data = Prestige)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.0397  -6.5228   0.6611   6.7430  18.1636 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -10.732      3.677  -2.919  0.00434 ** \neducation      5.361      0.332  16.148  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.103 on 100 degrees of freedom\nMultiple R-squared:  0.7228,    Adjusted R-squared:   0.72 \nF-statistic: 260.8 on 1 and 100 DF,  p-value: &lt; 2.2e-16\nRedundant Covariation\nWe could go through life (and statistics) by considering simple relationships between two variables. These kinds of bivariate models are a good (and necessary) place to start our inquiry. But no psychological phenomenon is entirely explained by any one variable. Instead, human life is explained by multiple variables that are often related to each other and sometimes work together2 in order to influence behavior. We saw this in the example above, where prestige appears to be separately explained both by job type and education. But the situation gets more complicated, because as a quick test in R reveals, job type and education are also related to each other.\nmod3 &lt;- lm(education ~ type, data = Prestige)\nsummary(mod3)\n\n\nCall:\nlm(formula = education ~ type, data = Prestige)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.99419 -0.80932  0.08947  0.61392  2.57068 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   8.3593     0.1800  46.446  &lt; 2e-16 ***\ntypeprof      5.7249     0.2799  20.450  &lt; 2e-16 ***\ntypewc        2.6624     0.3072   8.667 1.16e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.194 on 95 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.8153,    Adjusted R-squared:  0.8114 \nF-statistic: 209.6 on 2 and 95 DF,  p-value: &lt; 2.2e-16\n\nplotmeans(education ~ type, data = Prestige, connect = F, xlab = \"Job Type\", ylab = \"Years of Education\")\nCompare this output (and graph) to the output (and graph) where we predicted prestige from job type. Spoiler alert - the effects are pretty similar. Blue collar workers are predicted to have the lowest level of education (8.35 years), professionals have 5.72 years of education more than blue collar workers (a significant difference), and white collar workers have 2.66 years of education more than blue collar workers (also a significant difference).\nThat job type, education, and prestige are all related to each other represents redundant covariation and raises an important possibility - the relationship between job type and prestige could really be due to the relationship between education and prestige. That is, since jobs with more education are rated as having more prestige, and blue collar workers have the least education (on average), the reason why blue collar jobs have the least amount of prestige could be better explained by differences in education. Similarly, professionals might be rated as having the most prestige because they have the most education. Of course, it‚Äôs also possible that education is related to prestige because of the type of job that workers have.\nWith separate bivariate models, it‚Äôs impossible to know whether these two independent variables are uniquely related to prestige or whether one variable is more related to prestige than another because we are only looking at one relationship at a time. The multivariate regression - one that predicts prestige simultaneously from both education and job type - will help sort out this issue.",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/11R_MultipleRegression.html",
    "href": "chapters/11R_MultipleRegression.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "Hi! Stay tuned for reading materials. Thanks!",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/12R_Conclusion2Introduction.html",
    "href": "chapters/12R_Conclusion2Introduction.html",
    "title": "Conclusion 2 Introduction",
    "section": "",
    "text": "Hi! Stay tuned for reading materials. Thanks!",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Conclusion 2 Introduction</span>"
    ]
  },
  {
    "objectID": "labs.html",
    "href": "labs.html",
    "title": "Appendix A ‚Äî Lab Assignments",
    "section": "",
    "text": "Here is a list of your lab assignments. Everyone loves lab assignments!!\n\n\n\nLecture Date\nLecture Notes\nLab [due by 2:00 PM the week after lecture]\nLink to Key\n\n\n\n\n1/24\nWelcome\nLab 1 - Getting Started [Google Doc]\nLab 1 Key\n\n\n1/31\n\nLab 2 [Navigating Data]\n\n\n\n2/7\n\nProject Milestone: Intro Outline\n\n\n\n2/14\n\nLab 3 [Summarizing Data]\n\n\n\n2/21\n\nLab 4 [Practice Mini Exam]\n\n\n\n2/28\n\nProject Milestone: Study Draft\n\n\n\n3/7\n\nLab 5 [Linear Models]\n\n\n\n3/14\n\nLab 6 [More Models]¬†\n\n\n\n3/21\n\nProject Milestone : Methods & Launch Study!\n\n\n\n3/28\n\nProject Milestone : Participants & Descriptive Statistics\n\n\n\n4/4\n\nProject Milestone : Linear Model Tables\n\n\n\n4/11\n\nLab 7 [Practice Exam]\n\n\n\n4/18\n\n\n\n\n\n4/25\n\nProject Milestone : Draft\n\n\n\n5/2\n\n\n\n\n\n5/9\n\nFinal Project is Due 5/12 at 11:59 PM",
    "crumbs": [
      "Lab Assignments",
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Lab Assignments</span>"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Appendix B ‚Äî About",
    "section": "",
    "text": "B.1 Hi, it‚Äôs me - your professor.\nBlah blah",
    "crumbs": [
      "Home",
      "Appendices",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>About</span>"
    ]
  },
  {
    "objectID": "chapters/2R_WhyResearch.html#part-2.",
    "href": "chapters/2R_WhyResearch.html#part-2.",
    "title": "Why Research Methods?",
    "section": "Part 2.",
    "text": "Part 2.",
    "crumbs": [
      "Home",
      "Why?",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/2R_WhyResearch.html#part-3.",
    "href": "chapters/2R_WhyResearch.html#part-3.",
    "title": "Why Research Methods?",
    "section": "Part 3.",
    "text": "Part 3.",
    "crumbs": [
      "Home",
      "Why?",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Description.html#part-2.",
    "href": "chapters/4R_Description.html#part-2.",
    "title": "Description",
    "section": "Part 2.",
    "text": "Part 2.",
    "crumbs": [
      "Home",
      "Describing Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Description.html#part-3.",
    "href": "chapters/4R_Description.html#part-3.",
    "title": "Description",
    "section": "Part 3.",
    "text": "Part 3.",
    "crumbs": [
      "Home",
      "Describing Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/0R_About.html",
    "href": "chapters/0R_About.html",
    "title": "Introduction",
    "section": "",
    "text": "Goals of the Course\nThis class is really three classes in one semester - a research methods class where you will learn how psychologists collect data in order to answer questions about people (or non-human animals), a programming class where you will learn how to use R to work with these data, and a statistics class where you will learn how and why psychologists analyze this data to answer their questions.\nThere are two major assignments in the class that represent the kinds of authentic skills you might need as a psychological researcher:\nWe will talk much more about these assignments throughout the semester, and you will be well prepared for them if you follow along with the readings, quizzes, and homework assignments each week.",
    "crumbs": [
      "List of R Code",
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/0R_About.html#the-book",
    "href": "chapters/0R_About.html#the-book",
    "title": "About this Class and Author",
    "section": "The Book",
    "text": "The Book",
    "crumbs": [
      "Home",
      "Introduction"
    ]
  },
  {
    "objectID": "Rcode.html",
    "href": "Rcode.html",
    "title": "Appendix B ‚Äî Rcode",
    "section": "",
    "text": "Here is a list of the R code we use in this class.",
    "crumbs": [
      "List of R Code",
      "Appendices",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Rcode</span>"
    ]
  },
  {
    "objectID": "chapters/0R_About.html#this-book",
    "href": "chapters/0R_About.html#this-book",
    "title": "Introduction",
    "section": "This Book",
    "text": "This Book\nThis textbook will also be part of the flipped classroom approach that we will take this semester.\n\nBefore lecture you‚Äôll read and watch some videos to be introduced to the content that we will then cover more deeply in lecture. You‚Äôll also take a short quiz (no time limit, open-note, and you can take as many times as you‚Äôd like) that will encourage you to do the readings, and let me know what topics are still confusing to students.\nDuring lecture we will review concepts that students still had questions about from the readings, and spend the rest of the time practicing and discussing the skills you learned. We will work on the homework assignment together\nAfter lecture you‚Äôll complete any homework that we didn‚Äôt finish in class, and then read for the next week‚Äôs lecture.\n\nThe flipped classroom approach requires y‚Äôall to do the readings and watch the videos before class.\nThe flipped classroom approach also requires me to write text and record videos that are engaging and helpful for the three main parts of this class.\n\n\n\n\n\n\n\nProf.¬†Cat\nStatistics and R : This semester, we‚Äôll be learning how (and why) psychologists use statistics. We‚Äôll also learn how to use the programming language R.\n\n\nMickey Mouse\nResearch Methods : Everyone‚Äôs favorite public domain character is here to help navigate you through the various tools that psychologists use, so you can use them to conduct an independent research project! Hooray!\n\n\nRatty Rat\nCritical Thinking :",
    "crumbs": [
      "Cat Home",
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/0R_About.html#the-class",
    "href": "chapters/0R_About.html#the-class",
    "title": "Introduction",
    "section": "The Class",
    "text": "The Class\nHere‚Äôs a link to",
    "crumbs": [
      "Cat Home",
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/0R_About.html#hey-its-a-check-in",
    "href": "chapters/0R_About.html#hey-its-a-check-in",
    "title": "Introduction",
    "section": "Hey, it‚Äôs a check-in!",
    "text": "Hey, it‚Äôs a check-in!\nLoading‚Ä¶",
    "crumbs": [
      "Cat Home",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#about-the-author",
    "href": "index.html#about-the-author",
    "title": "Why Statistics?",
    "section": "About the Author",
    "text": "About the Author\nMy name is Arman Daniel Catterson, and thank you for reading these words that I wrote. I‚Äôm a professor at Diablo Valley College (tenured) & UC Berkeley (continuing lecturer), who has been teaching some version of this class since Summer 2015. Feel free to say ‚Äúhi‚Äù if you see me on campus :)",
    "crumbs": [
      "List of R Code",
      "Preface"
    ]
  },
  {
    "objectID": "index.html#find-a-problem-or-have-an-idea",
    "href": "index.html#find-a-problem-or-have-an-idea",
    "title": "Why Statistics?",
    "section": "Find a Problem or Have an Idea?",
    "text": "Find a Problem or Have an Idea?\nPlease fill out this form if you see any errors in the book, or have ideas about ways this textbook could better support students in this (or other) classes. This textbook is very much a work in progress, and I‚Äôd love any input you have about the content, organization, or presentation of these materials. If you want to use this text in your own class, reach out and I can send you lecture notes and assignment details.",
    "crumbs": [
      "List of R Code",
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "Why Statistics?",
    "section": "How to Use This Book",
    "text": "How to Use This Book\nTo get started, click on the section titled ‚ÄúIntroduction‚Äù in the Table of Contents to the left. You should also see an arrow in the bottom right corner of this screen that you can click on to advance to the next section if you want to read in order.\nAt the very top of this page, you should see some helpful links to our Lab Assignments, the RCode that you will need for this class (we will go over this throughout the semester), and the course syllabus.",
    "crumbs": [
      "List of R Code",
      "Preface"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#to-do-list-due-before-our-first-lecture",
    "href": "chapters/1R_WhyStats.html#to-do-list-due-before-our-first-lecture",
    "title": "Why Statistics?",
    "section": "",
    "text": "Read this document and watch the videos.\nTake the quiz on bCourses (and submit the on-boarding survey code for the final question).",
    "crumbs": [
      "Lab Assignments",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#quiz-1",
    "href": "chapters/1R_WhyStats.html#quiz-1",
    "title": "Why Statistics?",
    "section": "Quiz 1",
    "text": "Quiz 1",
    "crumbs": [
      "Lab Assignments",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#psychology-as-a-real-science",
    "href": "chapters/1R_WhyStats.html#psychology-as-a-real-science",
    "title": "Chapter 1 | Why?",
    "section": "Psychology as a REAL SCIENCE ‚Ñ¢",
    "text": "Psychology as a REAL SCIENCE ‚Ñ¢\nPsychology desperately wants to establish itself as a real science, like physics and chemistry. You don‚Äôt have to take my word for it, just look at the definitions of some common sources of psychological knowledge - introductory textbooks :¬†¬†\n\n‚ÄúToday, we define psychology as the science of behavior and mental processes.‚Äù (Myers, 2011)\n‚Äú‚Ä¶the science of behavior and the mind.‚Äù (Grey, 2010)\n‚Äú‚Ä¶the scientific study of mind, brain, and behavior.‚Äù (Gazzaniga, 2010)\n‚Äú‚Ä¶We now define psychology as the science of behavior and mental processes.‚Äù (Myers & DeWall, 2018)\n\nI‚Äôm probably showing my age looking to textbooks, so let‚Äôs check in with ChatGPT6 to see whether the algorithmic summary of large piles of data suggests that psychology is, in fact, a ‚Äúreal science‚Äù :¬†\n6¬†See the syllabus for the course ChatGPT policy. You may also be interested to read on the ethical and environmental issues surrounding this emerging technology.\nPerhaps more authoritatively, the American Psychological Association (APA) confirms that psychology is, ‚Äúthe study of the mind and behavior‚Ä¶a diverse scientific discipline comprising several major branches of research.‚Äù (APA, 2024).¬†\nThe consistent emphasis on science (and ‚Äúrigorous‚Äù methods!) in these definitions is an attempt to elevate psychology to the status of other ‚Äúhard‚Äù sciences, like physics and chemistry. But inclusion of the term ‚Äúscience‚Äù also seeks to differentiate psychology from its less scientific heritage and past, defend itself from accusations from other scientists / talking heads (if not some of your friends in STEM majors‚Ä¶or parents) that it is not actually REAL SCIENCE ‚Ñ¢.¬†\n\nWhat is Science? Prediction (and Error)\nOne of the most important goals of science is to form predictions, and then use these predictions in order to influence outcomes (a form of power).\nA prediction is an educated guess you have about the future. Educated means that the guess comes from some knowledge (either your experiences, beliefs, something you learned in a textbook, or the results of a scientific study). A prediction can have two outcomes :\n\nValid : your prediction is right\nError : your prediction is wrong.\n\nOf course, things are rarely as simple as ‚Äúright‚Äù or ‚Äúwrong‚Äù, and a large part of this class will be learning how to quantify exactly how much error there is in our scientific predictions.\nAs an example, let‚Äôs look to the stars.\n\n\n\n\nAstronomers have developed knowledge about celestial bodies - gravity, orbits, mass (I know very little about this).\nBut I trust this science because astronomers are able to use it to make very valid predictions about giant space rocks and when they will come close to the earth.7\nI can use this knowledge to plan a stargazing trip, or plan to watch all the rich people leave earth when the ‚Äúbig one‚Äù comes for the rest of us.\n\n\n\n7¬†You can see when scientists predict Halley‚Äôs comet to come closest to earth here. While this is fairly accurate, I‚Äôve seen the exact prediction change over the years - there is still some error in this prediction.For our first lecture, start thinking of some predictions that you have made today. What knowledge informed the prediction. Did you use this prediction to influence your future behavior in some way? What kinds of predictions do psychologists make? We will chat more about these ideas in class :) but it‚Äôs a core focus on why psychologists use predictions.\nAnd so, here we are. In this document, in this required class for the psychology major, learning how to DO REAL SCIENCE. With statistics. So Oh yeah, and we‚Äôll also be learning to use this computer programming language called R üòà",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Chapter 1 \\| Why?</span>"
    ]
  },
  {
    "objectID": "chapters/0R_About.html#goals-of-the-course",
    "href": "chapters/0R_About.html#goals-of-the-course",
    "title": "Introduction",
    "section": "",
    "text": "The R Exam. I‚Äôll give you a dataset, and you‚Äôll use your knowledge of statistics, R, and research methods to answer questions about the dataset.\nThe Final Project. You will identify a resarch question that you care about, and then design a study, collect data, analyze the data to answer this question (and write up everything as a scientific research paper.) Wow!",
    "crumbs": [
      "List of R Code",
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/0R_About.html#course-structure",
    "href": "chapters/0R_About.html#course-structure",
    "title": "Introduction",
    "section": "Course Structure",
    "text": "Course Structure\nThis semester, we‚Äôll be taking a flipped classroom approach to learning the statistics, research methods, and programming required of modern psychology researchers.\n\nBefore lecture you‚Äôll read and watch some videos to be introduced to the content that we will then cover more deeply in lecture. You‚Äôll also take a short quiz (no time limit, open-note, and you can take as many times as you‚Äôd like) that will encourage you to do the readings, and let me know what topics are still confusing to students.\nDuring lecture we will start with a review of concepts you learned from the pre-readings, go over any common questions that students still have, and then use the remaining time to practice and discussing the skills and concepts. We will work on the homework assignment together\nAfter lecture you‚Äôll complete any homework that we didn‚Äôt finish in class, and then read for the next week‚Äôs lecture.\n\nThe flipped classroom approach requires y‚Äôall to do the readings and watch the videos before class, and requires me to write text and record videos that are engaging and helpful for the students in the class.",
    "crumbs": [
      "List of R Code",
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/0R_About.html#course-syllabus.",
    "href": "chapters/0R_About.html#course-syllabus.",
    "title": "Introduction",
    "section": "Course Syllabus.",
    "text": "Course Syllabus.\nTake a look at our course syllabus - linked above (and also on bCourses). We will chat a little about course policies on the first day.\nAlso, please take a moment to join our class Discord if you haven‚Äôt already (the link to join is on bCourses, and in first the announcement I sent) - it‚Äôs a great space to build community, and ask (and help answer) questions about the class or why R isn‚Äôt working.",
    "crumbs": [
      "List of R Code",
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html",
    "href": "chapters/2R_Data.html",
    "title": "Data",
    "section": "",
    "text": "Part 1 : Defining Data\nHello! In this week‚Äôs reading, you‚Äôll learn how to work with data in R - first how to navigate datasets, and then how to graph (and think critically about) both categorical and continuous variables.\nResearchers seeking to bring a scientific approach to psychology love data, and aim to convert complex human thoughts, feelings, and behaviors into numbers. This is called quantitative data, and is the default approach almost all modern research psychologists take. For example:\nWhile we will learn more about the various ways psychologists collect data later this semester, for now it‚Äôs important to acknowledge that these numbers have error (called measurement error), a fair amount of work in psychology goes into learning how to reduce measurement error as much as possible, and the existence of measurement error is one form of error that will contributes to the ERROR term in our linear models.\nQuantitative data takes two forms that we will see in this class - numeric (sometimes called continuous data)¬† and categorical data (sometimes called ‚Äústring‚Äù data).",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/3R_ResearchMethods.html",
    "href": "chapters/3R_ResearchMethods.html",
    "title": "Why Research Methods?",
    "section": "",
    "text": "Part 1.",
    "crumbs": [
      "Lab Assignments",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/3R_ResearchMethods.html#part-2.",
    "href": "chapters/3R_ResearchMethods.html#part-2.",
    "title": "Why Research Methods?",
    "section": "Part 2.",
    "text": "Part 2.",
    "crumbs": [
      "Lab Assignments",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/3R_ResearchMethods.html#part-3.",
    "href": "chapters/3R_ResearchMethods.html#part-3.",
    "title": "Why Research Methods?",
    "section": "Part 3.",
    "text": "Part 3.",
    "crumbs": [
      "Lab Assignments",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/0R_About.html#getting-started.",
    "href": "chapters/0R_About.html#getting-started.",
    "title": "Introduction",
    "section": "Getting Started.",
    "text": "Getting Started.\nBefore our first class, please read Chapter 1 (Why Statistics?) By clicking the right arrow below, or clicking on this chapter in the Table of Contents. Yeah!",
    "crumbs": [
      "List of R Code",
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#numeric-variables",
    "href": "chapters/2R_Data.html#numeric-variables",
    "title": "Data",
    "section": "Numeric variables",
    "text": "Numeric variables\n\nDefinition : Numeric Variable\nNumeric variables are when the value of the variable is a number (e.g., your Extraversion score is 62 on a scale from 0 to 100; or you said ‚Äúum‚Äù fifty times yesterday, or scrolled your phone five times since starting this reading.¬†\nContinuous variables are a special type of numeric variable, with the idea that values of the variable represent an ‚Äúinfinite‚Äù range of possibilities.\nWe often simplify complexity into discrete groups, but for most complex phenomena, I believe that it‚Äôs best to think of life as a spectrum. For example, while I look at my walls and say ‚Äúthey are blue‚Äù, a physicist who really understands color theory would be able to interpret the wavelength of light that is being reflected off these walls, and understands that that wavelength really just a point on an infinite spectrum (bound by a certain range).\n\nPsychologists working in R often use numeric data, and see this as a list (or vector) of numbers. For example, below is data on the narcissism (variable = NPI; a measure of how self-absorbed; self-interested) of a group of Berkeley Haas MBA students were1.\n\nhaas &lt;- read.csv(\"./chapter_data/hormone_data.csv\", stringsAsFactors = T) \nhaas$NPI\n\n  [1] 3.43 4.40 3.13   NA 3.00   NA 3.05   NA   NA 3.63 3.95 3.08 3.83 3.23 3.80\n [16] 1.80 3.68 3.48 2.73 3.40 2.95 3.65 2.88 2.50 3.13 2.75 3.00 3.15 3.30 3.20\n [31] 2.43 3.13   NA 3.33 2.88 2.55 3.35 3.30 3.28 3.08 2.48 2.78 4.58 2.53 2.78\n [46] 2.88   NA 3.43 2.48 3.50 2.40 3.28 3.63 3.13 2.05 2.98 2.53 3.45 2.80 2.60\n [61] 2.05 2.60 2.73 3.25 2.78 2.93 3.08 3.33 4.05 3.65 3.15 3.33 3.98 4.48 3.00\n [76] 3.00 3.25 4.28 3.13 3.83 3.98 4.13 3.73 3.28 2.85 3.28 3.70 3.03 3.38 2.88\n [91] 3.20 3.40 3.70 3.50 2.58 2.90 3.00 3.35 2.63   NA   NA 4.05 3.43 4.28 3.00\n[106] 3.10 3.13 2.83 2.78 2.33 2.68 2.88 2.53 3.80 3.48 3.15 4.38 3.73 3.80 2.60\n[121] 3.38 3.13\n\n\nProfessor Interpretation I learn a lot just from this simple output!\n\nhaas &lt;- read.csv(‚Äú./chapter_data/hormone_data.csv‚Äù, stringsAsFactors = T‚Äù) is the R command that loads the dataset. Note that the path to the datafile - hormone_data.csv - is specific to the way I‚Äôve stored these data in my file system. You‚Äôll learn below how to change this to access your own dataset :)\nhaas$NPI is the R command that was used to generate the output below; a list of 122 individual Narcissism scores.\n\nI know there‚Äôs 122 individual scores because R is keeping count for me using indexing; the numbers in brackets. [1] shows that the first person in the dataset has a narcissism (NPI) score of 3.43; [118] 3.73 shows that this is the score for the 118th person in the dataset, and then I can count up to 122. There are much faster ways to do this, but I can do it this way too :)\nI also see there are a few missing data points in the responses - these are marked as NA. This could be people who didn‚Äôt complete the survey or were excluded for other reasons (e.g.¬†missing data).\n\n\n\n\nGraphing : The Histogram\nThe Histogram is a commonway researchers illustrate numeric variables. We will learn more about principles of good graphing this semester, but the KEY IDEA is to always always always graph your data because A PICTURE IS WORTH 1000 WORDS.¬†\nThe histogram organizes data - you lose the individual values, but gain understanding in seeing how data are grouped together, which helps you observe patterns and get a quick summary of the variable.¬†\nThere are two dimensions of a histogram :¬†\n\nthe x-axis (the horizontal axis; what goes across) : displays the values of the variable as organized into groups (or ‚Äúbreaks‚Äù, in R).¬†\nthe y-axis (the vertical axis; what goes up and down) : displays the frequency (or count) of the individuals in the data who ‚Äúbelong‚Äù to that group.\n\nLet‚Äôs look at our MBA friends again, through the power of a histogram. As you look at a graph, it‚Äôs important to practice thinking about what you learn from the data. Let‚Äôs avoid fancy stats terminology for now; it‚Äôs not necessary for our purposes!!\n\nhist(haas$NPI, xlab = \"Narcissism Score\", col = 'black', bor = 'white', main = \"\")\n\n\n\n\n\n\n\n\n\nthe code : this code draws a histogram using the hist() function. I‚Äôve also added several arguments that change some of the default settings to give the graph some digital style.\n\nxlab gives the x-axis of the graph a nice label.\ncolchanges the color of the bars to black.\nbor changes the color of the lines surrounding the bars to white.\nmain changes the title. In this case, \"\" sets the title to be nothing, so there‚Äôs no title.\n\nthe graph : okay, what did R do!\n\nx-axis : this reports the grouped values of the individual narcissism scores.¬†\ny-axis : this reports how many people were in each group.\n\nprofessor interpretation with no fancy stats language needed.\n\nmost people (around 42?) had a narcissism score between 3 and 3.5\na few people were really high in narcissism‚Ä¶above a 4.5. I‚Äôm not sure from the graph exactly how many people were in this group, or what their score was.\na few people were really low in narcissism‚Ä¶below a 2. Again, I‚Äôm not sure from the graph exactly how many people were in this group, or what their score was, but I see their humble selves!\nI also notice that this is not a super large study - the frequencies on the y-axis are relatively low numbers.\n\n\n\n\nActivity : Think about Data!\nOkay, your turn. Below is a graph from the same MBA students, but this time measuring their testosterone levels. Look over the graph, THINK about what you see, and then expand the textbox below (click on the arrow on the right side of the green box) to see what I wrote.\n\nhist(haas$test, \n     xlab = \"Testosterone Level\", main = \"\", \n     col = 'black', bor = 'white')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROFESSOR SPOILERS : Expand this textbox when you are ready by clicking on the arrow ‚Äî&gt;\n\n\n\n\n\n\nthe graph\n\nx-axis : this reports the grouped values of the individual testosterone scores, measured in some kind of density (pg/ML)\ny-axis : this reports how many people were in each group.\n\nwhat I see and observe with no stats language :\n\nmost people (around 25+12+20 = 77) had a testosterone level between 50 and 100.\nthere were no scores below zero (which makes sense) and one person who had a very high level of testosterone. I‚Äôm not a hormone researcher, but the non-negative values seems good, and I might want to make sure that there wasn‚Äôt some data entry error for the extreme score.\nAgain, I notice that this is not a super large study‚Ä¶.and these relatively low numbers seem similar to the narcissism data, which makes sense since they came from the same study.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#footnotes",
    "href": "chapters/2R_Data.html#footnotes",
    "title": "Data",
    "section": "",
    "text": "These data come from the hormone_data.csv file, which should be updated to our course page. You‚Äôll learn more about how to access these data files later in this chapter.‚Ü©Ô∏é\nthey are all one color - the human color. just kidding from the top left it‚Äôs 2, 3, 4, and 7. but I‚Äôm blue green color blind so you should argue with me in the comments.‚Ü©Ô∏é\nSee this article for research documenting this phenomenon, and arguing why a more inclusive science is needed.\n\n‚Ü©Ô∏é\nfacebook‚Äôs attempt at measuring more complex categories.\n\n‚Ü©Ô∏é\na continuous approach to measuring gender. hi if u still reading, let me know if you have any thoughts on this section of the chapter.‚Ü©Ô∏é\nWill learn about these ideas much later this semester! here‚Äôs a link to learn more about women in Haas. capitalism will eat us all eventually I guess, and good to challenge our stereotypes / perceptions!‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#categorical-factor-variable",
    "href": "chapters/2R_Data.html#categorical-factor-variable",
    "title": "Data",
    "section": "Categorical Factor Variable",
    "text": "Categorical Factor Variable\n\nDefinition : Categorical Factor Variable\nA categorical factor variable is when the values of the variable represent different groups, usually labeled with some kind of word. Categories are often useful and simple ways to group individuals together. For example, when I see a color, I don‚Äôt ever describe it in terms of its color hex code or specific wavelength - I just call it by the simple primary color that I got from the crayola box; maybe the 24 color version if I‚Äôm feeling fancy.\nWhich of the shades below would you call blue?2\n\n\n\n\n\nThe broad label for the variable is called the factor, and the specific groups of data are called levels. So in the color example, the category of color would be the factor, and the different groups of color would be the levels.\nAs another example, researchers can measure gender with categories such as female, male, transgender, and other. Identify the factor and levels in this example.\n\n\n\n\n\n\nWhat are the factors and levels in the example above?\n\n\n\n\n\n\nFactor : would be the variable of gender. Generally there‚Äôs one factor label for each variable.\nLevel : would be the categories female, male, transgender, and other.\n\n\n\n\n\nCulture in Statistics : Gender Identity\n\n\n\n\nHi folks! It‚Äôs me again, Open-Source Mickey Mouse to talk with you about the idea that statistics has a culture that is socially constructed by people like you! We live in a society where people in positions of power often have very narrow definitions of what it means to be a person! This manifests in all sorts of ways - you probably feel this pressure when you think about what it means to be a ‚Äúsuccessful student‚Äù.\nOne domain where this is particularly relevant is in the area of gender identity. While many people identify as ‚Äúmale‚Äù or ‚Äúfemale‚Äù, some people don‚Äôt fit into these categories. (Seems pretty simple to me to let folks exist as they want! But I‚Äôm just a poor public servant.) Yet as folks in power have recently forced this narrow binary view of gender identity onto everyone, it becomes even more critical to engage with these ideas and try to define a science that can capture the complexity of human life in ways that let people be their full selves.\n\n\n\n\n\n\nUnfortunately, most psychological researchers still hold on to Male / Female binaries in the way they measure gender or sex, yet there are many reasons - both scientific and humanistic - to give people more range to express important aspects of their identity3.\nIndeed, categories almost always oversimplify the complexity of life, yet are often used by people (and researchers) because they can sometimes be useful and simple shortcuts for us to understand the world.\nIf you are simply interested in doing a superficial survey of a variable like race, ethnicity, or gender, then I think categorical data can be a fine -if often unscientific - approach, and would recommend giving all people the chance to express their identity in some way.\nHowever, if you are interested in really digging into a variable, then a continuous approach is almost always best. We‚Äôll discuss more on how to do this in a few weeks when we learn about continuous variables and likert scales.\n\n4\n5\n\n\n\n\n\n\nGraphing : The Categorical Plot\nThe histogram only describes a graph for numeric data, since it organizes numbers into groups (it kind of turns complex variation into more simple categories). When the variable is categorical, people call it a plot ü§∑.\nThis graph looks very similar to our histogram :¬†\n\nthe x-axis (the horizontal axis; what goes across) : displays the levels of the factor variable.\nthe y-axis (the vertical axis; what goes up and down) : displays the frequency (or count) of the individuals in the data who ‚Äúbelong‚Äù to each group.\n\nAlright, back to our good MBA friends. This is a graph of the categorical variable ‚Äúsex‚Äù. Again, look over the graph, THINK about what you see (no stats terminology; what do you learn!), and then highlight my text to see what I wrote about.\n\nplot(haas$sex, col = 'black', bor = 'white', xlab = \"Sex\")\n\n\n\n\n\n\n\n\n\nThe Code : this code draws a histogram using the plot() function. Note that I‚Äôve asked R to plot the variable haas$sex. I‚Äôve also added several arguments that change some of the default settings to give the graph some digital style.\n\nxlab gives the x-axis of the graph a nice label.\ncolchanges the color of the bars to black.\nbor changes the color of the lines surrounding the bars to white.\n\nThe Graph :\n\nx-axis : this reports levels (female; male) of the categorical factor variable Sex.¬†\ny-axis : this reports how many people were in each group.\n\nWhat I see and observe with no stats language :\n\nIt appears that the researchers only measured sex as a f/m binary (or that no participants reported a category other than female or male).\nthere were more males than females in this dataset. This matches my perception / stereotype of what a typical MBA program might look like; however I looked into it and Haas reports a larger percentage of female enrollments in the MBA program; so our data may not serve as a representative sample of the true population.6",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#defining-variables-in-r",
    "href": "chapters/2R_Data.html#defining-variables-in-r",
    "title": "Data",
    "section": "Defining Variables in R",
    "text": "Defining Variables in R\nBelow are some videos, and R code, that review how to define a variable in R. Yeah!\nWe practiced this in lecture, but below are some videos that go over how to define variables in R. Yeah!!!! I‚Äôm not going to share the Rscripts I‚Äôm using for these videos, since I think there‚Äôs value in typing this out yourself to get that muscle memory in üí™ü§ò but let me know if you disagree / there‚Äôs a reason to provide them to y‚Äôall!\n\nVideo : Defining Numeric Variables in R\n\n\nobjects - assign function for numerical data\nc() : combining data together.\nlength() : the number of objects\n\n\n\nVideo : Graphing Numeric Variables in R\n\n\nhist() : a graph\nchanging arguments : xlab, ylab, main\n\n\n\nVideo : Defining Categorical Variables in R\n\n\ncategorical data (‚Äústring‚Äù)\nas.factor() : to convert a string to a categorical variable\nlevels() : to see the levels of your categorical variable.\n\n\n\nVideo : Graphing categorical variables in R\n\n\nplot()\nchanging arguments : col, bor, main; xlab; ylab",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#part-2-working-with-datasets",
    "href": "chapters/2R_Data.html#part-2-working-with-datasets",
    "title": "Data",
    "section": "Part 2 : Working with Datasets",
    "text": "Part 2 : Working with Datasets\n\nThe Dataframe\n\nDefinition : Rows and Columns\nAs a researcher, you‚Äôll be interested in understanding not only one variable at a time, but will be interested in a dataset - multiple variables about an individual that are organized - in order to see how variables are related to each other (remember : this is a function of the linear model).\nThe datasets in our class will be stored on Dropbox; you can find a link to this on bCourses (see below).\n\n\n\n\n\nYou‚Äôll learn how to load these datasets later in this lecture. For now, what is a dataset?\nA dataset is really a dataframe - a two-dimensional way to organize data - and takes the following structure in this class.\n\nthe rows define the individual in the dataset.¬†rows go across horizontally, like a rowboat going across a lake.\nthe columns define the variables in the dataset. ¬†go up and down vertically; like what might support a bridge.\n\nLook at the example below - again from our budding MBAs in the Haas program. What do you observe about the rows and columns? What does this tell you about the dataset?\n\n\nIn the example dataframe above - I see 5 rows (representing 5 individuals) and five columns (representing five variables like the person‚Äôs age, their sex, their testosterone levels, political ideology, and their NPI (Narcissism) score.¬† or their Race, etc.) Note that the names of the variables do not count as a row, since these are not individuals in the dataset, and you would need to know more about the dataset to know that ideo = political ideology, or test = testosterone. I also see that R is helpfully telling me that this is only a snapshot of the entire dataset - the whole dataframe has 122 entries (rows), meaning that there‚Äôs 122 MBA students in this dataset, and 5 total columns (which we can all see here.)\nAs a researcher, you have access to an entire dataset (either collected by you or another researcher) that organizes multiple variables for each individual. This semester, we‚Äôll work with a variety of datasets on different psychological topics - not just haas students.\n\n\nDefinition : Indexing\nThe dataset gives us access to all the individual rows and columns at once, we will often want to focus on one specific variable (or individual) at a time. Indexing refers to a flexible method of selecting a specific set of data from a larger collection. Previously‚Äô we‚Äôve seen indexing when asking R to produce a large set of numbers; for example asking it to count from 1 to 100.\n\n1:100\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\n\nThe indexing shows up as brackets next to the actual data, and is way for R to index that the [1]st data entry is the number 1, the [24]th entry is the number 24, and so on.\nWhen I ask R to show me the dataset haas, the output can be overwhelming. Below is what R shows you when you ask to see the haas dataset. And this is a relatively small dataset with just 122 individuals (rows) and five variables (columns).\n\nhaas\n\n    age    sex   test ideo  NPI\n1    NA   male     NA   NA 3.43\n2    NA   male 143.89   NA 4.40\n3    NA   male     NA   NA 3.13\n4    30   male     NA    4   NA\n5    28   male     NA    4 3.00\n6    33 female     NA    5   NA\n7    NA   male     NA   NA 3.05\n8    NA   male     NA   NA   NA\n9    NA   male  77.95   NA   NA\n10   NA   male     NA   NA 3.63\n11   26   male 126.29    3 3.95\n12   31   male  59.48    5 3.08\n13   27   male  89.45    4 3.83\n14   27   male  82.80    3 3.23\n15   28   male  97.39    4 3.80\n16   30   male  54.80    4 1.80\n17   28   male  46.07    4 3.68\n18   24   male     NA    4 3.48\n19   32   male  87.40    3 2.73\n20   25   male  85.01    4 3.40\n21   27   male     NA    3 2.95\n22   25   male     NA    4 3.65\n23   24   male 102.86    3 2.88\n24   28   male  73.60    3 2.50\n25   27   male     NA    2 3.13\n26   29   male  90.68    4 2.75\n27   28   male  44.70    3 3.00\n28   29   male     NA    4 3.15\n29   30   male  77.61    4 3.30\n30   26   male  57.20    5 3.20\n31   31   male  49.92    4 2.43\n32   28   male     NA    3 3.13\n33   32   male     NA    5   NA\n34   27   male  85.01    2 3.33\n35   32   male  74.86    2 2.88\n36   27   male 125.89    3 2.55\n37   29   male  77.07    4 3.35\n38   30   male     NA    4 3.30\n39   26   male  30.54    4 3.28\n40   27   male  73.76    3 3.08\n41   32   male  65.61    3 2.48\n42   29   male  51.23    4 2.78\n43   28   male  85.17    3 4.58\n44   28   male     NA    3 2.53\n45   29   male  57.14    2 2.78\n46   30   male  65.31    4 2.88\n47   28   male  53.07    4   NA\n48   28   male 104.65    3 3.43\n49   31   male  90.32    3 2.48\n50   NA female  24.71   NA 3.50\n51   26 female  20.99    3 2.40\n52   27 female     NA    4 3.28\n53   28 female     NA    3 3.63\n54   28 female   5.51    5 3.13\n55   27 female  40.49    4 2.05\n56   25 female  35.05    2 2.98\n57   26 female  57.71    4 2.53\n58   26 female  27.36    4 3.45\n59   27 female  59.37    3 2.80\n60   26 female  21.63    3 2.60\n61   29 female     NA    3 2.05\n62   25 female     NA    7 2.60\n63   37 female  39.50    4 2.73\n64   28 female  42.35    4 3.25\n65   24 female  32.42    3 2.78\n66   29   male  97.63    4 2.93\n67   28   male 131.51    3 3.08\n68   26   male     NA    4 3.33\n69   27   male     NA    5 4.05\n70   29   male     NA    2 3.65\n71   27   male 140.53    2 3.15\n72   26   male     NA    3 3.33\n73   28   male     NA    3 3.98\n74   22   male  90.88    5 4.48\n75   29   male 148.24    5 3.00\n76   29   male 132.24    4 3.00\n77   27   male  82.43    4 3.25\n78   26   male  73.43    4 4.28\n79   35   male     NA    2 3.13\n80   27   male 100.49    4 3.83\n81   25   male  94.31    4 3.98\n82   27   male  72.53    2 4.13\n83   30   male 133.35    4 3.73\n84   27   male  59.77    4 3.28\n85   30   male  91.83    4 2.85\n86   29   male  82.13    3 3.28\n87   30   male 172.15    3 3.70\n88   29   male 228.17    2 3.03\n89   27   male 133.70    3 3.38\n90   27   male  89.24    4 2.88\n91   28   male  88.62    3 3.20\n92   28   male  86.83    4 3.40\n93   25   male 138.65    4 3.70\n94   33   male  59.75    4 3.50\n95   28   male  46.30    3 2.58\n96   31   male 107.02    3 2.90\n97   24   male  60.16    2 3.00\n98   26   male     NA    4 3.35\n99   27   male 107.71    3 2.63\n100  23   male  99.64    2   NA\n101  32   male 131.51    3   NA\n102  29   male  91.94    4 4.05\n103  25   male  53.67    3 3.43\n104  25   male     NA    4 4.28\n105  27 female     NA    4 3.00\n106  27 female  59.24    2 3.10\n107  30 female  28.03    5 3.13\n108  28 female  33.38    5 2.83\n109  26 female  53.31    4 2.78\n110  28 female  27.53    4 2.33\n111  29 female  16.89    4 2.68\n112  25 female  51.53    4 2.88\n113  26 female  37.15    4 2.53\n114  27 female  50.55    2 3.80\n115  28 female     NA    4 3.48\n116  28 female  41.35    5 3.15\n117  29 female  64.66    5 4.38\n118  24 female  37.95    2 3.73\n119  27 female  54.26    4 3.80\n120  27 female     NA    4 2.60\n121  27 female 113.41    4 3.38\n122  29 female  41.35    3 3.13\n\n\nI am overwhelmed with data. So it will be important to find ways to target the data that we want. There are several ways we can do this!\nBecause a dataset has two different dimensions, we have to use two coordinates to index the dataset - one coordinate for the row(s) that we want to focus on, and one coordinate for the column(s) that we want to focus on.\n\n\n\nIndexing an Entire Dataset\nBecause a dataset has two different dimensions, we have to use two coordinates to index the dataset - one coordinate for the row(s) that we want to focus on, and one coordinate for the column(s) that we want to focus on.\n\ndata # this reports the entire dataset. In the example to the right, I‚Äôve typed in haas (since this is the name of the dataset in this example) and see the dataset reported.\ndata[i, j] # this code returns a specific row (i), and a specific column (j). The convention is to use the letter i for a row first, then j for a column [you can remember this order as RC Car, or R is Cool]. For example\n\nhaas[2,3]\n\n[1] 143.89\n\n\nShows me that R has highlighted the second row and third column of the dataset - the second person‚Äôs testosterone level is 143.89 units.\n\ndata[ , j] # if you leave a blank for the rows, then R will return all of the rows, and whatever column you specify. This can be good for looking at a specific variable for all individuals. For example, the following code returns all of the testosterone data (the third column).\n```{r}\nhaas[,3]\n```\n\ndata[i, ] # ¬†if you leave a blank for the column, then you would see all of the columns for a specific row. This can be good for looking at a specific individual‚Äôs entire dataset; such as all of participant 2‚Äôs data below.\n\nhaas[2,]\n\n  age  sex   test ideo NPI\n2  NA male 143.89   NA 4.4\n\n\nhaas[i:i, c(j, j)] # you can adapt this code to give a range of values too. for example, if I want to see rows 4-10 and columns 1 and 3, I would run the following code.\n\nhaas[4:10, c(1,3)]\n\n   age  test\n4   30    NA\n5   28    NA\n6   33    NA\n7   NA    NA\n8   NA    NA\n9   NA 77.95\n10  NA    NA\n\n\n\n\n\nIndexing a Single Variable\n\ndata$variable # You can also use the $ (dollar sign) in R to reference a single variable from a dataset. This is very useful, because you can use the name of the variable instead of the numerical index. So, for example, if I want to highlight the testosterone levels of the haas dataset, I would run the following :\n\nhaas$test\n\n  [1]     NA 143.89     NA     NA     NA     NA     NA     NA  77.95     NA\n [11] 126.29  59.48  89.45  82.80  97.39  54.80  46.07     NA  87.40  85.01\n [21]     NA     NA 102.86  73.60     NA  90.68  44.70     NA  77.61  57.20\n [31]  49.92     NA     NA  85.01  74.86 125.89  77.07     NA  30.54  73.76\n [41]  65.61  51.23  85.17     NA  57.14  65.31  53.07 104.65  90.32  24.71\n [51]  20.99     NA     NA   5.51  40.49  35.05  57.71  27.36  59.37  21.63\n [61]     NA     NA  39.50  42.35  32.42  97.63 131.51     NA     NA     NA\n [71] 140.53     NA     NA  90.88 148.24 132.24  82.43  73.43     NA 100.49\n [81]  94.31  72.53 133.35  59.77  91.83  82.13 172.15 228.17 133.70  89.24\n [91]  88.62  86.83 138.65  59.75  46.30 107.02  60.16     NA 107.71  99.64\n[101] 131.51  91.94  53.67     NA     NA  59.24  28.03  33.38  53.31  27.53\n[111]  16.89  51.53  37.15  50.55     NA  41.35  64.66  37.95  54.26     NA\n[121] 113.41  41.35\n\n\ndata$variable[i] # We can then use indexing to narrow this down. Because a variable only has one dimension (it‚Äôs just a collection of individuals; not rows and individuals) I only need to use one coordinate to index the specific individual(s) I want to find.\n\n\nhaas$test[2]\n\n[1] 143.89\n\n\n\ndata$variable[i:i] # Can be used to find a range of individuals. These numbers need to be sequential for this code to work.\n\nhaas$test[1:3]\n\n[1]     NA 143.89     NA\n\n\ndata$variable[c(i,i,i)] # If you want to find individuals who are not next to each other, you need to use the c (combine) function to combine multiple coordinates together. You can have as many coordinates here as you want. For example :¬†\n\nhaas$test[c(2,3,14:18, 116:118)]\n\n [1] 143.89     NA  82.80  97.39  54.80  46.07     NA  41.35  64.66  37.95\n\n\n\n\n\nTest Yourself!\nOkay, practice time. Use the haas dataset and your knowledge of indexing to identify what R would show if you typed in the following commands (no R required)\n\nhaas$age[47]\nhaas$NPI[1:3]\nhaas[51,2]\nhaas[60, ]\nhaas[ , 6]\n\n\n\n\n\n\n\nAnswer Key\n\n\n\n\n\n\n28\n3.43 4.40 3.13\nfemale\n26 female 21.63 3 2.6\nyou would get an error; there is no 6th column.\n\n\n\n\n\n\n\nVideos : How to Navigate Datasets in R\nLet‚Äôs get some more practice with some actual data. Before we learn how to import data in R, we can work with a super exciting dataset that is already part of the R program - a dataset on the weights of chickens (chkwt).\nWatch the two videos below to see how I navigate this dataset; here‚Äôs a link to the RScript that I use in the videos.¬†\n\nVideo : Checking Datasets in R\n\n\nlength() : counts the number of objects (variables) in a dataset (or any object)\nnrow() : counts the number of rows (participants) in a dataset\n\nhead() : looks at the first six rows of a dataset\n\n\nVideo : Navigating Datasets with Indexing\n\n\nUse this video to answer the check-in questions below.",
    "crumbs": [
      "Lab Assignments",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#check-in-navigating-variables-and-datasets-with-indexing",
    "href": "chapters/2R_Data.html#check-in-navigating-variables-and-datasets-with-indexing",
    "title": "Data",
    "section": "Check-In : Navigating Variables and Datasets with Indexing",
    "text": "Check-In : Navigating Variables and Datasets with Indexing\nUse the fake dataset below and your knowledge of navigating datasets with indexing to identify what answer R would give if you gave it the following code. (Note : no R is needed to complete this problem).\n\ndata\n\n  StudentID favDrink age\n1         1     boba  20\n2         2     boba  19\n3         3     boba  54\n4         4   coffee  22\n5         5    water  38",
    "crumbs": [
      "Lab Assignments",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#the-.csv-file",
    "href": "chapters/2R_Data.html#the-.csv-file",
    "title": "Data",
    "section": "The .csv File",
    "text": "The .csv File\n\nDefinition : The .csv File\nAs a researcher, you will work with data that you (or other researcher friends) have collected. The .csv file (csv stands for comma separated variables) is one of the most common formats for storing data that you will encounter. You‚Äôve probably encountered this before, and likely have opened this file type in a program like excel or google sheets. But in this class, we‚Äôll learn to load these files directly into R. Using R has two advantages :\n\nR is way more powerful than excel or Google Sheets.\nR allows us to document all of our steps. This semester, we‚Äôll learn how to make changes to the dataset (e.g., changing the names of a variable; removing bad data; transforming data). It‚Äôs important to be completely transparent about these changes, and doing these changes in R (with an R Script!) will ensure that we document our steps for our future selves / other researchers.\n\n\n\nVideos : How to Load Datasets in R\nThere are two different ways to load a data file into R : one way (‚Äúthe point and click method‚Äù) involves clicking some boxes, like most of y‚Äôall are used to doing. The second way involves typing in an R command. Below are videos that highlight each method.\n\n\n\n\n\n\nImportant\n\n\n\nRegardless of which method you use, there are three things you want to check every time you load data : change the name of the dataset (to make it something simple to type and memorable); check the headers (make sure the variables have names, since sometimes), and set stringAsFactors = TRUE (which will automatically convert all your string variables into categorical factor variables, which is almost always what you will want to do in this class.\nThese instructions are highlighted because students often forget. So note the importance! They are important steps!!!\n\n\n\nVideo : Importing Data with the ‚ÄúPoint and Click‚Äù Method and Console Method\n\n\nthe ‚Äúpoint and click‚Äù method of loading data\nthe console / Rscript method of loading data\n\n\n\nVideo : For Posit Users : working with projects and loading data in the cloud.\n{{&lt; video https://youtu.be/HOhINtpyjT4&gt; }}\n\nposit.cloud users! You will need an extra step that folks using posit.cloud have to use to upload datasets to the cloud (and then import them).",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#the-dataframe",
    "href": "chapters/2R_Data.html#the-dataframe",
    "title": "Data",
    "section": "The Dataframe",
    "text": "The Dataframe\n\nDefinition : Rows and Columns\nAs a researcher, you‚Äôll be interested in understanding not only one variable at a time, but will be interested in a dataset - multiple variables about an individual that are organized - in order to see how variables are related to each other (remember : this is a function of the linear model).\nThe datasets in our class will be stored on Dropbox; you can find a link to this on bCourses (see below).\n\n\n\n\n\nYou‚Äôll learn how to load these datasets later in this lecture. For now, what is a dataset?\nA dataset is really a dataframe - a two-dimensional way to organize data - and takes the following structure in this class.\n\nthe rows define the individual in the dataset.¬†rows go across horizontally, like a rowboat going across a lake.\nthe columns define the variables in the dataset. ¬†go up and down vertically; like what might support a bridge.\n\nLook at the example below - again from our budding MBAs in the Haas program. What do you observe about the rows and columns? What does this tell you about the dataset?\n\n\nIn the example dataframe above - I see 5 rows (representing 5 individuals) and five columns (representing five variables like the person‚Äôs age, their sex, their testosterone levels, political ideology, and their NPI (Narcissism) score.¬† or their Race, etc.) Note that the names of the variables do not count as a row, since these are not individuals in the dataset, and you would need to know more about the dataset to know that ideo = political ideology, or test = testosterone. I also see that R is helpfully telling me that this is only a snapshot of the entire dataset - the whole dataframe has 122 entries (rows), meaning that there‚Äôs 122 MBA students in this dataset, and 5 total columns (which we can all see here.)\nAs a researcher, you have access to an entire dataset (either collected by you or another researcher) that organizes multiple variables for each individual. This semester, we‚Äôll work with a variety of datasets on different psychological topics - not just haas students.\n\n\nDefinition : Indexing\nThe dataset gives us access to all the individual rows and columns at once, we will often want to focus on one specific variable (or individual) at a time. Indexing refers to a flexible method of selecting a specific set of data from a larger collection. Previously‚Äô we‚Äôve seen indexing when asking R to produce a large set of numbers; for example asking it to count from 1 to 100.\n\n1:100\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\n\nThe indexing shows up as brackets next to the actual data, and is way for R to index that the [1]st data entry is the number 1, the [24]th entry is the number 24, and so on.\nWhen I ask R to show me the dataset haas, the output can be overwhelming. Below is what R shows you when you ask to see the haas dataset. And this is a relatively small dataset with just 122 individuals (rows) and five variables (columns).\n\nhaas\n\n    age    sex   test ideo  NPI\n1    NA   male     NA   NA 3.43\n2    NA   male 143.89   NA 4.40\n3    NA   male     NA   NA 3.13\n4    30   male     NA    4   NA\n5    28   male     NA    4 3.00\n6    33 female     NA    5   NA\n7    NA   male     NA   NA 3.05\n8    NA   male     NA   NA   NA\n9    NA   male  77.95   NA   NA\n10   NA   male     NA   NA 3.63\n11   26   male 126.29    3 3.95\n12   31   male  59.48    5 3.08\n13   27   male  89.45    4 3.83\n14   27   male  82.80    3 3.23\n15   28   male  97.39    4 3.80\n16   30   male  54.80    4 1.80\n17   28   male  46.07    4 3.68\n18   24   male     NA    4 3.48\n19   32   male  87.40    3 2.73\n20   25   male  85.01    4 3.40\n21   27   male     NA    3 2.95\n22   25   male     NA    4 3.65\n23   24   male 102.86    3 2.88\n24   28   male  73.60    3 2.50\n25   27   male     NA    2 3.13\n26   29   male  90.68    4 2.75\n27   28   male  44.70    3 3.00\n28   29   male     NA    4 3.15\n29   30   male  77.61    4 3.30\n30   26   male  57.20    5 3.20\n31   31   male  49.92    4 2.43\n32   28   male     NA    3 3.13\n33   32   male     NA    5   NA\n34   27   male  85.01    2 3.33\n35   32   male  74.86    2 2.88\n36   27   male 125.89    3 2.55\n37   29   male  77.07    4 3.35\n38   30   male     NA    4 3.30\n39   26   male  30.54    4 3.28\n40   27   male  73.76    3 3.08\n41   32   male  65.61    3 2.48\n42   29   male  51.23    4 2.78\n43   28   male  85.17    3 4.58\n44   28   male     NA    3 2.53\n45   29   male  57.14    2 2.78\n46   30   male  65.31    4 2.88\n47   28   male  53.07    4   NA\n48   28   male 104.65    3 3.43\n49   31   male  90.32    3 2.48\n50   NA female  24.71   NA 3.50\n51   26 female  20.99    3 2.40\n52   27 female     NA    4 3.28\n53   28 female     NA    3 3.63\n54   28 female   5.51    5 3.13\n55   27 female  40.49    4 2.05\n56   25 female  35.05    2 2.98\n57   26 female  57.71    4 2.53\n58   26 female  27.36    4 3.45\n59   27 female  59.37    3 2.80\n60   26 female  21.63    3 2.60\n61   29 female     NA    3 2.05\n62   25 female     NA    7 2.60\n63   37 female  39.50    4 2.73\n64   28 female  42.35    4 3.25\n65   24 female  32.42    3 2.78\n66   29   male  97.63    4 2.93\n67   28   male 131.51    3 3.08\n68   26   male     NA    4 3.33\n69   27   male     NA    5 4.05\n70   29   male     NA    2 3.65\n71   27   male 140.53    2 3.15\n72   26   male     NA    3 3.33\n73   28   male     NA    3 3.98\n74   22   male  90.88    5 4.48\n75   29   male 148.24    5 3.00\n76   29   male 132.24    4 3.00\n77   27   male  82.43    4 3.25\n78   26   male  73.43    4 4.28\n79   35   male     NA    2 3.13\n80   27   male 100.49    4 3.83\n81   25   male  94.31    4 3.98\n82   27   male  72.53    2 4.13\n83   30   male 133.35    4 3.73\n84   27   male  59.77    4 3.28\n85   30   male  91.83    4 2.85\n86   29   male  82.13    3 3.28\n87   30   male 172.15    3 3.70\n88   29   male 228.17    2 3.03\n89   27   male 133.70    3 3.38\n90   27   male  89.24    4 2.88\n91   28   male  88.62    3 3.20\n92   28   male  86.83    4 3.40\n93   25   male 138.65    4 3.70\n94   33   male  59.75    4 3.50\n95   28   male  46.30    3 2.58\n96   31   male 107.02    3 2.90\n97   24   male  60.16    2 3.00\n98   26   male     NA    4 3.35\n99   27   male 107.71    3 2.63\n100  23   male  99.64    2   NA\n101  32   male 131.51    3   NA\n102  29   male  91.94    4 4.05\n103  25   male  53.67    3 3.43\n104  25   male     NA    4 4.28\n105  27 female     NA    4 3.00\n106  27 female  59.24    2 3.10\n107  30 female  28.03    5 3.13\n108  28 female  33.38    5 2.83\n109  26 female  53.31    4 2.78\n110  28 female  27.53    4 2.33\n111  29 female  16.89    4 2.68\n112  25 female  51.53    4 2.88\n113  26 female  37.15    4 2.53\n114  27 female  50.55    2 3.80\n115  28 female     NA    4 3.48\n116  28 female  41.35    5 3.15\n117  29 female  64.66    5 4.38\n118  24 female  37.95    2 3.73\n119  27 female  54.26    4 3.80\n120  27 female     NA    4 2.60\n121  27 female 113.41    4 3.38\n122  29 female  41.35    3 3.13\n\n\nI am overwhelmed with data. So it will be important to find ways to target the data that we want. There are several ways we can do this!\nBecause a dataset has two different dimensions, we have to use two coordinates to index the dataset - one coordinate for the row(s) that we want to focus on, and one coordinate for the column(s) that we want to focus on.\n\n\nIndexing an Entire Dataset\nBecause a dataset has two different dimensions, we have to use two coordinates to index the dataset - one coordinate for the row(s) that we want to focus on, and one coordinate for the column(s) that we want to focus on.\n\ndata # this reports the entire dataset. In the example to the right, I‚Äôve typed in haas (since this is the name of the dataset in this example) and see the dataset reported.\ndata[i, j] # this code returns a specific row (i), and a specific column (j). The convention is to use the letter i for a row first, then j for a column [you can remember this order as RC Car, or R is Cool]. For example\n\nhaas[2,3]\n\n[1] 143.89\n\n\nShows me that R has highlighted the second row and third column of the dataset - the second person‚Äôs testosterone level is 143.89 units.\n\ndata[ , j] # if you leave a blank for the rows, then R will return all of the rows, and whatever column you specify. This can be good for looking at a specific variable for all individuals. For example, the following code returns all of the testosterone data (the third column).\n```{r}\nhaas[,3]\n```\n\ndata[i, ] # ¬†if you leave a blank for the column, then you would see all of the columns for a specific row. This can be good for looking at a specific individual‚Äôs entire dataset; such as all of participant 2‚Äôs data below.\n\nhaas[2,]\n\n  age  sex   test ideo NPI\n2  NA male 143.89   NA 4.4\n\n\nhaas[i:i, c(j, j)] # you can adapt this code to give a range of values too. for example, if I want to see rows 4-10 and columns 1 and 3, I would run the following code.\n\nhaas[4:10, c(1,3)]\n\n   age  test\n4   30    NA\n5   28    NA\n6   33    NA\n7   NA    NA\n8   NA    NA\n9   NA 77.95\n10  NA    NA\n\n\n\n\n\nIndexing a Single Variable\n\ndata$variable # You can also use the $ (dollar sign) in R to reference a single variable from a dataset. This is very useful, because you can use the name of the variable instead of the numerical index. So, for example, if I want to highlight the testosterone levels of the haas dataset, I would run the following :\n\nhaas$test\n\n  [1]     NA 143.89     NA     NA     NA     NA     NA     NA  77.95     NA\n [11] 126.29  59.48  89.45  82.80  97.39  54.80  46.07     NA  87.40  85.01\n [21]     NA     NA 102.86  73.60     NA  90.68  44.70     NA  77.61  57.20\n [31]  49.92     NA     NA  85.01  74.86 125.89  77.07     NA  30.54  73.76\n [41]  65.61  51.23  85.17     NA  57.14  65.31  53.07 104.65  90.32  24.71\n [51]  20.99     NA     NA   5.51  40.49  35.05  57.71  27.36  59.37  21.63\n [61]     NA     NA  39.50  42.35  32.42  97.63 131.51     NA     NA     NA\n [71] 140.53     NA     NA  90.88 148.24 132.24  82.43  73.43     NA 100.49\n [81]  94.31  72.53 133.35  59.77  91.83  82.13 172.15 228.17 133.70  89.24\n [91]  88.62  86.83 138.65  59.75  46.30 107.02  60.16     NA 107.71  99.64\n[101] 131.51  91.94  53.67     NA     NA  59.24  28.03  33.38  53.31  27.53\n[111]  16.89  51.53  37.15  50.55     NA  41.35  64.66  37.95  54.26     NA\n[121] 113.41  41.35\n\n\ndata$variable[i] # We can then use indexing to narrow this down. Because a variable only has one dimension (it‚Äôs just a collection of individuals; not rows and individuals) I only need to use one coordinate to index the specific individual(s) I want to find.\n\n\nhaas$test[2]\n\n[1] 143.89\n\n\n\ndata$variable[i:i] # Can be used to find a range of individuals. These numbers need to be sequential for this code to work.\n\nhaas$test[1:3]\n\n[1]     NA 143.89     NA\n\n\ndata$variable[c(i,i,i)] # If you want to find individuals who are not next to each other, you need to use the c (combine) function to combine multiple coordinates together. You can have as many coordinates here as you want. For example :¬†\n\nhaas$test[c(2,3,14:18, 116:118)]\n\n [1] 143.89     NA  82.80  97.39  54.80  46.07     NA  41.35  64.66  37.95",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#test-yourself",
    "href": "chapters/2R_Data.html#test-yourself",
    "title": "Data",
    "section": "Test Yourself!",
    "text": "Test Yourself!\nOkay, practice time. Use the haas dataset and your knowledge of indexing to identify what R would show if you typed in the following commands (no R required)\n\nhaas$age[47]\nhaas$NPI[1:3]\nhaas[51,2]\nhaas[60, ]\nhaas[ , 6]\n\n\n\n\n\n\n\nAnswer Key\n\n\n\n\n\n\n28\n3.43 4.40 3.13\nfemale\n26 female 21.63 3 2.6\nyou would get an error; there is no 6th column.\n\n\n\n\n\nVideos : How to Navigate Datasets in R\nLet‚Äôs get some more practice with some actual data. Before we learn how to import data in R, we can work with a super exciting dataset that is already part of the R program - a dataset on the weights of chickens (chkwt).\nWatch the two videos below to see how I navigate this dataset; here‚Äôs a link to the RScript that I use in the videos.¬†\n\nVideo : Checking Datasets in R\n\n\nlength() : counts the number of objects (variables) in a dataset (or any object)\nnrow() : counts the number of rows (participants) in a dataset\n\nhead() : looks at the first six rows of a dataset\n\n\nVideo : Navigating Datasets with Indexing\n\n\nUse this video to answer the check-in questions below.\n\n\n\n\nCheck-In : Navigating Variables and Datasets with Indexing\nUse the fake dataset below and your knowledge of navigating datasets with indexing to identify what answer R would give if you gave it the following code. (Note : no R is needed to complete this problem).\n\ndata\n\n  StudentID favDrink age\n1         1     boba  20\n2         2     boba  19\n3         3     boba  54\n4         4   coffee  22\n5         5    water  38",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#r-code-creating-variables-in-r",
    "href": "chapters/2R_Data.html#r-code-creating-variables-in-r",
    "title": "Data",
    "section": "R Code : Creating Variables in R",
    "text": "R Code : Creating Variables in R",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#numeric-variables-in-r",
    "href": "chapters/2R_Data.html#numeric-variables-in-r",
    "title": "Data",
    "section": "Numeric Variables in R",
    "text": "Numeric Variables in R\n\n\n\n\n\n\n\nCode\nDescription\n\n\n\n\nvariable &lt;- c(#, #, #, #, etc.)\ntired &lt;- c(1,2,3,4)\nvariable = an object that you will define in R\n&lt;- = ‚Äúassign‚Äù; tells R to save whatever comes on the right to whatever object is on the left.\nc = combine : tells R to combine whatever happens in the parentheses\n() = parentheses to group related terms\n# = what you store in the variable; each item should be separated by a comma and space.\n\n\nhist(dat$variable)\nFor continuous variables : draws a histogram.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#string-variables",
    "href": "chapters/2R_Data.html#string-variables",
    "title": "Data",
    "section": "String Variables",
    "text": "String Variables\n\n\n\n\n\n\n\nvariable &lt;- c(‚Äúname1‚Äù, ‚Äúname2‚Äù, ‚Äúname1‚Äù, etc.)\nemotion &lt;- c(‚Äúsad‚Äù, ‚Äúhappy‚Äù, ‚Äúsad‚Äù)\nvariable = an object that you will define in R\n&lt;- = ‚Äúassign‚Äù; tells R to save whatever comes on the right to whatever object is on the left.\nc = combine : tells R to combine whatever happens in the parentheses\n() = parentheses to group related terms\n# = what you store in the variable; each item should be separated by a comma and space.\n\n\nas.factor(variable)\nas.factor(emotion)\nas.factor() # converts a string variable into a categorical factor\n\n\nvariable &lt;- as.factor(variable)\n# ‚Äúsaves‚Äù this conversion as the original variable\n\n\nplot(dat$variable)\nFor categorical variables : draws a barplot. For continuous variables :¬† illustrates values of the variable (y-axis) as a function of their index (x-axis).",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#r-commands-for-importing-and-navigating-data",
    "href": "chapters/2R_Data.html#r-commands-for-importing-and-navigating-data",
    "title": "Data",
    "section": "R Commands for Importing and Navigating Data",
    "text": "R Commands for Importing and Navigating Data\n\n\n\n\n\n\n\nR Command\nWhat it Does\n\n\ndat &lt;- read.csv(‚Äúpath/file.csv‚Äù, stringsAsFactors = T)\nloads the data file into R (or use the ‚Äúpoint & click method‚Äù); sets string variables to be categorical factor variables.\n\n\nhead(dat)\nlooks at the first 6 rows of the data file\n\n\ntail(dat)\nlooks at the last 6 rows of the data file\n\n\nnrow(dat)\ndisplays the number of rows (each row = an individual)\n\n\nncol(dat)\ndisplays the number of columns (each column = a variable)\n\n\nnames(dat)\ndisplays the names of the object (column names = names of variables)\n\n\ndat$variable\ndisplays the variable from a dataset\n\n\ndat$variable[i]\ndisplays the individual row [i] from the variable\n\n\ndat[i, j]\ndisplays an individual row [i] and column [j] from the dataset",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "chapters/2R_Data.html#r-commands-for-visualizing-data",
    "href": "chapters/2R_Data.html#r-commands-for-visualizing-data",
    "title": "Data",
    "section": "R Commands for Visualizing Data",
    "text": "R Commands for Visualizing Data\n\n\n\n\n\n\n\nR Command\nWhat it Does\n\n\nsummary(dat)\nReports descriptive statistics for all variables in the dataset.\n\n\nsummary(dat$variable)\nReports descriptive statistics for a categorical variable (frequency / number of individuals in each level) or continuous variable (mean, range, etc.)\n\n\nas.numeric(dat$variable)\nMakes the variable numeric (for continuous graphs)\n\n\nas.factor(dat$variable)\nMakes the variable a categorical factor (for categorical graphs)\n\n\ndat$variable &lt;- as.factor(dat$variable)\nAssigns the as.factor output to the original variable. (In other words, this saves your new categorical factor variable by overwriting the old one.)\n\n\nplot(dat$variable)\nFor categorical variables : draws a barplot. For continuous variables :¬† illustrates values of the variable (y-axis) as a function of their index (x-axis).\n\n\nhist(dat$variable)\nFor continuous variables : draws a histogram.\n\n\npar(mfrow = c(i, j))\nSplits your graphics window into i rows and j columns.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html",
    "href": "1L_Whystats.html",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "",
    "text": "14 Check-In, Agenda and Announcements",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#welcome-and-check-in",
    "href": "1L_Whystats.html#welcome-and-check-in",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "14.1 Welcome and Check-In!",
    "text": "14.1 Welcome and Check-In!\naccess these lecture notes on bCourses!\nclick on this link to check-in (or visit : tinyurl.com/first101class)",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#course-announcements",
    "href": "1L_Whystats.html#course-announcements",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "14.2 Course Announcements",
    "text": "14.2 Course Announcements\n\nSection Swap : post on bCourses to find someone to swap with.\nWaitlisted Students : Thanks for your patience! Nothing I can do :(\nJoin the Class Discord : link on bCourses\nNext Week :\n\nAttend Discussion Section\nComplete Lab 1 (will start in lecture!)\nRead Chapter 2\nComplete Quiz 2",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#agenda",
    "href": "1L_Whystats.html#agenda",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "14.3 Agenda",
    "text": "14.3 Agenda\n\n2:10 - 2:20 | Check-In & Announcements\n2:20 - 3:10 | RECAP : Science as Prediction\n3:10 - 3:20 | Break #1\n3:20 - 3:50 | Positivism and Linear Models\n3:50 - 3:55 | Break #2\n3:55 - 4:30 | In R : Defining Variables\n4:30 - 5:00 | So you‚Äôre interested in being a researcher / going to graduate school?",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#activity-variables-and-variation-in-the-room",
    "href": "1L_Whystats.html#activity-variables-and-variation-in-the-room",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "15.1 Activity : Variables and Variation in the Room",
    "text": "15.1 Activity : Variables and Variation in the Room\nClass Activity. Let‚Äôs create a list of variables that we observe in this classroom.\n\nhair style\nhair color\nethnicity\neye color\nbody size\ndevices\ngender\nidentity\n\naffect : feeling of affinity for fitting in w/ your culture.\nbehavior : how you express it\ncognition : self-perception (do you think about this identity / perceive it in others?)\n\nglasses\nhats vs.¬†no hats\n\nKey Terms. From the readings.\n\nAffect, Behavior, Cognition\nBetween vs.¬†Within-Person Variation\n\n[7 Minutes] Answer the following questions with your buddy.\nFind a buddy in the class! (There‚Äôs a discord thread if you prefer to communicate with someone online.)\n\nIf you could have dinner with anyone in the world (living or dead) who would it be?\nWhy are you a psychology major? What interests you about people (or non-human animals)?\nHow would you label this interest as a variable?\n\nAre you interested in the between-person or within-person version of this variable?\nAre you interested in the Affective, Behavioral, or Cognitive aspect of this variable?\n\n\nStudent Examples\n\nHamza : motivation for goal changes over time [within person - starts as affect ‚Äì&gt; behavior]\nMax : emotional effect of languages (how much the same word in a western language influences someone compared to that word in an eastern language) [between person - comparing people who speak one language to people who speak another.]\nCamille : Moral regret (you did something bad and feel bad about it) and how that changes over time.",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#thinking-about-programming-free-association-activity",
    "href": "1L_Whystats.html#thinking-about-programming-free-association-activity",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "16.1 Thinking about Programming (Free Association Activity)",
    "text": "16.1 Thinking about Programming (Free Association Activity)\n\nClose your eyes\nTake a deep breath (inhale / exhale)\nVisualize an image based on the word that you hear me say.\nWhat do you observe?",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#r-is-your-friend",
    "href": "1L_Whystats.html#r-is-your-friend",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "16.2 R is Your Friend",
    "text": "16.2 R is Your Friend\n\n16.2.1 The Console\nThe console is where R does its work.\n\nACTIVITY : Look at the image below. What do you see? What makes sense / what seems confusing?\n\n\n\n16.2.2 \n\n\n16.2.3 Some Additional Notes on R Studio and the Source File (.R)\nIn this class, we‚Äôll be using RStudio. RStudio is an IDE (Integrated Development Environment) that includes the console along with other useful windows and tools.\n\nThe Console is at the bottom left of the IDE. Hi console!\nThe R script is at the top left of the IDE, and is a document that you use to write (and organize) code. You will want to do most of your work in the R script, and feel an appropriate level of anxiety when you notice that your Rscript is unsaved (as indicated by the red text and *).\nThe Environment is at the top right of the IDE, and shows you all of the ‚Äúobjects‚Äù that you have defined in R.\nThe File Window is at the bottom right of the IDE, and shows you the files. Note that there are tabs here for Plots (where graphs will pop up), Packages (things you can download to give R extra features), a Help viewer (sometimes very useful!).\n\n\n\n\n16.2.4 ACTIVTY : open up RStudio\n\nType some math into an Rscript, and send it to the console. Yeah, you are programming!\nDefine two variables in R - one numeric and one string variable (these can be unrelated to your project topic!) Make sure to collect at least ten data points for each variable, and show that you successfully defined the variable in R by ‚Äúprinting‚Äù it in R. Yeah, you‚Äôre programming!\nCopy/paste (or screenshot) your code and output from the question above to a document to answer Lab 1, Question 1.\n\n\n\n16.2.5",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#in-r-variables-and-variation",
    "href": "1L_Whystats.html#in-r-variables-and-variation",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "16.3 In R : Variables and Variation",
    "text": "16.3 In R : Variables and Variation\n\n16.3.1 Numeric Variables in R\n\n\n\n\n\n\n\nCode\nDescription\n\n\n\n\nvariable &lt;- c(#, #, #, #, etc.)\n\n\n\ntired &lt;- c(1,2,3,4)\nvariable = an object that you will define in R\n&lt;- = ‚Äúassign‚Äù; tells R to save whatever comes on the right to whatever object is on the left.\nc = combine : tells R to combine whatever happens in the parentheses\n() = parentheses to group related terms\n# = what you store in the variable; each item should be separated by a comma and space.\n\n\nhist(dat$variable)\nFor continuous variables : draws a histogram.\n\n\n\n\n\n16.3.2 Example : Creating Numeric Variables\n\ncounting &lt;- c(1,2,3,4,5) # the numbers one through five\nprint(counting) # one way to \"print\" the variable\n\n[1] 1 2 3 4 5\n\ncounting # another way to \"print\" the variable\n\n[1] 1 2 3 4 5\n\nhist(counting) # a way to graph the variable (a histogram)\n\n\n\n\n\n\n\n\n\n\n16.3.3 String Variables\n\n\n\n\n\n\n\nvariable &lt;- c(‚Äúname1‚Äù, ‚Äúname2‚Äù, ‚Äúname1‚Äù, etc.)\n\nemotion &lt;- c(‚Äúsad‚Äù, ‚Äúhappy‚Äù, ‚Äúsad‚Äù)\nvariable = an object that you will define in R\n&lt;- = ‚Äúassign‚Äù; tells R to save whatever comes on the right to whatever object is on the left.\nc = combine : tells R to combine whatever happens in the parentheses\n() = parentheses to group related terms\n# = what you store in the variable; each item should be separated by a comma and space.\n\n\nas.factor(variable)\n\nas.factor(emotion)\nas.factor() # converts a string variable into a categorical factor\n\n\nvariable &lt;- as.factor(variable)\n# ‚Äúsaves‚Äù this conversion as the original variable\n\n\nplot(dat$variable)\nFor categorical variables : draws a barplot. For continuous variables :¬† illustrates values of the variable (y-axis) as a function of their index (x-axis).\n\n\n\n\n\n16.3.4 Example : Creating Non-Numeric Variables\nThe data below describe the categories of family laundry that was hanging in my apartment to dry.\n\nlaundryhang &lt;- c(\"shirt\", \"shirt\", \"leggings\", \"leggings\", \"shirt\", \n             \"shirt\", \"leggings\", \"pants\", \"sweater\", \"sweater\") # defining a string variable\nprint(laundryhang)\n\n [1] \"shirt\"    \"shirt\"    \"leggings\" \"leggings\" \"shirt\"    \"shirt\"   \n [7] \"leggings\" \"pants\"    \"sweater\"  \"sweater\" \n\nlaundryhang # another way to \"print\" the variable\n\n [1] \"shirt\"    \"shirt\"    \"leggings\" \"leggings\" \"shirt\"    \"shirt\"   \n [7] \"leggings\" \"pants\"    \"sweater\"  \"sweater\" \n\nlaundryhang &lt;- as.factor(laundryhang) # changing the format of the sting variable into a categorical factor\nplot(laundryhang) # a way to graph the non-numeric variable",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#break-time-meet-back-at-325",
    "href": "1L_Whystats.html#break-time-meet-back-at-325",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "16.4 Break Time: Meet Back at 3:25",
    "text": "16.4 Break Time: Meet Back at 3:25",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#prediction-power",
    "href": "1L_Whystats.html#prediction-power",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "16.5 Prediction & Power",
    "text": "16.5 Prediction & Power\n\n16.5.1 Predictions in Real Life\n\nWill it rain tonight?\n\nKnowledge (what information did you use to make the prediction)?\nPower (ways your predictions influence future behaviors)\n\nProfessor predicted that attendance would be HIGH today, but will dip later in the semester :(\n\nKnowledge (what information did you use to make the prediction)?\n\nfirst day of the semester; students are STOKED and MINIMALLY STRESSED.\npattern seen in almost every past semester.\nFriday afternoons are basiscally the weekend.\n\nPower (ways your predictions influence future behaviors)\n\nprepared; made sure to arrive on time; tucked in shirt.\nremind students to attend with weekly announcements.\ncreate a positive classroom environment where students feel supported and like attendance is helpful.\ncreated an example that serves as meta-commentary on the importance of attendance.\n\nWas Professor Valid? TBD! &lt;3\n\nWork on Lab 1, Question 1. [In Lecture] What‚Äôs a prediction about people that you made today? What information did you use to make this prediction? How did (or could) you use this prediction to influence outcomes? Were you valid in your predictions?\n\n\n\n16.5.2 Scientific Predictions\nPsychological scientists seek to better understand variation, in order to help make valid predictions in ways that help exert power over our environments.\n\n\n\nTopic\nOther Questions We Might Ask?\n\n\n\n\nVideo\n\n\n\n1\n\n\n\n2",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#the-linear-model",
    "href": "1L_Whystats.html#the-linear-model",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "16.6 The Linear Model",
    "text": "16.6 The Linear Model\n\n16.6.1 Definition\nStatistical Model : DV ~ IV1 + IV2 + ‚Ä¶ + IVk + error\n\nDV = dependent variable = the variable you want to predict\nIV = independent variable(s) = the variable(s) you think will predict the DV\n\nk = any number = there can be MANY IVs\nany variable can be an IV or DV - it‚Äôs up to the researcher to choose\n\n~ = a squiggly line / tilde = our model is uncertain (not equal)\nerror = other factors that are not part of your model that would also explain the DV\nWe say: ‚Äúthe DV is a function of‚Ä¶‚Äù; ‚Äúthe DV depends on the IV(s)‚Äù\n\n\n\n16.6.2 Examples\n\nrain ~\nclass quality ~\n\n\n\n16.6.3 Another Example\nKEY IDEA : Linear Models Help Make and Quantify Prediction\n\nwhat information (IV) is related to the DV (predict)\nwhich IV allows us to make the best predictions (effect size)\nthe amount of error in your prediction (error can come from our measures, our models, and maybe is just inherent to science?)",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#work-on-lab-1-predictions-research-questions.",
    "href": "1L_Whystats.html#work-on-lab-1-predictions-research-questions.",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "16.7 Work on Lab 1 : Predictions & Research Questions.",
    "text": "16.7 Work on Lab 1 : Predictions & Research Questions.\n\n16.7.1 On Your Own\nDuring our break, think a little bit about what research questions you might want to address for the project in this class. Below are some ideas to help you get started thinking of a research question if you are feeling stuck!\n\nIs there a real-world issue that you care about? What variables make up this questions?\nWhat is something about people (your friends, parents, classmates) that you think is interesting or confusing? What variables are the focus of this interest or question?\nWhat‚Äôs a future career you might want to pursue with your psychology degree? What‚Äôs a variable that is related to this career? What questions might you ask abut this variable?\n\nQuestion 3 (In Lecture / On Your Own). Get started on the final project by thinking through a research question you might be interested in studying as a psychology researcher. (Totally fine to change this, but great to start focusing on a question.)\n\nWhat is your question? Why do you care about this question (and / or why does this question matter to others)? How interested in this question are you on a scale from 0 (just doing to get credit for this question) to 10 (this is what motivates you to wake up each day and you will answer this question with the energy and passion of 1000 suns)?\nHow do your past experiences and background inform this question?\nWhat is the variable that is the focus of this question? How does this variable relate to affect, behavior, and cognition? Which aspect of this variable are you most interested in focusing on for your project?\nWhat is the between-person form of variation for this variable? What is the within-person form of variation for this variable? Note: for the final project, I strongly recommend focusing on a between-person variation version of the variable for the final project.\nDo you have ideas about what might predict or explain this variable (the answer to your question)? How would you write this out as a linear model?\n\n\n\n16.7.2 Student Examples",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#getting-research-experience-as-an-ra",
    "href": "1L_Whystats.html#getting-research-experience-as-an-ra",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "17.1 Getting Research Experience as an RA",
    "text": "17.1 Getting Research Experience as an RA\n\nRA = Research Assistant\n\nMostly Unpaid Experiences\nSome paid experiences exist!\n\nFrom the berkeley website‚Ä¶\nBusine$$ $chool\nStanford [maybe paid]\nA list a student sent me that they found.\n‚ÄúCold calling‚Äù labs who are doing work you think is cool.\nChat with your TAs / Professors\n\n\nAs an RA :\n\nwork with data : transcribing data; behavioral coding data; recruiting and participants to collect data; setting up psychophysiological recordings; cleaning data; etc.\nother opportunities to gain skills you can demonstrate :\n\nreading & discussing papers\nworking with IRB (institutional review board - an ethics thing)\nanalyzing data ‚Üí presenting research at a conference (poster) or submitting a paper for publication [your golden ticket]\ngeneral mentorship (how to apply to grad school; where to apply; who to talk to & e-mail; etc.)\nNOTE : this work and these skills apply to other work outside of research applications [time management; coordinating schedules; juggling responsibilities; etc.]\n\nget a sense of whether this [work or lab] is for you?\n\ndo you enjoy the work? are you going to look forward to showing up and doing the work / fulfilling the commitment?¬†\nare you working with a horrible monster?\n\nnot responsive\ninconsistent work / no plan for your work\nkind of a bully (emotionally abusive ‚Üí stealing your work)¬†\n\nor are you working with someone who is super cool and a positive influence on mentoring young minds!?!?! [YES!!!!]",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#applying-to-graduate-school",
    "href": "1L_Whystats.html#applying-to-graduate-school",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "17.2 Applying to Graduate School",
    "text": "17.2 Applying to Graduate School\n\nYou are applying to work on research with a specific professor(s) at a school.\n\nShould have a sense of the topic you want to pursue.\nGood to have a narrative about how your past work and studies have prepared you for this topic / demonstrate an enduring interest in the topic.\n\nIndependent Thesis / Research Project :\n\nan official honors‚Äô thesis\nundergraduate research project (e.g., SURF; Psych 101!)\nyour own independent study / advanced work you did as an RA\n\nPersonal Statement : Experiences with Research You Can Write About\n\nI‚Äôm fascinated by people‚Ä¶Over the last year, I worked on an independent research study to better understand‚Ä¶.\nWorking as an RA; your research project; attending / presenting at a conference; etc.\n\n3-4 Letters of Recommendation : folks who can speak personally to your ability to do research.\nClinical Students : some kind of clinical internship / experience üòü\nTalk to people who are doing the thing you want to be doing about their journey\n\n\n17.2.1 The Academic Job Market\nSome Data [Source]\n\n\n\nPhDs get jobs?\n\n\n\nbut not in academia‚Ä¶\n\n\n\n$$$$$$$$",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "1L_Whystats.html#footnotes",
    "href": "1L_Whystats.html#footnotes",
    "title": "13¬† Lecture 1 | Welcome to Psych 101",
    "section": "",
    "text": "Here‚Äôs a link to the article where this headline comes from. These data are a little dated, and I couldn‚Äôt immediately find more recent data - my guess is Meta does not really want to advertise that people are using the product more and more. However, in reports to investors reports consistent growth in metrics like ‚Äúad impressions‚Äù and ‚Äúdaily active users‚Äù. Let me know if you find other sources to show how technology companies are capturing more and more of our attention!‚Ü©Ô∏é\nOscar Grant, Trayvon Martin, Philando Castile, Eric Garner, George Floyd, Tamir Rice, Breonna Taylor, Ahmaud Aubrey, Jacob Blake. Here‚Äôs a more comprehensive list, and here‚Äôs a summary article on policing and race.\n‚Ü©Ô∏é",
    "crumbs": [
      "Lab Assignments",
      "Lectures",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Lecture 1 | Welcome to Psych 101</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html",
    "href": "chapters/3R_Description.html",
    "title": "Description",
    "section": "",
    "text": "Part 1 : Centrality\nCentrality refers to ways that statistics try to reduce the complexity of individual scores in a distribution to some more simple shared feature. Statistics like the mean, median, and mode try to focus on what is most common, or core, to a set of diverse data. You can think of centrality like a summary - while a lot of information is lost in summary (e.g., Lord of the Rings is much more about some Hobbits trying to destroy an evil ring), a summary often gets the point across in few words (e.g., Lord of the Rings does spend a lot of time describing Hobbits trying to destroy an evil ring.)",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#definitions-of-centrality",
    "href": "chapters/3R_Description.html#definitions-of-centrality",
    "title": "Description",
    "section": "Definitions of Centrality",
    "text": "Definitions of Centrality\n\nThe Mean\nThe mean (also known as the average) is one of the most important statistics, and the foundation for much of what we will do in this class.\nYou probably learned this equation as something like, ‚Äúadd up all the numbers and divide by the total number of numbers‚Äù. This is technically correct, but scientists like to be more specific and formal, and so statistics uses a more specific language.\nThe statistical equation for the mean is below; it may look confusing, but it is really just a fancy version of the same definition of the mean you know and love. Specifically, the formula defines the mean as ‚Äúequal to the sum of all individual x-values (starting with the first individual and ending with the last individual in the dataset), and divided by the sample size.‚Äù\n\n\n\n\n\n\n\nThe Equation\nBreakdown of Terminology\n\n\n\n\n\\[\n\\Huge \\bar{Y} = \\frac{\\sum_{i=1}^n y_i}{n}\n\\]\n\n\\[\\Sigma\\] = blah",
    "crumbs": [
      "Lab Assignments",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/4R_ResearchMethods.html",
    "href": "chapters/4R_ResearchMethods.html",
    "title": "Why Research Methods?",
    "section": "",
    "text": "Part 1.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/4R_ResearchMethods.html#part-2.",
    "href": "chapters/4R_ResearchMethods.html#part-2.",
    "title": "Why Research Methods?",
    "section": "Part 2.",
    "text": "Part 2.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/4R_ResearchMethods.html#part-3.",
    "href": "chapters/4R_ResearchMethods.html#part-3.",
    "title": "Why Research Methods?",
    "section": "Part 3.",
    "text": "Part 3.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#the-mean",
    "href": "chapters/3R_Description.html#the-mean",
    "title": "Description",
    "section": "The Mean",
    "text": "The Mean\n\nDefinition.\nThe mean (also known as the average) is one of the most important statistics, and the foundation for much of what we will do in this class.\nYou probably learned this equation as something like, ‚Äúadd up all the numbers and divide by the total number of numbers‚Äù. This is technically correct, but scientists like to be more specific and formal, and so statistics uses a more specific language.\nThe statistical equation for the mean is below; it may look confusing, but it is really just a fancy version of the same definition of the mean you know and love. Specifically, the formula defines the mean as ‚Äúequal to the sum of all individual x-values (starting with the first individual and ending with the last individual in the dataset), and divided by the sample size.‚Äù\n\n\n\n\n\n\n\nThe Equation\nBreakdown of Terminology\n\n\n\n\n\\[\n\\Large \\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}\n\\]\n\n\\(\\bar{y}\\) = ‚Äúy bar‚Äù = the mean of y\n\\(\\Sigma\\) = Sigma = the ‚Äúsum‚Äù of numbers (starting from the number on the bottom all the way through the number on the top).\n\\(i\\) = index = an individual\n\\(n\\) = sample size = the number of individuals in the dataset\n\\(y\\) = a variable\n\n\n\n\nSo, when reading this formula, you would ‚Äúsay‚Äù : ‚Äúy bar (the mean) is equal to the sum of all individuals of y (\\(y_i\\)) starting with the first (\\(i=1\\)) and going all the way through the total number of individuals (\\(n\\)). And then you take that sum, and divide by the total number of individuals (\\(n\\)).\nSee?! Simple!\n\n\nWhy It Matters.\nOne important characteristic of the mean is that it is the value of a distribution that is closest to all the other scores. This means that the mean serves as our ‚Äúbest guess‚Äù (a prediction) about the value of what any random individual scores in this distribution. This is why the mean is also called the ‚Äòexpected value‚Äô.\nYou‚Äôve internalized this in many ways - if you know the average temperature for summer in the Bay Area is a high of 70 degrees and a low of 56, then you can predict on any given day that you might need a sweater in the morning and evening, but will be hot in the afternoon.\nHOWEVER - the mean does not perfectly describe all scores in the distribution (because people are complex - we are not the same). We‚Äôll talk more about these ‚Äúerrors‚Äù in prediction when we talk about the standard deviation (a measure of complexity) below.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#the-median",
    "href": "chapters/3R_Description.html#the-median",
    "title": "Description",
    "section": "The Median",
    "text": "The Median\n\nThe Definition\nThe median is the value that is in the very middle of a distribution of scores. This means that 50% of scores in the distribution are higher than the median value, and 50% of the scores are lower than the median value.¬† If there‚Äôs an odd set of numbers, the median is the middle number. If there‚Äôs an even set of numbers, the median is the average of the two middle numbers.¬†\nSo imagine two sets of numbers : what number is in the very middle?\n\n2, 3, 3, 5, 10, 14, 19\n2, 2, 3, 3, 5, 10, 14, 19\n\n\n\n\n\n\n\nActivity : What‚Äôs the median?\n\n\n\n\n\n\n2, 3, 3, 5, 10, 14, 19 = the median value is 5, since this number is in the middle. note that when calculating the median, the values of the data should be organized from smallest to larges.\n2, 2, 3, 3, 5, 10, 14, 19 = the median value is 4; since there is no ‚Äútrue‚Äù middle, 4 is the value that is in the middle of the two nearest values 3 and 5.\n\n\n\n\n\n\nWhy It Matters\nBecause the median is defined entirely by the middle of a distribution, it is less influenced by extreme data (outliers) than the mean. Below are two graphs of height. The one on the left is for a collection of people, and the histogram on the right is a graph of heights for a collection of people and some big friendly giants. The median of this distribution is illustrated as a vertical blue line, and the mean of this distribution is illustrated as a vertical red line.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#the-mode",
    "href": "chapters/3R_Description.html#the-mode",
    "title": "Description",
    "section": "The Mode",
    "text": "The Mode\n\nThe Definition\nThe mode is the most common number in a set of numbers. If two numbers are equally common in a distribution, then the distribution is said to be bi-modal (and more than two most common numbers = multimodal)\nSo if your distribution was : 2, 3, 3, 5, 10, 14, 19, 20, 20, then the mode would be‚Ä¶1\n\n\nWhy It Matters\nThe mode is rarely reported in research articles - I sometimes see it in within-person studies, or in situations where researchers are measuring psychophysiological measures (like heart rate or vagal tone) where the peak of the distribution might indicate something important.\nConceptually, it can be interesting to note the presence of a mode, and to think about why a bi-modal (or multi-modal) distribution occurs.¬†\nFor example, look at the following illustration : why might this bimodal distribution occur?\n\n\n\n\n\n\n\nReasons for this bimodal distribution.\n\n\n\n\n\n\n\n\n\n\n\n\nThe more conventional answer is that this bimodal distribution represents overlap between male and females in a dataset.\n\nAnother possibility is that this graph illustrates a python who has swallowed an elephant.2",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#range.",
    "href": "chapters/3R_Description.html#range.",
    "title": "Description",
    "section": "Range.",
    "text": "Range.\n\nDefinition.\nOne way people differ is by the extreme ends; this is called the range. Most people refer to the range as the lowest and highest value; though sometimes the range is defined as the distance between the highest and lowest value.\n\n\nWhy It Matters.\nThe extreme low and high of your variable give you a sense about the limits of variation. How to interpret these limits really depends on the variable you are measuring; for a variable like reaction time in some cognitive task, I would expect the low end to be zero (or something near zero, but not negative) and the high end influenced by how long I would expect the task to take (usually anywhere from less than a second for a quick reaction to a few minutes.) If the high end of the range was something like 30-minutes, I would think that something went wrong.\nAs a researcher (and teacher) I often use the range as a quick way to ensure the data are correct - that is, to confirm that the lowest and highest scores are possible values given the way the variable was measured. For example, I check the range when looking at test scores to make sure no students got a negative score or score above 100% (both impossible in my class.)",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#outliers.",
    "href": "chapters/3R_Description.html#outliers.",
    "title": "Description",
    "section": "Outliers.",
    "text": "Outliers.\n\nThe Definition\nOutliers are extreme values that are so different from the rest of the data that you remove them from the dataset because you worry that they might cause problems for your data. Outliers exist because of errors in data entry (for example, the person who lists their age as 1009 instead of 19) or because they represent individuals who are qualitatively different from the rest of your data (for example, the participant who is a billionaire and lists that as their income.3)\nHow extreme is too extreme? Some folks like to come up with rules for making this decision based on the number of standard deviations away from the mean or some other metric. I appreciate those efforts, but personally believe it‚Äôs better to judge outliers based on the qualitative decisions above (and use past research as a guide). Whatever you do, make sure to (1) justify your decisions, (2) report these decisions in your code and analyses, and (3) make any decisions about removing outliers as early as possible and before you start making predictions.\n\n\nWhy It Matters.\nThe presence of outliers in your data has the potential to influence your results in ways that will bias your results. For example, if someone wandered off in the middle of a cognitive task, their outliers for reaction time might make you think people took way longer to complete the task than people really needed to take. If I included everyone who didn‚Äôt take the exam (and got a zero) in taking the average of the exam score, I might think that students did worse on the exam than they really did, when I should have excluded these zeros to get a better representation of how people did on the exam.\nIt‚Äôs therefore super critical to a) identify any possible outliers in the data, and b) remove them from data analysis, and c) be 100% transparent that you have removed data. You will learn to do this using R in Part 4 below.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#skew.",
    "href": "chapters/3R_Description.html#skew.",
    "title": "Description",
    "section": "Skew.",
    "text": "Skew.\n\nDefinition.\nSkew describes asymmetry in the shape of the distribution. A graph that is symmetrical has no skew.\n\n\n\n\n\nIt‚Äôs easy to confuse the different types of skew, so I like to think of skew as a type of pokemon (‚Äúpikaskew‚Äù), where the direction of skewness is defined by its tail, since Pokemon (at least the ones I can think of) have tails. This is my trick; feel free to use it (you are welcome) or develop your own!¬†\nskew ‚Üí pikachu ‚Üí ‚Äì&gt; tail\n\n\nWhy It Matters.\nSkew can help us to think about why people\n\nNegative Skew (also called ‚ÄúLeft Skew‚Äù) is when the distribution ‚Äútail‚Äù sticks out on the negative (low) end of the measure. A negatively skewed distribution means that there‚Äôs a greater probability of high scores than low scores, and can be explained by ceiling effects (a measure does not differentiate between high scorers - like an exam that almost everybody aces because you were all prepared.)\nPositive Skew (also called ‚ÄúRight Skew‚Äù) is when the distribution ‚Äútail‚Äù sticks out on the positive (high) end of the measure. A positively skewed distribution means that there‚Äôs a greater probability of low scores than positive scores, and can be explained by floor effects (a measure does not differentiate between low scorers).\nNo Skew (also called the ‚ÄúNormal Distribution‚Äù) is when the distribution is symmetrical.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#kurtosis",
    "href": "chapters/3R_Description.html#kurtosis",
    "title": "Description",
    "section": "Kurtosis",
    "text": "Kurtosis\n\nKurtosis\nKurtosis describes the size of the tails, relative to the middle of the distribution. I think of kurtosis as the pointiness of the distribution. Mesokurtic is a distribution that looks ‚Äúnormal‚Äù, leptokurtic is a distribution that is skinny in the middle (with many individual scores in the tail of the distribution), and platykurtic is a distribution wide in the middle with few observations in the tails.\n\n\n\n\n\nLike skew, there are ways to quantify kurtosis, but we won‚Äôt cover this in the class. I almost never see kurtosis reported as a statistic in journals.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#the-standard-deviation.",
    "href": "chapters/3R_Description.html#the-standard-deviation.",
    "title": "Description",
    "section": "The Standard Deviation.",
    "text": "The Standard Deviation.\n\nThe Definition\nStandard Deviation (sd) is a way to quantify the ‚Äòaverage‚Äô variation in your dataset. More specifically, it is the average distance between all individual data points in the distribution, and the mean of the distribution. These distances (between an individual score and our prediction) are called residuals.\nThe standard deviation is always positive, since it describes the average distance of individual scores from the mean (residuals), and not whether those residuals are above or below the mean. A standard deviation of zero means there is no variation - all scores in the distribution are the same. The larger the standard deviation, the more variation there is in the data. There‚Äôs no limit to how large the standard deviation might be.\nUnderstanding what the standard deviation is, and how it‚Äôs calculated, is a critical skill. In the videos below I walk through how to calculate standard deviation by ‚Äúhand‚Äù. You will never actually use this approach in real-life, but I find it very helpful to fully understand what a standard deviation is, and how (and why) we use residual scores in statistics. With the chickenweights dataset, of course.\n\nVideo : The Mean as Prediction\nWith no other knowledge about an individual, the mean is our best prediction about what an individual is like.\n\n\n\nVideo : Residuals as Error\nResiduals refer to the fact that the mean is not a perfect prediction for every person; people will differ from our predictions. These differences between each individual‚Äôs actual score and our predicted value (in this case, the mean) are called residuals. The residuals will always be actual score minus prediction - I remember this because as researchers we care about actual people first.\n\n\n\nVideo : The Sum of (Squared) Residual Errors\nThe sum of squared errors (SS) is a way to quantify the total residuals when using the mean to make predictions. As you‚Äôll see in the video, we must first square the residual differences in order to remove the direction (since we care about the total error, not whether the individual was above or below our prediction.). And then we sum these squared differences to quantify the total (squared error).\n\n\n\nVideo : The (Unsquared) Average of These Squared Residuals = Standard Deviation\nThe standard deviation is the squared root of these averaged squared differences. Or, in less technical terms, the standard deviation is the average of how much people differ from the mean - a measure of the average variation.\n\n\n\n\nWhy This Matters\nGreat question! The standard deviation does two things :\n\nThe standard deviation quantifies how much the ‚Äúaverage‚Äù person differs from the average of the individuals in a group. This is a great statistic to have, since it quantifies how much individuals differ from each other on average (between-person variation)\nThe standard deviation serves as a baseline for our predictions. The mean is a GREAT starting place for our predictions, but soon we will want to make more sophisticated predictions. We will do this with our good friend the linear model, and will know whether we can improve our predictions by decreasing the amount of residual error.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#definition.-3",
    "href": "chapters/3R_Description.html#definition.-3",
    "title": "Description",
    "section": "Definition.",
    "text": "Definition.\nThe ‚ÄúNormal‚Äù (or Gaussian) distribution is a common shape for what distributions of data look like. The shape is often called a ‚Äúbell curve‚Äù, because it looks like the curve of a bell.\nWhile many distributions appear normal, the ‚ÄúNormal Distribution‚Äù ‚Ñ¢ refers to a distribution that describes an expected probability of a range of scores.\n\n\n\n\n\nThe Normal Distribution is called ‚Äúnormal‚Äù because researchers expect to see this type of distribution for variables where two conditions are met:\n\nThere are multiple explanations for why the variation occurs. This happens very frequently across all science, since life is complex and there are many reasons why individuals differ.\nThese multiple explanations occur randomly. This means that the multiple explanations for variation are mostly independent of one another, and there is not some shared experience among individuals that is influencing their variation.\n\n\nExample : Thinking About Distributions\nFor example, let‚Äôs look at one example ‚Äúnormal‚Äù distributions - the ‚Äúself-esteem‚Äù variable we saw in Lecture 2. Note that it‚Äôs not perfectly normal4, but it‚Äôs pretty close and representative of the kind of ‚Äúreal world‚Äù data that you might encounter.\n\nhist(d$SELFES, col = 'black', bor = 'white', \n     main = \"Histogram of Self-Esteem\", \n     xlab = \"Self-Esteem Score\", breaks = 15)\n\n\n\n\n\n\n\n\n‚ÄúRandom‚Äù explanations for why variation in self-esteem occurs. Self-esteem is complex, and can be influenced by variables such as: genetics, parental environment, home environment, income, neurotransmitters, whether your crush told you they like you too the day you took the self-esteem survey, etc. These variables are considered random because one does not influence the other, and they differ across participants in the study. That is, someone who had a happy parental environment may not necessarily have a high income.¬†\n‚ÄúNon-Random‚Äù Explanations. Careful observers will note that self-esteem appears slightly shifted above the mid-point of the scale (which goes from 1-4, so 2.5 would be the mid-point), and that there‚Äôs some slight negative skew (meaning more individuals are on the higher end of the distribution). This shift is likely the result of some shared cultural experiences among participants - our society values self-esteem, and people might be biased to self-enhance / self-present a higher self-esteem. This is a non-random influence, since many participants might experience this.\n\n\nExample 2 : Thinking About Distributions\nBelow is another example of a distribution - this one is not random, but is skewed (pop quiz : is it positively or negatively skewed? See here for answer5.)\n\n\n\n\n\n\n\n\n\n\n\n‚ÄúRandom‚Äù Reasons for Variation\n\n\n\n\n\nLots of things can influence a student‚Äôs score on an exam, such as how much students were motivated to study, how much time they had to study, what was going on in their lives, whether they had a study buddy in the class, whether they were sick or not on the day of the exam, their ‚Äútest taking‚Äù skills and strategies and anxiety levels, etc.\n\n\n\n\n\n\n\n\n\n‚ÄúNon-Random‚Äù Reasons for Variation.\n\n\n\n\n\nThese data are not normally distributed because the students were all part of the same college, in the same classroom, taught by the same professor, at the same time. The professor did his best to prepare these students, and wrote a test that would be based on the kinds of practice they had gone over in lecture. These variables are considered ‚Äúnon random‚Äù because they were shared by all students. The data are skewed because these non-random shared experiences helped students do well on the exam.\n\n\n\n\n\n\n\n\n\n\n\nCulture in Statistics : The Normal Curve\n\n\n\n\n\n\n\n\n\n\n\nThat‚Äôs right folks, it‚Äôs time for another chat with your friend Open-Source Mickey Mouse! This time, we‚Äôre gonna chat about the idea that people differ from some average. The idea that you could quantify people as ‚Äúaverage‚Äù is fairly new - it‚Äôs hard to pinpoint exactly, but a scientist named Quetelet first extended the statistical methods derived from astronomy to be applied to humans in the 1860s6. Quetelet thought the average was an ideal state since it reflected the center of all possible individuals. However, a few years later Francis Galton used Quetelet‚Äôs ideas to try and ‚Äúrank‚Äù individuals according to some hierarchy of excellence. For Galton, the average was not an ideal state, but rather something to overcome in a desire for greater and greater excellence. Galton was also a racist and father of the eugenics movement, who used distorted statistics as a tool to justify his own pre-existing racist beliefs that white people were superior to everyone else.\n\n\n\nBut you don‚Äôt have to take it from me! Here‚Äôs Galton in his own words :\nTo conclude, the range of mental power between‚ÄîI will not say the highest Caucasian and the lowest savage‚Äîbut between the greatest and least of English intellects, is enormous. ‚Ä¶ I propose in this chapter to range men according to their natural abilities, putting them into classes separated by equal degrees of merit, and to show the relative number of individuals included in the several classes‚Ä¶..The method I shall employ for discovering all this, is an application of the very curious theoretical law of ‚Äúdeviation from an average.‚Äù First, I will explain the law, and then I will show that the production of natural intellectual gifts comes justly within its scope. - Galton, Hereditary Genius (1869). Linked here.\n\n\nThe point of bringing up some of the racist origins of statistics is two-fold :\n\nMany people like to argue that ‚Äúgood‚Äù statistics is objective, and that scientists are free of bias. So it‚Äôs important to acknowledge that the inventors of many statistics that we use had clear biases and did not behave objectively. Rather than try to be free of bias, I think it‚Äôs important to acknowledge where and when people are biased, and address those biases up explicitly.\nStatistics is a tool, and that tool can be used poorly and dangerously in ways that can cause a lot of pain. Just because something has numbers doens‚Äôt mean it‚Äôs correct. For example, Galton‚Äôs work showing ‚Äústatistically‚Äù that white people were superior in ability to other groups didn‚Äôt account for other factors like socioeconomic status. And for what it‚Äôs worth, modern scientists overwhelmingly agree that ‚Äúrace‚Äù is a social construct. There are genetic differences that explain different skin tones, however there is more genetic variation in skin tone within a similar ‚Äúrace‚Äù than between different ‚Äúraces‚Äù. Read more about this here.\n\nAlright, that‚Äôs all for now! Let me know what you think and see you next time!",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#why-this-matters.",
    "href": "chapters/3R_Description.html#why-this-matters.",
    "title": "Description",
    "section": "Why This Matters.",
    "text": "Why This Matters.\nThe normal distribution is foundational to the statistics we will learn in this class. (And in an advanced statistics class, you‚Äôll learn how to adapt techniques if you want to understand non-normal distributions.)\nThis does not mean that every variable needs to be normally distributed; we‚Äôll work with skewed variables and categorical variables (which have their own distributions) in lots of ways. However, the ‚Äúnormal distribution‚Äù is an important reference point that we can use to evaluate variables. For example, exam scores are negatively skewed because they differ from the normal distribution.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#descriptive-statistics",
    "href": "chapters/3R_Description.html#descriptive-statistics",
    "title": "Description",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nBelow is a list of code we‚Äôll use to calculate descriptive statistics in R.\n\n\n\n\n\n\n\nR Command\nWhat It Does\n\n\nsummary(dat)\nReports descriptive statistics for all variables in the dataset.\n\n\nsummary(dat$variable)\nReports descriptive statistics for a continuous variable.\nReports frequency for a categorical variable.\n\n\nmean(dat$variable, na.rm = T)\nReports the mean (average) of a variable; you must include the na.rm = T argument if there is missing data (otherwise R will return NA as the result).\n\n\nmedian(dat$variable, na.rm = T)\nReports the median (middle point) of a variable.\n\n\nrange(dat$variable, na.rm = T)\nReports the lower limit and upper limit of the variable.\n\n\nsd(dat$variable, na.rm = T)\nReports the standard deviation of the variable.\n\n\nhist(dat$variable)\nabline(v =mean(dat$variable))\nDraws a line on a plot or histogram at specified values (e.g., this draws a vertical line at the mean of dat$variable. You can replace v with h to draw a horizontal line. We will use abline() later in the semester in a different way.\n\n\npar(mfrow = c(i, j))\nSplits your graphics window into i rows and j columns (replace i and j with numbers)",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#removing-outliers",
    "href": "chapters/3R_Description.html#removing-outliers",
    "title": "Description",
    "section": "Removing Outliers",
    "text": "Removing Outliers\nThe video below describes how to remove outliers, using a datset built into R.\n\nWe will practice removing outliers in lecture! It will get easier.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#footnotes",
    "href": "chapters/3R_Description.html#footnotes",
    "title": "Description",
    "section": "",
    "text": "the mode would be 3 and 20, since these are the most frequent‚Ü©Ô∏é\nsee Antoine de Saint-Exup√©ry‚Äôs (1943). The Little Prince.‚Ü©Ô∏é\nNo shame billionaires! You are just very different from the rest of us. Let us know if I can hang out on your yacht? You belong to an understudied group and I have some research ideas. kthxbye.‚Ü©Ô∏é\ngood not to hold data to unrealistic body images as well as people.‚Ü©Ô∏é\nIt is negatively skewed, since the tail is on the negative side of the distribution.‚Ü©Ô∏é\nsee Rose‚Äôs END OF AVERAGE (2016) or, for a more critical approach, Chapman‚Äôs (2023) EMPIRE OF NORMALITY.‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/3R_Description.html#check-in-with-r-practice-quiz-3-describing-variables",
    "href": "chapters/3R_Description.html#check-in-with-r-practice-quiz-3-describing-variables",
    "title": "Description",
    "section": "Check-In with R : Practice Quiz 3 (Describing Variables)",
    "text": "Check-In with R : Practice Quiz 3 (Describing Variables)\nInstructions\nUse R and the twitter_emotion_data.csv to answer the following questions in the check-in above.\n\nHere‚Äôs a link to the dataset (load this into R) and a link to the Codebook (that describes the dataset)\nLink to a video key; but good to try this on your own!\n\nQuestions\n\nLoad the data and check to make sure the data loaded correctly. How many individuals (tweets; in this dataset, each row = one tweet) are in the dataset?\nGraph the variable retweet_count. How would you describe the shape of this variable?\nWhat do you learn about the variable retweet_count from this graph?\nWhat is the mean of the variable retweet_count?\nWhat is the median of the variable retweet_count?\nWhat is the standard deviation of the variable retweet_count? [note : you do not need to do this by hand]?\nWhat is the lowest value (range) of the variable retweet_count?\nWhat is the highest value (range) of the variable retweet_count?\nNow, work with the categorical variable Orientation. How many Liberal (tweets) are in the dataset?\nHow many Conservative (tweets) are in the dataset?",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Description</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html",
    "href": "chapters/4R_Scales.html",
    "title": "Measures",
    "section": "",
    "text": "Part 1 | Methods of Measurement\nOne of the challenges psychologists face in their attempts to be a REAL SCIENCE ‚Ñ¢ is that their data is particularly hard to collect. Unlike physical variables like temperature or mass, psychological variables are often internal to people, and defined by mental states that are difficult to observe. As we saw in lecture, even a ‚Äúsimple‚Äù expressed behavior like an interruption can be very difficult to measure with high degrees of reliability and validity that we would hope. For a more complex variable such as depression, the task might seem impossible. Indeed, a large part of psychological research is engaging in debate and scholarship about how to best operationalize variables of interest (e.g., how should we define or measure depression?)\nA full discussion of the different types of methods psychologists use to collect data is beyond the scope of this author. However, below I‚Äôve tried to outline a few different approaches psychologists take, commenting on their benefits and limitations so you can begin to critically think about whether these methods are, in fact, getting at ‚ÄúTHE TRUTH‚Äù of what people (or non-human animals) are like.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Measures</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#self-reports",
    "href": "chapters/4R_Scales.html#self-reports",
    "title": "Measures",
    "section": "Self-Reports",
    "text": "Self-Reports\nOne of the simplest ways to collect data on an individual is just to ask them what they are like, and have the person report on themselves (a self-report). There are two different approaches to getting self-reports - survey methods and qualitative interviews.\n\nQualitative Interviews\nOne way to get individuals to tell you what they are like is through a structured interview where researchers ask open-ended questions. One such example of this is the McAdams Life Narrative1. In this structured interview, a trained research assistant asks a set of broad questions to participants over the course of 1 to 3 hours. The research assistant is advised to ‚Äúfeel free to skip some of these questions if they seem redundant or irrelevant, and should follow up with other questions as needed ‚Äú but also to ‚Äúnot adopt an advisory or judgmental role, but should instead serve as an empathic and encouraging guide and an affirming sounding board.‚Äù\nBelow is an excerpt from the first part of the interview - if you are comfortable, please share your chapters on the Chapter 4 Discord thread!2\n\n\n\n\nSurvey Methods\nQualitative interviews are not very common in psychological research, because they take a lot of time to conduct, and then more time to convert people‚Äôs open-ended responses into data (a form of behavioral coding, described in more detail below).\nInstead, the majority of self-reports come from surveys. Read about these below.\n\n\n\nDefinition\nA questionnaire where individuals answer specific questions about themselves on a structured rating scale.\n\n\nExample\n‚ÄúOn a scale from 1 (Strongly Disagree) to 5 (Strongly Agree), how satisfied with your life are you right now?‚Äù\n\n\nBenefits\n\nEasy to collect : It only takes a few minutes for people to answer a survey, and the data come in a clean and organized format that requires little effort to analyze. In Part 2 below, you‚Äôll learn how to clean and organize the results of a likert scale.\nSelf-Knowledge Validity : People know things about themselves, often this knowledge is based in ‚Äúreality‚Äù, and sometimes a self-report is the only way to get this knowledge. For example, only you know what was your happiest moment in life, and you probably have an accurate awareness about how anxious you are about the final project in this class.\n\n\n\nLimitations\n\nSelf-Enhancement / Self-Diminishment Bias : People are often motivated to either enhance or diminish their accomplishments when asked. For example, no student has ever come up to me at the end of the semester and told me, ‚ÄúProfessor, just so you know - I cheated on the exam.‚Äù Even though they may know they cheated, they don‚Äôt want to admit that because our society has norms or guidelines about when cheating is appropriate3. Other times, a person may not want to highlight their accomplishments (self-diminishment) because they don‚Äôt want to seem like they are bragging.\nSelf-Insight Bias : Sometimes, people also really don‚Äôt know what they are like. A person may not know, for example, whether they snore when they sleep (a behavior), how anxious they really are in a situation (an affect), or their patterns of unconscious bias (a cognition).\n\n\n\n\nSelf-reports have a bad reputation in psychology, particularly because of the ability for people to engage in self-enhancement/diminishment or self-insight bias. However, they are a very powerful, and very commonly used method of assessment, even for studies where researchers are able to observe other types of data.¬†\nFor example, despite all the behavioral data that powerful technology companies like Facebook/Instagram/Meta, TikTok, Twitter/X, etc. collect, you‚Äôve probably seen them ask you to answer some survey. They care about you4, and know that asking you questions about yourself is an important way to show that level of care.\nBelow is one example from some survey when I used to be on Facebook. If they changed their graphic design since I was last on, it‚Äôs probably because of some survey feedback they received.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Measures</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#observations",
    "href": "chapters/4R_Scales.html#observations",
    "title": "Measures",
    "section": "Observations",
    "text": "Observations\nOften, self-reports are insufficient to capture what a person is like, or researchers are studying individuals who cannot give self-reports, such as infants, people with disabilities, or non-human animals.5\nRead about some common forms of observation methods below.\n\n\n\nDefinition\nObservational methods refer to ways in which another individual generates data on the target person of interest.\n\n\nExamples\nInformant Reports. Informant reports are a special form of surveys, where researchers ask friends, family, or strangers to answer survey questions about another person. This is technically observational data, since the people answering the surveys are basing their judgments on their observations of the individual.\n |\nBehavioral Data. When the variables of interest are physical, then researchers can use measurement tools to directly observe the behavior. For example, researchers wanting to measure stress might measure cortisol by taking samples of saliva from the cheek; researchers wanting to understand the brain look to voxel activation with fMRI, or cortical neuron activation with EEG.\n |\nBehavioral Coding. Sometimes, it‚Äôs easier to have research assistants observe the physical behaviors of interest. For example, y‚Äôall served as behavioral coders when you counted the number of interruptions (a behavior!) Other times, research assistants will observe real-life interactions and observe variables such as time spent talking, distance between participants, or provide ratings of how much emotion or anxiety the person seemed to be expressing (using a rating scale). The ‚Äústrange situation‚Äù task (where a parent leaves the room and researchers observe what a child does) is another example.6\n\n\n\nBenefits\n\n‚ÄúExternal‚Äù. Researchers like observational methods because they, by definition, require some outward expression of the underlying psychological processes. Professor could go on a rant here and won‚Äôt, but psychology has been increasingly fixated on behavior since Watson kicked off the behaviorism movement in the 1920s, and these data are often prioritized, since our field loves predicting people‚Äôs actual behavior (so they can exert power over it).\nLess influenced by self-report biases. Observers are considered to be less biased than individuals, who may be particularly prone to self-enhancement, self-diminishment. And observers may be able to fill in the gaps left behind by self-insight bias. For example, a person‚Äôs close friends may know more about the individual‚Äôs reputation than they themselves do.\nMore reliable (multiple sources). While there is only one self to provide a self-report, there can be multiple observers. Indeed, observational methods almost always leverage this power and require multiple swabs of spit to get a reliable estimate of cortisol, or have multiple research assistants rate the same behavior to check and make sure they are each getting a similar answer.\n\n\n\nLimitations\n\nTime-Intensive. It can be incredibly costly to collect observational data. Yale charges over $600/hour for use of their fMRI machine (Berkeley doesn‚Äôt list their prices), and conducting a study to measure a naturally occurring behavior could take years between designing the study, recruiting and training the research assistants to observe the behavior, taking the time to collect the data, and then doing the behavioral coding necessary to convert the observations into numbers. Whew. Much easier to just give someone a survey and have them complete it.\nThe Hawthorne Effect. The act of observation can often change behavior. Couples may be less likely to fight if they know they are being monitored by a psychologist, and even light changes its behavior depending on the way it is observed. Researchers can take steps to address this change in behavior - and sometimes the power of the phenomenon is so large that it doesn‚Äôt matter if a researcher is there. In couples studies, for example, researchers can get couples to fight by having each person write out a list of things that cause conflict in the relationship, and then having the people trade lists and talk about it. Often however, individuals habituate to the presence of observation - do you think about the fact that your online interactions are being harvested by tech companies every day, or just kinda get used to it?\nNot all aspects of psychology are observable. A person‚Äôs subjective experience matters, and sometimes a self-report is the only way you can get this data. If you look like you are smiling and have the neurotransmitter levels that suggest you are happy, but feel miserable, are you happy?\n\n\n\n\nTLDR : there are lots of different methods to measure what individuals are like, and for your final project you probably will want to give people self-report surveys to keep things simple for this very first study!",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Measures</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#definition-theory",
    "href": "chapters/4R_Scales.html#definition-theory",
    "title": "Measures",
    "section": "Definition & Theory",
    "text": "Definition & Theory\nA likert scale is a common survey method psychologists use to measure continuous variation. Likert scales can be used for self-report surveys (where an individual answers questions about themselves), or given to observers (where an individual answers questions about another person - either someone they know, or someone they are actively observing).¬†For example, to the right is an example likert scale - the Rosenberg Self-Esteem Scale7. Here‚Äôs a link to take the survey and get feedback.\n\n\n\nBelow are some common terms we will use when describing likert scale. (There‚Äôs a video that goes over these terms with another example below too.)\n\n\n\n\n\n\n\n\nTerm\nDefinition\nUsage / Example\n\n\nScale\nThe variable that you want to measure as a continuous variable.\nSelf-esteem is often measured with the Rosenberg Self-Esteem Scale (1965)\n\n\nItem(s)\nThe specific question(s) in the scale. Each item measures some aspect of the variable the researcher is interested in.\nThe Rosenberg Self-Esteem Scale (RSE; 1965) is a ten item scale, which means it has ten questions about self-esteem.\n\n\nResponse Scale\nHow people answer the scale items. People give a number rating on a fixed range of options with labels. Many 5-point scales include the following labels (1 = Strongly Disagree; 2 = Disagree; 3 = Neutral; 4 = Agree; 5 = Strongly Agree.)\nThe RSE was originally written to use a 4-point rating scale from 0 (Strongly Disagree) to 3 (Strongly Agree). When Professor includes the RSE in his studies, he might change the response scale to go from 0-4 to so it has an odd-number of answers to allow people to say they are ‚Äúneutral‚Äù.\n\n\nPositively-\nKeyed Item\nAn item that measures the high end of the scale, where answering ‚Äúyes‚Äù to the question means you are high on this variable.\n‚ÄúOn the whole, I am satisfied with my life‚Äù is a positively-keyed item, because answering 4 (Strongly Agree) means the person says they are high in self-esteem.\n\n\nNegatively-Keyed Item\nAn item that measures the low end of the scale, where answering ‚Äúyes‚Äù to the question means you are low on the variable.\n‚ÄúI certainly feel useless at times‚Äù is a negatively-keyed item, because answering 4 (Strongly Agree) means the person says they are low in self-esteem.\n\n\nReverse Scoring\nHow researchers ‚Äúflip‚Äù the negatively-keyed items to be positively-keyed. To calculate how to reverse-score an item, you can add the lower and upper limit of the full range. So to reverse-score a response scale that goes from 0 to 4 = 0 + 4 = subtract the negatively keyed items from 4. A response scale that goes from 1 to 15 = 1 + 15 = subtract the negatively keyed items from 16. And so on.\nThis is confusing. We will practice in lecture some more, okay?\nTo reverse score the negatively-keyed item, you would subtract the person‚Äôs 4 from 4 (since the scale range is 0 to 4, so 0+4 = 4). A response of 4 (Strongly Agree) to the question I certainly feel useless at times means that for this question, the person‚Äôs self-esteem would be rated as a 0.\nPOP QUIZ : a survey has a response scale that goes from 1-7. What number would you subtract from in order to reverse score a negatively-keyed item?8\n\n\n\nAdvantages of Likert Scales\n\nThey are easy to administer as a self-report or observational survey, and provide structured data.\nThe principle of aggregation describes a phenomenon where combining multiple items into one scale will provide a more reliable and continuous measure. Remember, the normal distribution is a theoretical distribution that exists when there are multiple explanations for one variable that occur randomly in a population. The multiple items in a scale are one way to try and measure the multiple random explanations for variation. And indeed, as you‚Äôll see in the R demonstration, when you combine multiple categorical items into one variable, the distribution of the variable looks more normal than any individual item.\nResearchers can assess the reliability of the multiple items that were included in the measure. For example, if we are reliably measuring extraversion, then there should be. Cronbach‚Äôs (alpha) is a statistic that estimates the internal consistency (reliability) of a scale, and is based on (a) the similarity of people‚Äôs responses to the items in a scale (the more similar, the higher the reliability) and (b) the number of items in a scale (sales with many items will tend to have higher cronbach than will likert scales with just a few items.) There‚Äôs no official ‚Äúrule‚Äù for what‚Äôs considered good or bad alpha, but below are some guidelines:\n\nŒ± &gt; .8 = GREAT! Your scale is reliable\nŒ± = .5 - .7 = OKAY! Your scale has low reliability, so something may be wrong with your measure.\nŒ± &lt; .5 = UH OH‚Ä¶your scale has really low reliability. Below are a few possible reasons:\n\nyour scale only has a few items: remember, that Œ± is influenced by the number of items in your scale; so scales with a few items will almost certainly have a low alpha reliability.\nwere the items in scale incorrectly coded (reverse scored items)?\nis the scale measuring different things (no consistency)? It could be that your scale isn‚Äôt very precise, and is measuring different variables.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Measures</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#video-example-the-extraversion-scale",
    "href": "chapters/4R_Scales.html#video-example-the-extraversion-scale",
    "title": "Measures",
    "section": "Video Example : The Extraversion Scale",
    "text": "Video Example : The Extraversion Scale\nHere‚Äôs another example of a likert scale - Extraversion items adapted from Big Five Inventory 2 (Soto & John, 2017).\n\n\n\n\nWatch This Video.\n\n\n\nCheck-In\nPLEASE COMPLETE THIS CHECK-IN TO PRACTICE REVERSE-SCORING.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Measures</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#in-r-creating-a-likert-scale",
    "href": "chapters/4R_Scales.html#in-r-creating-a-likert-scale",
    "title": "Measures",
    "section": "In R : Creating a Likert Scale",
    "text": "In R : Creating a Likert Scale\nIn this demonstration, we‚Äôll use the class dataset to create a scale to measure differences in EXTRAVERSION. To do this, we will need to complete the following steps:\n\n1. Import and Check the Data.\nFirst, we‚Äôll need to load the data, and check to make sure it is imported correctly. You can access these data here - personality measures of extraversion (how social people say they are) and conscientiousness (how organized people say they are).\n\nec &lt;- read.csv(\"../datasets/ec_data.csv\") # Note: make sure to change the *path* in the `read.csv()` function to point R to the correct spot to import the ec dataset from YOUR computer.\n\n\n\n2. Create a data.frame that isolates the items in the scale.\nNow, I‚Äôll just create a smaller dataframe of the variables that I want to work with for the extraversion scale. From the codebook, I see that the extraversion scale is made up of the items e1-e6r, with the r indicating items that are negatively-keyed.\n\nextra.df &lt;- data.frame(ec$e1, ec$e2, ec$e3, # the three positively keyed items\n                    ec$e4r, ec$e5r, ec$e6r) # the three negatively keyed items\nhead(extra.df) # this code checks my work and make sure my newly created dataframe in fact contain the positively and negatively keyed items\n\n  ec.e1 ec.e2 ec.e3 ec.e4r ec.e5r ec.e6r\n1     2     3     2      4      4      4\n2     2     4     3      3      3      4\n3     3     4     2      4      5      4\n4     2     3     2      3      4      3\n5     5     5     5      1      1      1\n6     1     3     3      3      4      4\n\n\n\n\n3. Correctly reverse-score the negatively-keyed items in the scale.\nNow, I need to reverse-score the negatively keyed items. Since the scale ranged from 1 to 5, I need to subtract the negatively keyed items from 6 to reverse the scoring (so 6 - 1 = 5, and 6 - 5 = 1.)\nNote that you can calculate how to reverse-score an item by adding the lower and upper limit of the full range. So to reverse-score a response scale that goes from 0 to 4 = 0 + 4 = subtract the negatively keyed items from 4. A response scale that goes from 1 to 15 = 1 + 15 = subtract the negatively keyed items from 16. And so on.\nI can again use the head() function to check my work and confirm that I successfully reverse scored the variables. Note that you can reverse-score the variables in one step; I don‚Äôt really do this twice when creating a scale :)\n\nextra.df &lt;- data.frame(ec$e1, ec$e2, ec$e3, # the three positively keyed items\n                    6-ec$e4r, 6-ec$e5r, 6-ec$e6r) # the three negatively keyed items\nhead(extra.df) # this code checks my work and make sure my newly created dataframe in fact contain the positively and negatively keyed items. Note that there seems to be more consistency in the scores for each individual - people who are low in e1-e3 are now also low in e4r - e6r.\n\n  ec.e1 ec.e2 ec.e3 X6...ec.e4r X6...ec.e5r X6...ec.e6r\n1     2     3     2           2           2           2\n2     2     4     3           3           3           2\n3     3     4     2           2           1           2\n4     2     3     2           3           2           3\n5     5     5     5           5           5           5\n6     1     3     3           3           2           2\n\n\n\n\n4. Evaluate the reliability of the items in this variable.\nI‚Äôll examine the internal reliability of the scale. Internal reliability measures how consistent people‚Äôs responses were for each of the items of the scale. I‚Äôm hoping for a high value.\n\nlibrary(psych) # make sure you install.packages(\"psych\") first!\nalpha(extra.df)\n\n\nReliability analysis   \nCall: alpha(x = extra.df)\n\n  raw_alpha std.alpha G6(smc) average_r S/N  ase mean   sd median_r\n      0.87      0.87    0.88      0.52 6.6 0.03  3.1 0.88     0.49\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.80  0.87  0.92\nDuhachek  0.81  0.87  0.92\n\n Reliability if an item is dropped:\n            raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nec.e1            0.88      0.88    0.89      0.59 7.2    0.028 0.017  0.58\nec.e2            0.85      0.85    0.85      0.53 5.6    0.035 0.029  0.51\nec.e3            0.82      0.82    0.83      0.48 4.6    0.040 0.025  0.45\nX6...ec.e4r      0.85      0.85    0.86      0.53 5.7    0.035 0.032  0.51\nX6...ec.e5r      0.80      0.81    0.81      0.46 4.3    0.044 0.020  0.46\nX6...ec.e6r      0.86      0.86    0.86      0.55 6.1    0.032 0.020  0.53\n\n Item statistics \n             n raw.r std.r r.cor r.drop mean   sd\nec.e1       50  0.63  0.63  0.52   0.47  2.9 1.18\nec.e2       50  0.75  0.77  0.72   0.65  3.6 0.91\nec.e3       50  0.87  0.88  0.87   0.79  3.3 1.12\nX6...ec.e4r 49  0.77  0.76  0.69   0.64  3.3 1.22\nX6...ec.e5r 49  0.91  0.91  0.92   0.86  3.0 1.16\nX6...ec.e6r 50  0.73  0.72  0.67   0.59  2.7 1.21\n\nNon missing response frequency for each item\n               1    2    3    4    5 miss\nec.e1       0.14 0.26 0.28 0.24 0.08 0.00\nec.e2       0.04 0.06 0.30 0.50 0.10 0.00\nec.e3       0.06 0.20 0.30 0.30 0.14 0.00\nX6...ec.e4r 0.04 0.31 0.20 0.24 0.20 0.02\nX6...ec.e5r 0.08 0.27 0.35 0.16 0.14 0.02\nX6...ec.e6r 0.16 0.34 0.20 0.22 0.08 0.00\n\n\n\n\nThere‚Äôs a LOT going on in this code, but I‚Äôm looking at the number underneath raw_alpha, which shows me that this scale is reliable. This is good, and would be something that I would report when describing the measure of Extraversion.\nThe rest of the code output gives you other statistics on the scale (e.g., the mean or standard deviation), and shows you what the reliability of the scale would be if you removed one of the items from the scale. This can be useful for diagnosing whether there was an issue with your code (e.g., did you forget to reverse-score one item?) or with the scale (e.g., is one of your items actually measuring something other than extraversion?) In this case, the reliability doesn‚Äôt change much if we remove any of the items.\n\n\n5. Use the rowmeans() function to create a new variable that is the average of each person‚Äôs items.\nNow, I need to create one variable that is combines all the items into one number. To do this, I could either add up each person‚Äôs 6 extraversion scores, or take the average. The convention is usually to take the average for personality variables - not sure why‚Ä¶a cultural difference.\nSo we will use the rowMeans() function to do this. There are two methods for this.\n\nMethod #1 (Default - very conservative approach) : only calculate an average score if people answered every item in the dataset. This completely removes a person from the dataset, even if they answered 5/6 of the questions.\n\nthis calculates the average of these items for each row (individual) in the dataset. This is the measure of extraversion for each person. Notice that there is some missing data - the default for this code is that a person‚Äôs data will be totally removed if they didn‚Äôt answer all the questions in the scale. This is a very conservative way to handle missing data.\n\n    rowMeans(extra.df) \n\n [1] 2.166667 2.833333 2.333333 2.500000 5.000000 2.333333 3.333333 3.666667\n [9] 2.833333 2.333333 2.000000 3.500000 4.166667 2.333333 4.500000 3.166667\n[17]       NA 3.666667 3.000000 3.666667       NA 3.500000 3.666667 4.000000\n[25] 1.666667 4.833333 3.666667 3.833333 3.166667 3.000000 2.500000 2.833333\n[33] 1.000000 2.833333 3.333333 3.000000 3.166667 2.166667 2.333333 3.166667\n[41] 1.833333 3.000000 3.166667 4.333333 4.166667 3.500000 3.500000 2.166667\n[49] 4.833333 1.666667\n\n\n\nMethod #2 (more liberal approach) : this removes missing data from specific items, so the average score will be calculated even if the person didn‚Äôt answer some of the items.¬†\n\n\nrowMeans(extra.df, na.rm = T) #     adding na.rm = T as an argument. \n\n [1] 2.166667 2.833333 2.333333 2.500000 5.000000 2.333333 3.333333 3.666667\n [9] 2.833333 2.333333 2.000000 3.500000 4.166667 2.333333 4.500000 3.166667\n[17] 3.800000 3.666667 3.000000 3.666667 2.800000 3.500000 3.666667 4.000000\n[25] 1.666667 4.833333 3.666667 3.833333 3.166667 3.000000 2.500000 2.833333\n[33] 1.000000 2.833333 3.333333 3.000000 3.166667 2.166667 2.333333 3.166667\n[41] 1.833333 3.000000 3.166667 4.333333 4.166667 3.500000 3.500000 2.166667\n[49] 4.833333 1.666667\n\n\n\nIMPORTANT In order to save the output as a variable, you will need to assign the output of rowMeans() to a new object, ideally one that is saved as part of the original dataset.\n\n\nec$EXTRAVERSION &lt;- rowMeans(extra.df, na.rm = T) # this saves the scales to the dataset as a new object (which I'm calling EXTRAVERSION). I like to name variables that I create in ALL CAPS. Note that I've chosen to be less conservative in how I handle missing data.\n\n\n\n6. Graph this variable and interpret the graph (what do you learn)?\nOkay, we have a scale! And this scale should measure continuous variation! Let‚Äôs graph it. I‚Äôm looking for a graph that ranges from 1 to 5 (since that was the limit of my response scale), and something that looks mostly normally distributed.\n\nhist(ec$EXTRAVERSION, main = \"\", col = 'black', bor = 'white')\n\n\n\n\n\n\n\n\nThis looks good. When I look at this graph I see the following things:\n\nthe range of the scale goes from 1 to 5. This is good, because the response scale ranged from 1 to 5. An incorrect range would suggest that I made a mistake when analyzing the data.\nthe graph is mostly normally distributed. This is also good, and expected for a personality variable like Extraversion. If there was some extreme skew, I might again think that I made a mistake when creating the scale, or wonder if there was some non-random variable that was influencing students‚Äô extraversion scores (for example, the entire cohort of students took an improv class during orientation).\nthere is some slight positive / right skew - there are a few students who are maxed out on extraversion. What‚Äôs up extraverts [waves furiously]. Not sure why that is, but some deviation from normality is always expected! Ooh, one theory is that this survey was given out at the end of a three-hour lecture, so maybe students who were more extraverted were more likely to stick around in a large classroom setting, and thus more likely to be included in the survey. This is an example of sampling bias.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Measures</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#video-creating-a-likert-scale",
    "href": "chapters/4R_Scales.html#video-creating-a-likert-scale",
    "title": "Measures",
    "section": "Video : Creating a Likert Scale",
    "text": "Video : Creating a Likert Scale\n\n\nHere‚Äôs a link to the Rscript I used in the video",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Measures</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#check-in-practice-for-quiz-4",
    "href": "chapters/4R_Scales.html#check-in-practice-for-quiz-4",
    "title": "Measures",
    "section": "Check-In : Practice for Quiz 4",
    "text": "Check-In : Practice for Quiz 4",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Measures</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#definition-theory-1",
    "href": "chapters/4R_Scales.html#definition-theory-1",
    "title": "Chapter 4 | Measures and Scales",
    "section": "Definition & Theory",
    "text": "Definition & Theory",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Chapter 4 | Measures and Scales</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#in-r-z-scoring",
    "href": "chapters/4R_Scales.html#in-r-z-scoring",
    "title": "Chapter 4 | Measures and Scales",
    "section": "In R : Z-Scoring",
    "text": "In R : Z-Scoring",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Chapter 4 | Measures and Scales</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#video-z-scoring-in-r",
    "href": "chapters/4R_Scales.html#video-z-scoring-in-r",
    "title": "Chapter 4 | Measures and Scales",
    "section": "Video : Z-Scoring in R",
    "text": "Video : Z-Scoring in R",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Chapter 4 | Measures and Scales</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#check-in-practice-for-quiz-4-1",
    "href": "chapters/4R_Scales.html#check-in-practice-for-quiz-4-1",
    "title": "Chapter 4 | Measures and Scales",
    "section": "Check-In : Practice for Quiz 4",
    "text": "Check-In : Practice for Quiz 4",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Chapter 4 | Measures and Scales</span>"
    ]
  },
  {
    "objectID": "chapters/4R_Scales.html#footnotes",
    "href": "chapters/4R_Scales.html#footnotes",
    "title": "Measures",
    "section": "",
    "text": "McAdams talks about his work in this popular press interview and writes about it in this scientific journal review article.‚Ü©Ô∏é\nHere‚Äôs a link to the full narrative instructions if you want to do the whole thing; it‚Äôs a great way to know someone.‚Ü©Ô∏é\nIndeed, our society decides what forms of cheating are acceptable.‚Ü©Ô∏é\n‚Ä¶and your clicking on advertisements; hey, it‚Äôs hard to distinguish the two really‚Ä¶‚Ü©Ô∏é\nIf I was a billionaire, I‚Äôd fund a team of psychologists to train monkeys to answer surveys. this is maybe why I am not a billionaire. that and the whole ‚Äúintergenerational wealth‚Äù thing / chosen teaching career / lack of a desire to crush others and extract as much wealth from them‚Ä¶hard to know which factor is at play. Life is complex! Let me know if you are a billionaire and want to fund some other ideas / subscribe to my newsletter.\n\n‚Ü©Ô∏é\nYou can compare this child‚Äôs reaction to this child‚Äôs reaction. What do you observe? How would you quantify these observations and turn them into cold, hard data?\n\n‚Ü©Ô∏é\nRosenberg, M. (1965). Rosenberg Self-Esteem Scale (RSES) [Database record]. APA PsycTests. Here‚Äôs a link to take the survey and get feedback.\n\n‚Ü©Ô∏é\nYou would subtract from 8, since 1+7 = 8. So a 7 for a negatively-keyed item on the 1-7 scale would be turned into a 1, since 8-7 = 1‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Measures</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html",
    "href": "chapters/5R_GoodScience.html",
    "title": "Why Research Methods?",
    "section": "",
    "text": "Part 1. Good Science [moved to chapter 1]\nIn this chapter, you‚Äôll learn how psychologists (and scientists) construct and share their knowledge.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#part-2.",
    "href": "chapters/5R_GoodScience.html#part-2.",
    "title": "Why Research Methods?",
    "section": "Part 2.",
    "text": "Part 2.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#part-3.",
    "href": "chapters/5R_GoodScience.html#part-3.",
    "title": "Why Research Methods?",
    "section": "Part 3.",
    "text": "Part 3.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#the-scientific-method-in-5-easy-steps",
    "href": "chapters/5R_GoodScience.html#the-scientific-method-in-5-easy-steps",
    "title": "Why Research Methods?",
    "section": "The Scientific Method in 5 Easy Steps",
    "text": "The Scientific Method in 5 Easy Steps\nSo, you‚Äôve defined a research question you are interested in? Yeah! The Scientific Method is used to help science progress toward valid (accurate, ‚Äútrue‚Äù) predictions and avoid biases. This is the same scientific method you may have learned about in a previous science class or used for a science fair project1. There are five parts, described below.\n1¬†¬†¬†Do elementary school students still do those science fair projects with the tri-fold posters? Adult scientists do the same kinds of science fairs, except they are called ‚Äúconferences‚Äù, involve a little more math, and use flat posters. I also don‚Äôt think anyone gets ribbons (status among scientists takes other less concrete forms). Some of the largest conferences include that held by the American Psychological Association or the Association of Psychological Science. The Western Psychological Association has a more local conference, and there are literally hundreds of other conferences based on research topic (for example, the Society of Personality and Social Psychology). If you are interested in learning more about conferences, ask your GSI what conferences they attend. And you even might be able to present your project in this class as a conference poster - no tri-fold needed.\nStep 1 : Identify a Question\nFirst, a researcher starts with a question about the variable that they want to predict or the psychological phenomenon they are interested in. In Chapter 1, we talked about how these questions are often informed by the researcher‚Äôs own observations or experiences.\nStill looking for a project topic? A few ideas to consider :\n\nThink about why you become a psychology major. Was it because you were interested in people, find dreams fascinating, wonder if you could get good at detecting people‚Äôs lies? Think about these interests, then think about what variables might be relevant. For example, while you won‚Äôt have access to an fMRI machine (or the required statistics) in order to reconstruct images people see during their dreams, you might study people‚Äôs beliefs about the importance of their dreams, or the extent to which they have dreams.\nFocus on a problem you‚Äôve encountered or observed in real-life. Notice that something in the world could be better? How would you label that as a variable? For example, maybe you want to better understand people‚Äôs attitudes about capitalism or racism or housing costs.\nLook at faculty webpages, and see what they (and / or their graduate students) are studying. Does anything seem interesting to you? Who looks like they might be cool to work with? What aspects of their research question might you study with this project?\nChase the latest trends of today. What‚Äôs capitalism care about these days? AI?\n\nBut you don‚Äôt have to take my word for it. Here‚Äôs another guide that might offer some help, or ask for help in the class discord / office hours / lecture!\n\nStep 2 : Develop a Theory\nA scientific theory is one that is comprehensive, explanatory, and supported by evidence. For example, the theory of evolution is comprehensive (it relates to all nature, not just plants or animals or finches), it is explanatory (it‚Äôs why we and cats both narrow our eyes when we are scared and angry), and it is supported (by over 100 years of evidence2).\n2¬†From fossil records to observations of fruit flies and plansRECAP : Statistical Models as a Question & Theory:\nAs discussed in Lecture 1, a scientific model identifies the variables that a researcher wants to predict (the dependent variable = the focus of the question) and the variables that the researcher thinks will explain the dependent variable (the independent variables).\nFor example, if my question is ‚ÄúWhat causes rain to fall in the sky?‚Äù, then my dependent variable would be listed as rain (sometimes it rains; sometimes it does not). If my theory is that it rains because there are dark clouds in the sky, then I would write my model as¬† : rain ~ clouds + error.\nMost scientists refrain from saying that a theory is ‚Äúproven‚Äù or ‚Äútrue‚Äù for two reasons:\n\nFirst, the scientific method is a process - our knowledge and ideas are continually updated. So it‚Äôs likely that the theory of evolution will be updated as we learn more about the complex ways genes replicate and interact with the environment. Saying that a theory is ‚Äúproven‚Äù is a common mistake - watch out for it!\nSecond, most scientists (and psychologists) draw from Karl Popper‚Äôs philosophy of science, which adheres to a requirement for science called falsifiability - the ability to find evidence that rejects a theory (‚Äúability to falsify‚Äù). This means a theory is never ‚Äòproven‚Äô because scientists are continually looking for evidence to reject the theory. It also means that a belief that cannot be tested or rejected would be rejected as a scientific belief - you have to be able to test your belief in some observable way. Falsifiability is where I think science separates from religious belief - someone with faith doesn‚Äôt need evidence, and that‚Äôs okay! It just doesn‚Äôt make the belief scientific under science‚Äôs narrow definition.\n\nHypotheses are specific predictions that researchers make about what they expect to see in the data if their theory is supported or is not supported by data.\n\nThe alternative hypothesis (sometimes written HA) is the researcher‚Äôs own belief. It may seem strange to label your belief ‚Äúalternative‚Äù when this word is used for things that are supposed to be different (‚Äúalternative rock = it‚Äôs not your parent‚Äôs rock & roll!‚Äù), and we are so used to thinking that our beliefs are the default that to call them alternative seems wrong. This is an example of previous beliefs bias, and the decision to label our beliefs as the ‚Äúalternative‚Äù is an example of science trying to correct this bias. It‚Äôs a small and symbolic correction, but it‚Äôs better than nothing.\nThe null hypothesis (sometimes written H0) is the label given for whatever evidence would not support the researcher‚Äôs belief.\n\nEXAMPLE : Let‚Äôs say you believe that smoking cannabis hurts a person‚Äôs memory. What‚Äôs the alternative hypothesis? What‚Äôs the null?\n\nNull Hypothesis : People who smoke cannabis will perform BETTER or NO DIFFERENT on a memory test than people who do not smoke marijauna.\nAlternative Hypothesis : People who smoke cannabis will perform WORSE on a memory test than people who do not smoke marijauna.\nMany students forget to include the ‚ÄúNO DIFFERENT‚Äù in the null hypothesis example above. However remember that the null hypothesis is everything that your theory is not. So if your theory is that smoking cannabis HURTS memory, then finding no difference in the memory of pot smokers vs.¬†non-smokers would not support your theory, and is thus part of the null hypothesis. (Note : some of y‚Äôall may have missed this because you are remembering learning about ‚Äúdirectional‚Äù vs ‚Äúnon-directional‚Äù hypotheses - we will discuss this more in Lecture 8.)\n\nCheck-In : Identifying Models, Null, and Alternative Hypotheses.Let‚Äôs review with a quick check-in to practice identifying models based on research questions and theories, and identifying the null and alternative hypotheses based on a given theory. As a reminder, check-ins are required, graded for completion, and will be used for you and me to gauge understanding.\n\n\nStep 3 : Collect Data\nAs described above, scientific theories are supported by evidence called data. How researchers collect data is something we will discuss in more detail over the next few weeks. In general, researchers have to figure out how to measure the variables they are interested in studying (e.g., ‚Äúhow will I know if someone is happy or not?‚Äù), and then find participants (people or animals) to study (e.g., ‚Äúwhose happiness should I study‚Äù).\nFor example, in our smoking cannabis example the decisions about how to measure memory (a music memory game or a word recognition task?) or how much cannabis (a little or a lot?) or who to study (Berkeley students or your grandparents?) in the study would likely influence the results.\nThe decisions that researchers make about how to define their measures and the participants they will study are very important, and will influence the results of the study (and thus our knowledge of the topic), so stay tuned for more discussion!\n\n\nStep 4 : Use Data to Test Theories\nFinally, researchers look to see if the data they collected supports or rejects their theory (and evaluate how strongly their theory is supported or rejected). We‚Äôll talk much more about using data to test theories this semester.\nIn our smoking cannabis example, the researcher would look to see which group did better on the memory test, and if the smokers did worse, then their theory would be supported (by this one study, at least).\n\n\nStep 5 : Repeat\nOnce a study is completed, researchers repeat the scientific method in two different ways.\nResearchers will sometimes repeat the exact same steps a second time - something called replication. Replication is critical to science.\nScientists also repeat the scientific method with a new question that is based on the results from their first study. Science is a process, and researchers are never done learning about how to better predict & control the world. There‚Äôs always more research to do. For example, after identifying a pattern between smoking cannabis and memory, a researcher might ask whether the type or dosage of cannabis intake would influence memory, whether abstinence could reverse the effects of memory impairment, or whether cannabis and coffee together might lead to a different result. Note that this is not an example of replication, since researchers are not testing the same question they had - but it‚Äôs repeating the scientific method for a new question inspired by the old. This is good, and part of scientific progress. But the problem is that the incentives for scientific publication focused almost entirely on ‚Äúnew‚Äù research, and not really making sure that the ‚Äúold‚Äù research was valid.\n\n\nIt‚Äôs Never Actually Easy\nScience is hard, and people are very complex, which makes psychological science very hard. Unfortunately, psychology is in a bit of a Replication Crisis. This crisis is two-fold a) researchers tend not to seek to replicate their (or others‚Äô) results, and b) systematic attempts to do so have suggested that the majority of results in psychology do not replicate3.\n3¬†You can go deeper into some of the drama surrounding the replication project here. lemme know what you think on the discord thread for this week.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#its-never-actually-easy",
    "href": "chapters/5R_GoodScience.html#its-never-actually-easy",
    "title": "Why Research Methods?",
    "section": "It‚Äôs Never Actually Easy",
    "text": "It‚Äôs Never Actually Easy\n\nThe Replication Crisis",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#bad-science",
    "href": "chapters/5R_GoodScience.html#bad-science",
    "title": "Why Research Methods?",
    "section": "Bad Science",
    "text": "Bad Science",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#reliability",
    "href": "chapters/5R_GoodScience.html#reliability",
    "title": "Why Research Methods?",
    "section": "Reliability",
    "text": "Reliability\n\nTest-retest reliability: asks us to evaluate whether we get the same result if we take multiple measures separated by time. If I think of self-esteem as a stable trait, I should expect to see some similarity in a person‚Äôs self-esteem at one time point and then the next day. Of course, there will be some change - self-esteem (and other personality variables) can be influenced by the situation and environment. But they shouldn‚Äôt be radically different if we have a good measure of this core aspect of the self.\nInter-rater / Inter-judge reliability: asks us to evalute whether multiple observers (or tools) make similar measurements. If I have two rulers made by the same company, I would expect them to give me similar answers for how tall I am. Similarly, two different observers who are reliable should make similar jugments about a person‚Äôs self-esteem, or the number of interruptions they count. If our measure is not reliable, then we might get different answers from the different people (or tools) making the measurement.\nInter-item reliability: When we learned about likert scales, we learned about Cronbach‚Äôs Alpha - a method of assessing how much the different items in a likert scale were related to each other. This is a form of reliability - specific only to likert scales where we have different questions that are all measuring the same thing. If the scale is reliable, we expect to get similar answers across the different items. For example, someone who says ‚ÄúI feel good about myself‚Äù should also say ‚ÄúI feel that I have a number of good qualities.‚Äù",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#validity",
    "href": "chapters/5R_GoodScience.html#validity",
    "title": "Why Research Methods?",
    "section": "Validity",
    "text": "Validity\nValidity is\n\nFace Validity :",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#bad-measures",
    "href": "chapters/5R_GoodScience.html#bad-measures",
    "title": "Why Research Methods?",
    "section": "Bad Measures",
    "text": "Bad Measures",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#journal-articles",
    "href": "chapters/5R_GoodScience.html#journal-articles",
    "title": "Why Research Methods?",
    "section": "Journal Articles",
    "text": "Journal Articles",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#example-phrenology-in-terms-of-validity-and-reliability",
    "href": "chapters/5R_GoodScience.html#example-phrenology-in-terms-of-validity-and-reliability",
    "title": "Why Research Methods?",
    "section": "Example : Phrenology in terms of Validity and Reliability",
    "text": "Example : Phrenology in terms of Validity and Reliability",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#footnotes",
    "href": "chapters/5R_GoodScience.html#footnotes",
    "title": "Why Research Methods?",
    "section": "",
    "text": "Do elementary school students still do those science fair projects with the tri-fold posters? Adult scientists do the same kinds of science fairs, except they are called ‚Äúconferences‚Äù, involve a little more math, and use flat posters. I also don‚Äôt think anyone gets ribbons (status among scientists takes other less concrete forms). Some of the largest conferences include that held by the American Psychological Association or the Association of Psychological Science. The Western Psychological Association has a more local conference, and there are literally hundreds of other conferences based on research topic (for example, the Society of Personality and Social Psychology). If you are interested in learning more about conferences, ask your GSI what conferences they attend. And you even might be able to present your project in this class as a conference poster - no tri-fold needed.‚Ü©Ô∏é\nFrom fossil records to observations of fruit flies and plans‚Ü©Ô∏é\nYou can go deeper into some of the drama surrounding the replication project here. lemme know what you think on the discord thread for this week.‚Ü©Ô∏é\nFor examples, in the common Intro Psych textbook written by Myers & DeWall (2018)‚Ü©Ô∏é\nPrestige is a very subjective concept in science. However, scientists have found many ways to quantify it, as described in the sections below!\n\n‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#bad-data-phrenology-in-terms-of-validity-and-reliability",
    "href": "chapters/5R_GoodScience.html#bad-data-phrenology-in-terms-of-validity-and-reliability",
    "title": "Why Research Methods?",
    "section": "Bad Data : Phrenology in terms of Validity and Reliability",
    "text": "Bad Data : Phrenology in terms of Validity and Reliability\nWatch the video below to review these terms, in the context of phrenology - an example of scientific racism.\n\n\n\n\n\n\nPhrenology is no longer considered a valid or reliable science, yet its presence still lingers in psychology, and is often taught as history without reference to its racist origins and consequences4. And as we have (and will continue to discuss) there are still many ways in which racism (and sexism, classism, and ableism) occur and affect psychology (and other sciences too).\n4¬†For examples, in the common Intro Psych textbook written by Myers & DeWall (2018)For example, more modern intelligence testing is often criticized for prioritizing White European values and language in the way it assesses supposedly ‚Äúobjective‚Äù knowledge. In an important test of this claim, the psychologist Robert Williams (pictured to the right) designed an IQ test that was as reliable as the default IQ test, but was ‚Äúbiased‚Äù to prioritize and value Black culture.\n\n\n\n\n\n\n\nAs seen in the table, Black students scored higher on this IQ test than White students - a point he (and others) use to emphasize the inherent biases in intelligence testing. Dr.¬†Williams also came to define the concept of Ebonics, and demonstrate that African American English is as much a complete language as ‚ÄúStandard‚Äù English.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#check-in-reliability-and-validity.",
    "href": "chapters/5R_GoodScience.html#check-in-reliability-and-validity.",
    "title": "Why Research Methods?",
    "section": "Check-In : Reliability and Validity.",
    "text": "Check-In : Reliability and Validity.\nTest your understanding of reliability and validity with the check-in above.\nBelow is a video to review the check-in answers, since these terms can be tricky :)",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#would-you-like-to-learn-more-optional-readings",
    "href": "chapters/5R_GoodScience.html#would-you-like-to-learn-more-optional-readings",
    "title": "Why Research Methods?",
    "section": "Would You Like to Learn More? [Optional Readings]",
    "text": "Would You Like to Learn More? [Optional Readings]\n\nHere‚Äôs a textbook chapter on the same topics. Note these authors use three terms to describe what I broadly call ‚Äúconvergent validity‚Äù. Internal consistency (a form of reliability) is measured with ‚Äúalpha reliability‚Äù (we will learn about this next week).\nDr.¬†Williams talks about his research here and here‚Äôs an episode of the TV show Good Times that Dr.¬†Williams consulted on. Here‚Äôs a link to his full study. Note that Dr.¬†Williams gave his intelligence test a name I don‚Äôt feel comfortable using because it is sexist :(. Times change, and it‚Äôs good to call out outdated language and update our terms accordingly :)\nLearn more about the racist history of how phrenology was produced and consumed and an article that conducted more recent researchto test phrenology‚Äôs theories.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#the-publication-process",
    "href": "chapters/5R_GoodScience.html#the-publication-process",
    "title": "Why Research Methods?",
    "section": "The Publication Process",
    "text": "The Publication Process\nResearchers spread their scientific knowledge by publishing research papers. You can read more about how researchers publish research HERE. However, the TLDR is something like this :\n\nResearcher has an idea! They assemble a team of others interested in the idea, and do a literature review in order to gain background knowledge on the topic.\nResearcher designs a study, collects data, analyzes the data, and writes up the data as a report. All the steps of the scientific method. This is what you will do for the final project!\nResearcher submits the report to a scientific journal. A journal is a collection of articles that are usually united by some common theme. In general, the shorter the name of the journal, the more prestigious5. For example, the ‚ÄúJournal of Research in Personality‚Äù is considered less prestigious than the ‚ÄúJournal of Personality and Social Psychology‚Äù, which is less prestigious than the journal called ‚ÄúPsychological Science‚Äù, which is considered less prestigious than the journal called ‚ÄúScience‚Äù.¬†\nAn editor decides whether to review or reject the article. Editors make an initial decision - based on a summary of the study and a letter that the author writes to the editor - whether the research article might be a good fit for the journal. If so, they pass it along to the next step. If not, they send a ‚ÄúThanks, but‚Ä¶.‚Äù rejection letter.\nThe editor sends the article to peer-reviewers. Peer reviewers are other researchers who have some related research interests or skills in the topic of the paper. They will look over the article. The editor may know these people, or they get asked by another peer-reviewer who didn‚Äôt want to do it but nominated someone else to step into the role. Peer-reviewers work on a completely voluntary basis - it‚Äôs seen as required service, and there‚Äôs a bit of professional reputation to maintain in doing this work. Yes, there are problems with unpaid labor in academia. We can chat about that if you‚Äôd like; ask questions / raise it as an issue on Discord.\nThe editor makes a decision on the paper based on the feedback from the peer-reviewers. The editor summarizes the feedback, and either accepts the paper, accepts as long as the person makes necessary revisions, asks the researcher to ‚ÄúRevise and Resubmit‚Äù (this is called an R&R - probably the most common outcome, and does not guarantee that the paper will be accepted if the revisions are made, but will get sent out to peer-reviewers again), or rejects the paper. In any case, the author will see the comments made by the peer-reviewers and the editor.\nThe (accepted) paper goes to a proofreader and is published. Hooray! This process probably takes anywhere from 6 months (insanely fast) to 2 years (or more, depending on the number of revisions that are required).\n\n5¬†Prestige is a very subjective concept in science. However, scientists have found many ways to quantify it, as described in the sections below!",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#publish-or-perish",
    "href": "chapters/5R_GoodScience.html#publish-or-perish",
    "title": "Why Research Methods?",
    "section": "Publish! Or Perish‚Ä¶?",
    "text": "Publish! Or Perish‚Ä¶?\nAsk any grad student or professor - the publication process is stressful, unpredictable, slow, and threatening. Grad students are required to publish papers in order to have a chance at an academic job as a researcher (and even extremely productive and thoughtful graduate students are not guaranteed an academic job), professors are required to publish papers in order to get a chance of getting tenure (and even extremely productive and thoughtful researchers are not guaranteed tenure).\nThis creates incredible pressure on researchers to get results; pressure that often can interfere with people‚Äôs ability to do GOOD science. We‚Äôll talk about this more throughout the semester; bring questions to class / Discord!",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#types-of-research-articles",
    "href": "chapters/5R_GoodScience.html#types-of-research-articles",
    "title": "Why Research Methods?",
    "section": "Types of Research Articles",
    "text": "Types of Research Articles\nWe‚Äôll learn how to read and dissect scientific articles this semester, but first it will be important to learn how to identify There are a few different types of articles that researchers write :\n\nOriginal Reports : An original report is where the researcher(s) write about the results of a novel study they did to test some theory. This means the researchers did something ‚Äúnew‚Äù - usually they collected and analyzed new data to test a theory, or analyzed existing data in a new way. Here‚Äôs an example of an original report on the topic of emotion regulation.\nReplication : A replication is a type of study where a researcher repeats the steps they (or another) researcher did, and sees if they get the same result. As we discussed, psychology (and many other fields) is in a replication crisis. This type of article was not very common before the 2010s, but is more common now. Still, faculty tend to be biased toward producing original reports - a school like Berkeley or Stanford would not hire a researcher just for doing replications. Here‚Äôs an example of a replication on the topic of emotion regulation. Note this is not really a direct replication, since they replicated in a different population.\nMeta-Analyses : A meta-analysis is where researchers take other people‚Äôs data, collect it, and analyze it in order to see broad trends across an entire field. For example, a meta-analysis might take all the research on whether there‚Äôs a relationship between playing violent video games and violent behavior, and analyze this existing research in terms of common themes, such as the type of video games the researchers studied, the measures of violence, and the results. Meta-Analyses can be a great way to look at a broad trend, but they rely on the assumption that the individual studies they summarize are, in fact, valid themselves. That is, if there are systematic biases in the way researchers study a topic, the Meta Analysis won‚Äôt solve or even identify those problems. Here‚Äôs an example of a meta-analysis done on the topic of emotion regulation.\nReview Article : Review articles summarize existing research without doing any additional data analysis (in contrast to a Meta-Analysis, in which there is data analysis of past research). This is the closest thing to a paper you might write in an English class - the authors take past research, summarize it in terms of common themes, and maybe highlight limitations, or new directions the field might take. Review articles are a great way to get a broad overview of a topic, since they summarize and organize past research, and will often highlight next steps that researchers should take. Here‚Äôs an example of a review article done on the topic of emotion regulation.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#the-peer-review-process",
    "href": "chapters/5R_GoodScience.html#the-peer-review-process",
    "title": "Why Research Methods?",
    "section": "The Peer Review Process",
    "text": "The Peer Review Process\nIn order to publish their results, researchers have their peers review their work, and provide comments or suggestions. The peer-review process ideally serves two purposes :¬†\n\nPeer Reviewers Help Improve the Research. The peers doing the reviewing are supposed to have expertise in the topic of the paper. This allows them to suggest ways to improve the paper. These suggestions can run from the simple (such as recommending other researchers to reference in the introduction or additional analyses to run) to very involved (suggestions for additional studies to run, different methods to use, or different people to study).\nPeer Reviewers Provide a Vote of Confidence in the Ideas and Analyses of the Paper. The editor of a journal will look to the peer reviewers for evidence that the research is ‚Äúhigh quality‚Äù and / or novel enough to be published. There‚Äôs a fair amount of bias here - some reviewers think the research is good but not considered a ‚Äúgood fit‚Äù for the journal. But the ‚Äúpeer-reviewed‚Äù label of a journal gives at least one layer of confidence that some other people like this research.\n\nOne important aspect of the peer-review process is that the peer-reviewers are anonymous to the author, and sometimes the author is anonymous to the peer-reviewers. Ideally, this helps prevent previous beliefs bias (since some researchers may have positive or negative impressions of each other) and social influence bias (since a famous researcher at a fancy school may have their research more trusted than someone with less prestige to their name or institution). However, psychological fields are often small enough that people tend to know who‚Äôs doing what research, and there are other cues that can tip peer-reviewers off about who the author of a study is (for example, the author of a study will likely reference their own work, since their new study builds off their old study.)\n\n\n\n\n\n\nAcademic Publishers are Predatory Capitalists.\n\n\n\n\n\n\n\nYou know how the music business can hurt artists and interrupt the free flow of groovy music??? Well, academic publishers are no different, and can make profits in the billions of dollars. They do this by charging exorbitant fees for accessing peer-reviewed articles, and not paying the researchers who publish papers any money. That‚Äôs right; researchers get a 0% commission of any sales of their academic articles. It is a horrible and corrupt system that deserves to die.\nBut you don‚Äôt have to take my word for it! You can read more about the problem with publishers and a (controversial) solution - sci-hub - here. Here‚Äôs an [OPTIONAL] longer articlethat goes into the history of academic publishing, and why it‚Äôs so corrupt. Here‚Äôs a videothat covers some of the same info. Here‚Äôs an even longer article that goes into sci-hub and ‚Äúscientific communism‚Äù. Feel free to skim or skip all of this! But lemme know if you read / found something you thought was interesting :)",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#finding-research-articles",
    "href": "chapters/5R_GoodScience.html#finding-research-articles",
    "title": "Why Research Methods?",
    "section": "Finding Research Articles",
    "text": "Finding Research Articles\nNext week we will find research articles related to YOUR research interests. I like to use Google Scholar for this - I find the search features powerful and Google will comb the internet for free versions of research articles (so I don‚Äôt have to be on campus or have proxy access to UC Berkeley‚Äôs library or ‚Äústeal‚Äù articles from publishers using sci-hub).\nFor example, searching for one of my dissertation chapters shows this page.\n\n\n\nHow to Find Articles\nSome tips for finding an article related to your topic :¬†\n\nUse the right ‚Äújargon‚Äù. As part of the operationalization process, scientists use specialized terms. What you might call ‚Äúholding it in‚Äù researchers call ‚Äúexpressive suppression‚Äù; a ‚Äújerk‚Äù would be someone ‚Äúlow in agreeableness‚Äù; that feeling of ‚Äúbeing hella stressed before an exam but also low key stepping up because of that stress‚Äù is the ‚Äúpsychophysiological distinction between challenge and threat‚Äù. As you search for research related to your topic, take note of how researchers are describing related phenomena, and adjust your terms as needed. This is part of building your schema for the topic.\nLook at past research on the topic. If you‚Äôve found a relevant article on your topic, it‚Äôs likely that the article has referenced other research that is also relevant. Read or scan through the introduction (or the references section) and see if there‚Äôs something that looks related to your interests.\nLook at future research on the topic. If you found a relevant article on your topic, it‚Äôs likely that other researchers have also read that article, and used it in their future research. Google Scholar has a ‚ÄúCited By‚Äù button []that you can use in order to see more recent articles that have referenced the article you found. This is a particularly useful way to find more recent research if you found a ‚Äúclassic‚Äù in the field, or check for replications or controversies.\nOld Research is Okay! But look for new research too. Many students wonder if an ‚Äúold‚Äù study is still relevant. Some papers are ‚Äúclassics‚Äù in the field, and great to read. But it‚Äôs likely that our field‚Äôs understanding of self-esteem has changed from 1970. If you are hoping to build your schema on a topic, finding a review article from the last 10 years (or 5; or 2!) would be a good place to start.\n\n\n\nHow to Evaluate an Article\nIt can often be overwhelming for students to sift through the masses of research on a topic and know what‚Äôs most important and relevant.¬†\nReading the article and using your critical thinking skills / psychological training is the best approach. To do this, it is recommended to go to Graduate School, where you canspend multiple years reading as much as you want on a beautiful college campus, taking classes where you can deeply engage with the research and ideas, immerse yourself in meaningful intellectual conversations had by other graduate students and kindly professors - the gleam of knowledge and excitement of supporting the next generation of researcher in their eye. Oh, that is not interesting to you / grad schools are flooded with applications / you can‚Äôt get an office hour appointment with your professor who actually / you don‚Äôt have the privilege of spending 5-8 years getting paid near-poverty wages to be a poor scholar?¬†\nWell, below are a few other ideas to make superficial , all depending on our good friend social influence bias :\n\nThe Citation Count. Google scholar allows you to see how many other research articles have referenced the article that you found. While this can be a nice way to see how influential a paper is, a paper could be referenced a lot for reasons other than its validity, and maybe no one has read the most amazing paper in the world.\nThe Impact Factor of the Journal. Journals have different ‚Äúprestige factors‚Äù, and the impact factor is one way to quantify this prestige. Impact factor is usually defined as the number of times the average article in a journal has been referenced by other researchers in a year. So an impact factor of 2 means that each article in that journal is referenced by two other articles in a year. The impact factor is something you have to look up - journals usually track this. I wouldn‚Äôt spend too much time worrying about it, but it‚Äôs a quick way to get a very superficial sense of the journal‚Äôs reputation. For example, let‚Äôs see how the impact factor relates to our rule of ‚Äúbroader journal name = more prestige‚Äù.\n\n\n\n\n\n\n\n\nJournal\nImpact Factor According to Google in 2024\n\n\nJournal of Research in Personality\n2.6\n\n\nJournal of Personality and Social Psychology\n6.4\n\n\nPsychological Science\n10.1 [couldn‚Äôt find a recent stat on this tho]\n\n\nScience\n44.7 [this escalated quickly]\n\n\n\n\nThe Researcher and Institution. Another way to evaluate an article is by evaluating the author. Does it look like this research has produced other cool research, or do you find their work boring and problematic for some reason? Is this researcher well known and respected in the field? Do they seem to have a happy photo with all their graduate students on their lab website, or is their lab website 10 years old and just has one sad looking graduate student asking for help with their eyes? Has the researcher continued to produce interesting, reliable research? Or were they the subject of a replication scandal?\n\n\n\nVideo Examples : Using Google Scholar to Find Research\n\nUsing Google Scholar\n\n\nHow to find articles, use the right jargon, and do some very superficial evaluations of the article‚Äôs quality.\n\n\n\nExporting APA Citations\n\n\nThe ‚Äú‚Äù button on Google Scholar makes life so much easier!! No more memorizing APA format!! Hooray!!!",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#specific-forms-of-validity",
    "href": "chapters/5R_GoodScience.html#specific-forms-of-validity",
    "title": "Why Research Methods?",
    "section": "Specific Forms of Validity",
    "text": "Specific Forms of Validity\n\nFace Validity: asks us to evaluate whether our measure or result look like what it should look like. This is a superficial (and somewhat subjective) judgment. But it is often a powerful and quick way to assess. For example, if I measure my height and it tells me 100 feet, I know something is wrong because there is no way I‚Äôm that tall. Or, when looking at a self-esteem measure, I would want to see items that look like self-esteem questions (‚ÄúI feel good about myself‚Äù.) If the self-esteem measure had other questions in it that didn‚Äôt really seem like they were measuring self-esteem (‚ÄúI like to look at myself in the mirror‚Äù) I would have questions about the face-validity of the measure. This seems super obvious, but it‚Äôs an important check - do the measures used actually look like what they should?\nConvergent validity: asks us to evaluate whether our measure similar to related concepts. When two things converge, they come together, and we want our measure to be similar to things that it should be similar to. For example, a measure of body height should be related to a measure of shoe size or tibia length. A measure of self-esteem should be similar to a measure of self-efficacy or satisfaction with life, since both are about how the person is subjectively seeing themselves. They shouldn‚Äôt be exactly the same thing, but we‚Äôd expect to see a pattern in the data. (We‚Äôll talk more about how to quantify these patterns when we learn more about linear models.)\nDiscriminant validity: asks about whether our measure is different from unrelated concepts. When two things diverge, they are different from one another. And we WANT our measure to be different from things that we expect them to be different from. For example, a measure of height should be different from a measure of reading speed or how organized a person is. We would expect self-esteem to be different from how social a person is (though maybe there‚Äôs some relationship since our society values sociability, and people who are social might get more positive messages from others, bolstering their self-esteem.) This is the hardest concept for students to get, but it‚Äôs a really important test of the validity of a measure. I not only want my measure to be related to concepts it should be related to, but also different from concepts it should be different from.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/5R_GoodScience.html#example-validity-and-reliability",
    "href": "chapters/5R_GoodScience.html#example-validity-and-reliability",
    "title": "Why Research Methods?",
    "section": "Example : Validity and Reliability",
    "text": "Example : Validity and Reliability\nThink about a scale. How would you evaluate the validity (face, convergent, discriminant) and reliability (test-retest / interjudge) of a bathroom scale? Think about this on your own, then look over the video key / guide below.\n\n\n\n\n\n\nExpand To See Answers\n\n\n\n\n\nWatch the video below to go over some possible answers, or just look over the table.\n\n\n\n\n\n\n\n\nface : does our measure or result look like what it should look like?\nhigh : I have a sense of what my weight should be (e.g, if it says 10 or 1000 i know either the units are wrong or scale is broken.)\n\n\nconvergent : is our measure similar to related concepts?\nhigh : my weight according to the scale is (somewhat) related to how much I stress eat, how little I exercise, my parents‚Äô weight, etc.\n\n\ndiscriminant : is our measure different from unrelated concepts?\nhigh : my weight is unrelated to intelligence, how much I love R, whether I wear sandals with or without socks, etc.\n\n\ntest-retest : do we get the same result if we take multiple measures?\nhigh : If I step on the scale and get a number, I should be able to step off the scale, step on again, and get the same number.\n\n\ninterrater reliability : would another observer make the same measurements?\nhigh : a different scale (same model and technology) should give me the same result as my scale.\n\n\ninter-item reliability : would one item in the likert scale be related to others?\nnot relevant. a bathroom scale is not a likert scale.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Why Research Methods?</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#recap-the-mean-and-linear-model-as-prediction",
    "href": "chapters/6R_LinearModels.html#recap-the-mean-and-linear-model-as-prediction",
    "title": "The Linear Model",
    "section": "RECAP : The Mean (and Linear Model) as Prediction",
    "text": "RECAP : The Mean (and Linear Model) as Prediction\nPreviously, we learned how the mean was a simple way to make a prediction about individuals.\nFor example, if you wanted to know whether it would rain today, you might look at the average rainfall for today‚Äôs date, and use that average for your prediction.\nLet‚Äôs review this idea, and set up the linear model, by working with a classic dataset in teaching statistics - the Prestige dataset. These data are contained in the car package, and are used in one of the classic R textbooks - John Fox‚Äô Applied Regression Analysis and Generalized Linear Models (2nd Edition).\n\n\nCode\n# install.packages(\"car\") # this installs a package - you only need to do this ONCE. Remove the # to run this code.\nlibrary(car) # loading the library - make sure you installed it first!\n\n\nLoading required package: carData\n\n\nCode\npresto &lt;- Prestige # creating a copy of the dataset so you don't mess something up :)\nnames(presto) # tadaa!!\n\n\n[1] \"education\" \"income\"    \"women\"     \"prestige\"  \"census\"    \"type\"     \n\n\nYou can read more about these variables by typing in ?Prestige to access the help page for the dataset. For this lecture, we‚Äôll be working with the variable prestige, which is a measure of how prestigious certain jobs were, in Canada, in the 1960s1. Note that individuals in this dataset are not people, but people‚Äôs attitudes about types of jobs.\nThe graph to the right illustrates variation in this variable, as well as how the mean of prestige is the value that is closest to all the scores in the distribution.\nThe graph below 2 is defined by the following equation :\n\\(\\huge y_i = \\hat{Y} + \\epsilon_i\\)\n\n\nCode\nplot(presto$prestige)\nabline(h = mean(presto$prestige), lwd = 5, col = 'red',\n       xlab = \"Index (Individual Row Number)\",\n       ylab = \"Individual Prestige Score\")\n\n\n\n\n\n\n\n\n\n\n\nHere‚Äôs a guide to what‚Äôs in the equation and on the graph!\n\\(\\Large y_i\\) = the DV = the individual‚Äôs actual score we are trying to predict (remember \\(_i\\) = index; a specific individual.)\n\non the graph: each individual dot (on the y-axis; the x-axis just describes when people submitted the survey.\n\n\\(\\Large \\hat{Y}\\) = our prediction (the mean).\n\non the graph: the solid red line\n\n\\(\\Large \\epsilon\\) = residual error = distance between the predicted values of y and the individual‚Äôs actual value of y\n\non the graph: the distance between each dot and the line.\n\nThe equation is fancy way of saying that an individual‚Äôs actual scores = our prediction (the mean) + error.\nThe mean was a good starting place to make predictions for two reasons :\n\nBy definition, the mean is the value that is closest to all the scores. In other words, the mean minimizes the error in our predictions.\nThe mean is static (it does not change), meaning we can make the same prediction for every person. This is a good place to start, but obviously there‚Äôs a lot of error in our predictions. In fact, using our knowledge of residual errors, we can calculate this total (squared) error when we use the mean to make a prediction.\n\n\nCode\nresidual &lt;- presto$prestige - mean(presto$prestige)\nsum(residual^2)\n\n\n[1] 29895.43\n\n\n\nThis value is the total sum of the squared residuals (also called the sum of the squared errors or often abbreviated SST when focused on the residuals of the mean.\nTLDR : we are interested in a variable (prestige), we can make pretty good predictions about prestige based on the mean (since by definition the mean is closest to all the scores in the data), and we are able to quantify how good our prediction is by calculating the sum of squared errors.\nNext, we‚Äôll try to improve upon our predictions of prestige.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>The Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#the-linear-model-its-just-a-line-with-a-slope",
    "href": "chapters/6R_LinearModels.html#the-linear-model-its-just-a-line-with-a-slope",
    "title": "The Linear Model",
    "section": "The Linear Model : It‚Äôs Just a Line (With a Slope)",
    "text": "The Linear Model : It‚Äôs Just a Line (With a Slope)\n\nBasic Concept.\nThe linear model is a simple, yet flexible, way to make predictions about one variable (the DV or y). There are many types of models, but most follow the same basic principles that we will review in this document. The mean is actually a linear model in its simplest form : y ~ 1 + error, with 1 serving as a constant value (the mean!).\nThe mean is a great starting place, but it‚Äôs limited because it‚Äôs static - we have the same prediction for everyone in the dataset, when we know that people differ. So we will want to come up with predictions that change, depending on what we learn about another person. This is something I refer to as the principle of covariation. It‚Äôs a simple idea - if there‚Äôs a pattern in how two things vary, then we can use information about one variable to make a prediction about what will happen for the other variable. This is what we talked about earlier in the semester when we discussed the idea of prediction - we‚Äôre just formalizing this idea with numbers now.\nSo, as a conceptual example, there is variation in rain (some days it rains and some days it does not) and there is variation in clouds (bright skies some days; clouds other days). The covariation happens as I notice that on days when it rains (variable = rain), it also tends to be cloudy (variable = clouds). These two variables vary together (they ‚Äúco-vary‚Äù). Of course, this pattern isn‚Äôt always true - there‚Äôs error.\nI could write this as a model, where my predictions about whether it will rain will be influenced by whether I see clouds in the sky : rain = clouds + error\nI would use this model to make an adjustment to my prediction when it rains - if there are clouds, I might think it‚Äôs more likely that it will rain. That is, the presence of clouds changes my prediction. This change is a critical idea, and will be important to quanity - how large is the change? Does it improve my predictions?\nAs another example, think about how you would write an equation to model the idea that on days when it‚Äôs raining, I tend to hear raindrops (and on days when it‚Äôs not raining, I don‚Äôt tend to hear raindrops). I might write this model as rain = rain sounds + error\nThese two models look similar, but are not equal. If I had to guess, I‚Äôd say that hearing rain is a better way to make predictions of rain than looking at the clouds, meaning there would be less error in my predictions. So not only do models use information about which variables you can use to make predictions about another, but they also tell you how much you should update your predictions about one variable from another.\n\n\nPrestige Example\nReturning to our previous example, let‚Äôs predict the variable prestige from the variable education - another continuous variable in the Prestige dataset. As a linear model, I would write this as : prestige = education + error\nIn the same way I could expect rain sounds to be related to rain, a job that requires more years of education might be related to how prestigious the job is. This is not true of all careers (consider the ‚Äúhigh educated‚Äù poet ridiculed by society, perhaps, or the ‚Äúlow educated‚Äù firefighter revered by society3.\nLet‚Äôs graph these two variables side by side.\n\n\nCode\npar(mfrow = c(1,2)) # splits my graphing window\nhist(presto$prestige, col = 'black', bor = 'white', main = \"\")\nhist(presto$education, col = 'black', bor = 'white', main = \"\")\n\n\n\n\n\n\n\n\n\nGreat. So both prestige and education vary. Not every job has the same prestige, and not every job requires the same years of education.\nThe question is whether these two variables covary. Are changes in prestige related to changes in education??\nPop Quiz: How can you see the relationship between prestige and education in the graphs above?\n::: {.callout-tip collapse = ‚Äútrue‚Äù} You cannot!!! I‚Äôm guessing that some of you are thinking that because both distributions are slightly positively skewed, this means that there is some covariation between these variables. However, this is an example of patterns in randomness - we can‚Äôt really tell whether there is covariation from these two separate graphs. Instead, we need a different kind of graph that explicitly draws a connection between these two separate variables. This is the scatterplot, which you will learn about below :) :::\n\n\nThe Scatterplot\nIn order to examine how these two variables covary (that is, how variation in education is related to variation in prestige), we need to use a scatterplot.\nA scatterplot graphs individual scores in terms of one variable on the Y axis (the vertical line) and the other variable on the X axis (the horizontal line).\nTo graph a scatterplot, you can use the plot() function, and tell R to predict one variable (in this case prestige) from another (education).\nTake a look at the graph below - what do you see?\n\n\nCode\nplot(prestige ~ education, data = presto)\n\n\n\n\n\n\n\n\n\nWatch the video below for an explanation of what‚Äôs going on in the graph.\n\nTo define the model (as I did in the video), we just need to use a few lines of code.\n\n\nCode\nmod &lt;- lm(prestige ~ education, data = presto) # this defines the model, and then saves it to an object (called mod)\ncoef(mod) # this shows me the values of the model\n\n\n(Intercept)   education \n -10.731982    5.360878 \n\n\nThe linear model is just another line that updates our predictions of one variable based on knowledge of another.\nThis line (in red, on the graph below) has the following equation :\n\\(\\huge y_i = a + b_1 * X_i + \\epsilon_i\\)\n\n\nCode\nplot(prestige ~ education, data = presto, # plots the model again\n     xlim = c(0, 16),  # changes my x-axis to range from 0 to 16\n     ylim = c(-20,90)) # changes my y-axis to range from -15 to 90\nabline(mod, col = 'red', lwd = 5) # this adds the line to my graph.\n\n\n\n\n\n\n\n\n\n\n\n\\(\\Large y_i\\) = the DV = each individual‚Äôs actual score on the dependent variable.\n\non the graph: the value of each dot on the y-axis\n\n\\(\\Large a\\) = the intercept = the starting place for our prediction. You can think of the intercept as ‚Äúthe predicted value of y when all x values are zero‚Äù.)\n\non the graph : the value of the line at X = 0\n\n\\(\\Large X_i\\) = the IV = the individual‚Äôs actual score on the independent variable (a different variable than the DV).\n\non the graph : the value of each dot on the x-axis\n\n\\(\\Large b_1\\) = the slope = an adjustment we make in our prediction of y, based on the individual‚Äôs x value.\n\non the graph: how much the line increases in y value when x-values increase by 1 unit.\n\n\\(\\Large \\epsilon_i\\) = residual error = the distance between our prediction and the individual‚Äôs actual y value.\n\non the graph: the distance between each individual data point and the line.\n\n\n\n\n\n\n\nCheck-In: Intercepts and Slopes\n\n\n\n\n\nTest your understanding of linear models! Use the Prestige dataset and R to predict the variable income (the DV) from the variable education (the IV). You can try to do this in R on your own computer, or use the output below. Use this model to answer the questions for this check-in in the link above.\n\n\n\nCall:\nlm(formula = income ~ education, data = presto)\n\nCoefficients:\n(Intercept)    education  \n    -2853.6        898.8",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>The Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#footnotes",
    "href": "chapters/6R_LinearModels.html#footnotes",
    "title": "The Linear Model",
    "section": "",
    "text": "Super exciting! But remember this is like driving around a safe, boring parking lot!! We‚Äôll hit the highway soon enough.‚Ü©Ô∏é\nNOTE: Eagle eyed students may note something odd about the way the data are arranged on this graph - it looks like there‚Äôs some quadratic (curved) pattern in the way the data are arranged. Because the x-axis for this graph (the index) is the row in which each data, all this quadratic pattern means is that more prestigious jobs tended to be listed earlier in the dataset than less prestigious jobs.‚Ü©Ô∏é\nAnd good to explore why we care about prestige in careers anyway? I blame capitalism and our society‚Äôs unwillingness to provide people with their basic needs, so a person‚Äôs value is determined by how much their material conditions, and whether they can meet (or exceed) those basic needs. Anyway, point is firefighters and poets are both cool and important for society.‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>The Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#visualizing-residual-error-in-the-model",
    "href": "chapters/6R_LinearModels.html#visualizing-residual-error-in-the-model",
    "title": "The Linear Model",
    "section": "Visualizing Residual Error in the Model",
    "text": "Visualizing Residual Error in the Model\nThis is similar to what we did with the mean - we draw a line that is close to all the individual scores, and then calculate the sum of the squared errors. However, whereas the mean yields the same prediction for each individual (and the line is flat), the linear model yields a specific prediction for each individual‚Äôs y score, based on the value of x (and the line has a slope).\nBelow are two graphs - the one on the left uses the mean to make predictions of prestige, and the one on the right uses education to make predictions of prestige (our model).\nLook at the two graphs - can you tell which one has more (or less) residual error?\n\n\nCode\npar(mfrow = c(1,2))\nplot(presto$prestige)\nabline(h = mean(presto$prestige), lwd = 5, col = 'red')\nplot(prestige ~ education, data = presto, # plots the model again\n     xlim = c(0, 16),  # changes my x-axis to range from 0 to 16\n     ylim = c(-20,90)) # changes my y-axis to range from -15 to 90\nabline(mod, col = 'red', lwd = 5) # this adds the line to my graph.\n\n\n\n\n\n\n\n\n\nJust by looking at two graphs, it‚Äôs clear that there‚Äôs less residual error when we use education to make predictions of prestige (vs.¬†using the mean). In other words, the individual scores are further from the red line on the left graph than on the right graph.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>The Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#calculating-residual-error-in-the-model",
    "href": "chapters/6R_LinearModels.html#calculating-residual-error-in-the-model",
    "title": "The Linear Model",
    "section": "Calculating Residual Error in the Model",
    "text": "Calculating Residual Error in the Model\nStill, we are going to want to calculate these differences to describe just how much better our predictions are. What makes this potentially more challenging is that when we use a model to make predictions for individual scores, we will predict a different value for each individual based on the result of our model. For example, a job that requires 6 years of education will have a different predicted value of prestige than a job that requires 7 years of education.\nFortunately, R does the hard work of making predictions for us, and even saves the residual errors as part of the model output.\nFor example, from our model where we predicted prestige from education:\n\n\nCode\nhead(mod$residuals) # these are the residuals (the errors from our model)\n\n\n gov.administrators    general.managers         accountants purchasing.officers \n           9.250875           14.107621            5.673573            6.310758 \n           chemists          physicists \n           5.855950            4.487854 \n\n\nCode\nhead(mod$residuals^2) # these are the squared residuals\n\n\n gov.administrators    general.managers         accountants purchasing.officers \n           85.57869           199.02497            32.18943            39.82567 \n           chemists          physicists \n           34.29215            20.14084 \n\n\nCode\nsum(mod$residuals^2) # these are the sum of the squared residuals when using the model to make predictions\n\n\n[1] 8286.99\n\n\nNotice that the sum of the squared errors for this model, where we use education to predict prestige, is less than the sum of the squared errors from the model where we used the mean to make predictions.\nIn fact, we can calculate exactly how large this difference in errors is between the two predictions.\n\n\nCode\nSSM &lt;- sum(mod$residuals^2) # saving the sum of the squared errors from the model\nSST &lt;- sum(residual^2) # saving the sum of the squared errors from the mean\nSST - SSM # the difference in the squared errors from the mean vs. the model\n\n\n[1] 21608.44\n\n\nThis tells me that the model where we use education to predict prestige reduces the squared error by 21608.44. That is a large number! But it‚Äôs hard to understand how large it is, because it‚Äôs missing context.\nTo provide this number context, we can describe how large this reduction in residual error is, relative to the original residual error that we had when we used the mean to make predictions.\n\n\nCode\n(SST - SSM)/SST\n\n\n[1] 0.7228007\n\n\nThis number (.72) means that using education to predict prestige explains 72% of the total variation in prestige (when you use the mean to make predictions). If this sounds like a large percentage, you would be right - there‚Äôs no ‚Äúrule‚Äù about what counts as a large or little percentage of variation explained.\nThis statistic is called \\(R^2\\) (‚Äúr-squared‚Äù), and is defined by the following equation.\n\\(\\Huge R^2 = \\frac{SS_{total} - SS_{model}}{SS_{total}}\\)\nWhat \\(R^2\\) does is contextualize our reduction in error, by describing how much less error we have in our model, compared to the error that we had when using just the mean to make predictions.\n\nAnother way to think of \\(R^2\\) is that it describes the percentage of variation in the DV that our model is able to predict or explain.\n\\(R^2\\) can range from 0 to 1. The closer to zero, the less our model improves upon predictions (because 0 = no difference between the error when using the mean to make predictions and the error when using the model to make predictions). The closer to one, the more our model improves upon predictions. An \\(R^2\\) of 1 would mean that you are making perfect predictions. If this happens, you have probably done something wrong.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>The Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#video-example-age-and-narcissism",
    "href": "chapters/6R_LinearModels.html#video-example-age-and-narcissism",
    "title": "The Linear Model",
    "section": "Video Example : Age and Narcissism",
    "text": "Video Example : Age and Narcissism\nRemember our Narcissistic MBA students? They‚Äôre back, in Linear Model form!!!!\n\nlink to the R script I used for this video\n\n\n\n\n\n\n\n\nCheck-In : Understanding \\(R^2\\)\n\n\n\n\n\nHere‚Äôs a super quick check-in on interpreting \\(R^2\\) values!",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>The Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#recap-uhhhcan-you-re-explain-z-scoring-professor",
    "href": "chapters/6R_LinearModels.html#recap-uhhhcan-you-re-explain-z-scoring-professor",
    "title": "Linear Model : Continuous IV",
    "section": "RECAP : Uhhh‚Ä¶can you re-explain Z-Scoring Professor???",
    "text": "RECAP : Uhhh‚Ä¶can you re-explain Z-Scoring Professor???\nA z-score describes how far an individual score falls above and below the mean (a residual!) in units of standard deviation. Z-scores are used to help give context to data - how far above or below the average is an individual (their distance from the mean), compared to the standard deviation (the average amount that people differ from the mean).\nZ-scores can also be useful when the units of measurement don‚Äôt have any meaning. For example, let‚Äôs say you take a job on Jeff Bezo‚Äôs Mars ‚Ñ¢ and learn that a job pays 1298723 BezosBucks. Is this a little? A lot? Well, knowing that it‚Äôs 120 BezosBucks above the average income might give you some indication that you are going to be better off than others on Jeff Bezos‚Äô Mars ‚Ñ¢. But how much better off?\nIf you learn the standard deviation of income on Jeff Bezos‚Äô Mars ‚Ñ¢ is 12, then your above average salary is 10 times more than what you‚Äôd expect the average person to differ from the average salary - you are gonna be VERY RICH compared to the average resident - drinking fresh water and breathing air created by the finest asteroidoxygenators!\nBut if the standard deviation is 1200, then your z-score = .1, which means you are only a tenth of a standard deviation above average, which means that you will be lumped with the masses on Jeff Bezos‚Äô Mars - slurping recycled air with the rest of us.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Linear Model : Continuous IV</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#why-z-score-in-a-model",
    "href": "chapters/6R_LinearModels.html#why-z-score-in-a-model",
    "title": "The Linear Model",
    "section": "Why Z-Score in a Model",
    "text": "Why Z-Score in a Model\nIn a linear model, the slope describes the relationship between the two variables in whatever units the DV and the IV were measured in. So in our prestige example, the slope of 5.36 means that for every 1-unit increase in years of education, our prediction of prestige goes up by 5.36 points. Is that a little change in prestige? A lot? It‚Äôs hard to know, since prestige is not tangible, but a human-created construct.\nWhich brings us back to z-scores. If we z-score both the DV and the IV in our linear model, the (arbitrary) units of measurement disappear, and both variables are described in terms of standard deviation. This allows us to better relate each variable to another. To z-score the variables in a model, you just use the scale() function inside the linear model.\nClick the tabs to switch between Raw Units and Z-Scored Units. What changes? What stays the same??\n\nLinear Model in Raw UnitsLinear Model in Z-Scored Units\n\n\nHere‚Äôs the graph, in the original units of measurement.\n\n\nCode\nplot(prestige ~ education, data = presto, \n     ylab = \"Prestige (Raw Units)\",\n     xlab = \"Education (Years)\") \nmod &lt;- lm(prestige ~ education, data = presto)\nabline(mod, lwd = 5, col = 'red')\n\n\n\n\n\n\n\n\n\nAnd here‚Äôs the result of the model.\n\n\nCode\nround(coef(mod), 2)\n\n\n(Intercept)   education \n     -10.73        5.36 \n\n\n\n\nHere‚Äôs the graph when the DV and IV are Z-Scored.\n\n\nCode\nplot(scale(prestige) ~ scale(education), data = presto, \n     ylab = \"Prestige (Units of Standard Deviation)\",\n     xlab = \"Education (Units of Standard Deviation)\") \nzmod &lt;- lm(scale(prestige) ~ scale(education), data = presto)\nabline(zmod, lwd = 5, col = 'red')\n\n\n\n\n\n\n\n\n\nAnd here‚Äôs the result of the model.\n\n\nCode\nround(coef(zmod), 2)\n\n\n     (Intercept) scale(education) \n            0.00             0.85 \n\n\n\n\n\n\nInterpretation of Z-Scores\nAs before, the data do not change - the only thing that changes are the units in which the DV and IV are measured (and thus the units of the intercept and slope).¬†\n\nThe intercept of a z-scored model will always be zero (or something very near zero). Remember that a z-score of zero means average, and the intercept is defined as ‚Äúthe predicted value of the DV when all IVs are zero.‚Äù This means that‚Ä¶.\n\n‚Ä¶the predicted value of the DV is zero when the IV is zero.\n‚Ä¶someone with the average IV (IV = z-score of zero) is predicted to have the average DV (DV = z-score of zero), or¬†\n\nThe slope of a z-scored model describes the relationship between the variables in units of standard deviation. When both the DV and IV share the same units of measurement, the slope becomes a lot more informative, since it tells you exactly how linked the two variables are. Knowing that for every 1-unit increase in years of education, the predicted prestige goes up by 5.36 (the slope) makes far less sense to me than knowing that for every standard deviation increase in years of education, the predicted prestige goes up by .85.\n\nThe maximum slope of a z-scored linear model (with one IV) is 1 (one). This would be a perfect positive relationship, where a one standard deviation increase in the IV is equal to a one standard deviation increase in the DV.¬†\nThe minimum slope of a z-scored linear model (with one IV) is -1 (negative one). This would be a perfect negative relationship, where a one standard deviation increase in the IV is equal to a one standard deviation decrease in the DV.¬†\nA slope of zero would mean that there‚Äôs no relationship between the two variables.\nWait a minute‚Ä¶that‚Äôs‚Ä¶.CORRELATION COEFFICIENT‚ÄôS MUSIC.\n\n\nYes, class, a correlation - the relationship between two variables, is just the standardized (z-scored) slope of a linear model (with one IV).\n\n\nCode\ncor(presto$prestige, presto$education) # the correlation\n\n\n[1] 0.8501769\n\n\nCode\ncoef(zmod)[2] # the slope of our z-scored model\n\n\nscale(education) \n       0.8501769 \n\n\nWow! We will chat more about this in the video below, and in lecture next week :) thanks for reading!\n\n\nVideo Example : Age and Narcissism (Z-Scored)\n{{&lt; https://youtu.be/2jYwIOTaQ6g  &gt;}} The video above walks through z-scoring in another example, from the narcissism dataset.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>The Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#section",
    "href": "chapters/6R_LinearModels.html#section",
    "title": "Linear Model : Continuous IV",
    "section": "",
    "text": "Tip",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Linear Model : Continuous IV</span>"
    ]
  },
  {
    "objectID": "chapters/6R_LinearModels.html#check-out-understanding-z-scores-and-this-chapter-document",
    "href": "chapters/6R_LinearModels.html#check-out-understanding-z-scores-and-this-chapter-document",
    "title": "The Linear Model",
    "section": "CHECK-OUT : Understanding Z-Scores and this Chapter! Document",
    "text": "CHECK-OUT : Understanding Z-Scores and this Chapter! Document",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>The Linear Model</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#recap-working-with-categorical-factor-and-levels",
    "href": "chapters/7R_CategoricalIV.html#recap-working-with-categorical-factor-and-levels",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "RECAP : Working With Categorical Factor and Levels",
    "text": "RECAP : Working With Categorical Factor and Levels\nIt‚Äôs been a while since we focused on categorical variables. As a reminder, a categorical variable measures variation in terms of groups. The specific groups are called levels, and the broad name for the groups is called a factor.¬†\nFor example, in the ‚ÄúMBA Business Student Data‚Äù (hormone_data.csv) researchers measure the variable sex as a categorical factor, with just two levels : female and male1.\n\n\nCode\nmba &lt;- read.csv(\"~/Dropbox/!WHY STATS/Class Datasets/hormone_data.csv\", stringsAsFactors = T)\nmba$sex\n\n\n  [1] male   male   male   male   male   female male   male   male   male  \n [11] male   male   male   male   male   male   male   male   male   male  \n [21] male   male   male   male   male   male   male   male   male   male  \n [31] male   male   male   male   male   male   male   male   male   male  \n [41] male   male   male   male   male   male   male   male   male   female\n [51] female female female female female female female female female female\n [61] female female female female female male   male   male   male   male  \n [71] male   male   male   male   male   male   male   male   male   male  \n [81] male   male   male   male   male   male   male   male   male   male  \n [91] male   male   male   male   male   male   male   male   male   male  \n[101] male   male   male   male   female female female female female female\n[111] female female female female female female female female female female\n[121] female female\nLevels: female male\n\n\nI can use the plot() function to illustrate this variable, and summary() function to report the number of individuals in each group.\n\n\nCode\nplot(mba$sex)\n\n\n\n\n\n\nSex, Graphed and Summarized\n\n\n\nCode\nsummary(mba$sex)\n\n\nfemale   male \n    35     87",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#a-conceptual-example",
    "href": "chapters/7R_CategoricalIV.html#a-conceptual-example",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "A Conceptual Example",
    "text": "A Conceptual Example\nThe equation for a linear model with a categorical IV is identical to what we‚Äôve seen before :¬†\n\\(\\huge y_i = a + b_1 * X_i + \\epsilon_i\\)\nWe are making a prediction about some dependent variable (\\(y_i\\)) from a linear equation that has an intercept (\\(a\\), the starting place for our prediction), and then a slope (\\(b_1\\) an adjustment we make) based on information about another (independent) variable (\\(x_i\\)).\nFor this first example, let‚Äôs define a model to predict narcissism (how self-centered and egotistical a person says they are) from the person‚Äôs sex.\nBefore we jump to the linear model, let‚Äôs graph our dependent variable using the hist() function, since the variable is numeric. In the mba dataset, NPI (Narcissistic Personality Inventory) is what researchers defined for Narcissism\n\n\nCode\nhist(mba$NPI, col = 'black', bor = 'white', main = \"\", xlab = \"Narcissism (NPI) Score\", xlim = c(1,5))\n\n\n\n\n\n\nNarcissism Variable, Graphed\n\n\n\nThe data look good - I don‚Äôt see any outliers or problems in the data, and while it seems a little odd nobody said they were a 1 in terms of narcissism, the distribution is mostly normal and maybe everyone‚Äôs a little narcissistic?\nIn the graph below, I‚Äôm using the plot function to illustrate the individual narcissism scores.\nEach individual narcissism score is a dot defined by the value on the y-axis, and their index (position in the dataset) is located on the x-axis. So the individual in the top left corner has a narcissism score of around 4.45, and was one of the first people to provide data (the index is not super relevant).\nSee if you can guess where the mean is; illustrated as a horizontal line that goes closest to all the individual narcissism scores, such that the sum of the residual errors will be zero. Click the tab to see where the mean is actually is.\n\nWhere is the Mean???Here is the mean!\n\n\n\n\nCode\nplot(mba$NPI, pch = 19, ylab = \"Narcissism Score\", xlab = \"Index (Position in Dataset)\",\n     main = \"Plot of Individual Narcissism Scores\")\n\n\n\n\n\n\n\n\n\nCode\n# abline(h = mean(mba$NPI, na.rm = T), lwd = 5)\n\n\n\n\n\n\nCode\nplot(mba$NPI, pch = 19, ylab = \"Narcissism Score\", xlab = \"Index (Position in Dataset)\",\n     main = \"Plot of Individual Narcissism Scores\")\nabline(h = mean(mba$NPI, na.rm = T), lwd = 5)\n\n\n\n\n\n\n\n\n\n\n\n\nHow did you do? I was a little low on this one. Okay; let‚Äôs keep moving.\nThe graph below illustrates the same data, however this time I‚Äôve asked R to color the dots based on the variable sex. In this graph, red dots illustrate the narcissism score for males in the dataset, the black dots illustrate the narcissism score for females in the dataset. Narcissism scores are on the y-axis, and the x-axis again indicates the index of the individual.\nTake a moment and look at this graph - what do you observe?\n\n\nCode\nplot(mba$NPI, pch = 19, col = mba$sex, ylab = \"Narcissism Score\", xlab = \"Index (Position in Dataset)\",\n     main = \"Plot of Individual Narcissism Scores\\nGrouped By Sex (Red = Male, Black = Female)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Professor Sees.\n\n\n\n\n\n\nI see that there are more red dots than black dots. This matches what I know about the variable ‚Äòsex‚Äô - there were more Male MBA students than Female MBA students in the data.\nI see that there are some clusters of where red and black dots occur. For some reason, the males and females are grouped - my guess is that these data were collected in two waves (maybe two classes of students) and were organized in each class by sex. This is not super relevant to the data, but\nI see that more of the red dots are higher on the y-axis than the black dots. This is not super easy to see, but there seems to be a trend there - the red dots are slightly higher on average than the black dots. But you don‚Äôt have to take my word for it, this is what the linear model does!\n\n\n\n\nOkay, time to play‚Ä¶.WHERE‚ÄôS‚Ä¶THAT‚Ä¶.LINE!!!! (crowd of students go wild). Think about where you would draw two horizontal lines in the graph above - one that is closest to all the red dots and one that is closest to all the black dots.\n\nWhere‚Äôs the line?The Black LineThe Red Line!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWow! How did you do??? Professor‚Äôs observations from the graph on the last page appear to be correct; the red dots tend to be higher than the black dots.\nI can see this on the graph because the red line (which is the average of the red dots) is higher than the black line (which is the average of the black dots).\nThis is the core idea of a linear model - we are making predictions of one variable (y = the DV = Narcissism) from another variable (x = the IV = sex). For people who are male (the red dots), we are going to predict a narcissism score of around‚Ä¶..3.3 (where the red line hits the y-axis). Not every male has this exact same narcissism score (life is complex!) - we can see the residual error of red dots above and below this line (we will get to calculate this soon; hooray!) - but this red line defines the trend.\nFor people who are female, we can predict a narcissism score of around 3 (where the black line hits the y-axis). Not every female has this exact same narcissism score, but the line defines the trend.\nAnd now, we can calculate the difference between these two groups - 0.3 - as the slope - the change we make in our predictions of narcissism depending on whether the person is male or female. Wow.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#the-four-reasons-why-youd-observe-a-pattern-in-the-data",
    "href": "chapters/7R_CategoricalIV.html#the-four-reasons-why-youd-observe-a-pattern-in-the-data",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "The ‚ÄúFour Reasons‚Äù Why You‚Äôd Observe a Pattern in the Data",
    "text": "The ‚ÄúFour Reasons‚Äù Why You‚Äôd Observe a Pattern in the Data\n\nExample : The Mascot Dataset\nLast lecture, we saw that there was a relationship between how much explicit prejudice against indigenous groups people reported, and their love for a native american mascot.\n\n\n\n\n\nWatch the video below to learn about the ‚Äúfour reasons‚Äù why we might observe this pattern in the data.\n\n\n\n\n\n\n\n\n\nReason\nDefinition\nmascot attitudes ~ indigenous prejudice + error\n\n\n\ncausation\n\nthe IV causes the DV to happen\nprejudice causes people to dehumanize others, and see them as mascots;\n\n\n\nreverse causation\n\nthe DV causes the IV to happen\nliking the mascot causes people to become more prejudiced.\n\n\n\nthird / confound variable\n\nthere‚Äôs some other variable that‚Äôs not in your model that is really causing the relationship\nmascot attitudes ~ prejudice + education + error; education is causing people to be prejudiced (less educated people are more prejudiced) and like the mascot (less educated people aren‚Äôt aware of the horrible racist history our society has caused indigenous groups).\n\n\n\nchance\n\nwe found this pattern due to random chance\nthe people in our study just happened to show that more prejudice ‚Üí more liking for the mascot.\n\n\n\n\n\nExample : Personality and Longevity\nResearchers have found a relationship between conscientiousness (a personality variable that describes how much someone says they are organized and on-time) and how long they will live.\n\n\n\n\n\n\n\n\n\n\n\nAnswers to Personality and Longevity Example\n\n\n\n\n\n\nCausation. Conscientiousness causes people to die less early; makes people more likely to go to the doctor; follow safety rules (wear helmets!); etc than people low in conscientiousness.\nReverse Causation. Could mortality cause people to be less conscientious? No - dying is the last thing you do, and happens AFTER people have a personality. Reverse causation is not possible in this example.\nThird Variables. The researchers do control for some possible third varibles - by including gender in the model, for example, they account for the fact that women tend to be more conscientious (likely due to socialization and expectations that they do lots of the mental and emotional if not physical labor), and live longer. We‚Äôll talk about this more when we learn about multiple regression. But the researchers don‚Äôt account for every confound‚Ä¶perhaps income is a confounding variable; richer people are more likely to be conscientious (easier to be organized when basic needs are met / can throw money at problems), and richer people are more likely to live longer (can afford healthcare) than less rich folks.\nChance. the people in this study just happened to show that more conscientiousness ‚Üí less mortality.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#footnotes",
    "href": "chapters/7R_CategoricalIV.html#footnotes",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "",
    "text": "I‚Äôll just spend pages going over it. Hah hah.‚Ü©Ô∏é\nIt‚Äôs up to you which group will be assigned the value 0 and which group will be assigned the value 1, and later we will learn how to swap this around and why it might matter.‚Ü©Ô∏é\ninstall.packages(‚Äúgplots‚Äù) to install the package, then library(gplots) to load.‚Ü©Ô∏é\nThe warning message is telling me that the gplots and the stats libaries both have a function called lowess. R is ‚Äúmasking‚Äù this function from stats, which means if I refer to the lowess function , R will think I mean the one that comes from the gplots package. If I want to use the lowess from the stats library, I will need to manually tell R to do this using stats::lowess(). We won‚Äôt use the lowess function in this class.‚Ü©Ô∏é\nIt‚Äôs not important to do releveling in this example. However, sometimes one group is a clear reference group that should be assigned as the intercept. For example, if one group is the ‚Äúdefault‚Äù experience, and you want to see how the other group changes that default. We‚Äôll chat more about this next week.‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#connecting-a-linear-model-to-the-graph",
    "href": "chapters/7R_CategoricalIV.html#connecting-a-linear-model-to-the-graph",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "Connecting a Linear Model to the Graph",
    "text": "Connecting a Linear Model to the Graph\nOkay, let‚Äôs dig into what‚Äôs really going on here with the model. To define these lines, I ran the same function we used last week - `lm()`.\n\n\nCode\nmod &lt;- lm(NPI ~ sex, data = mba) \n\n\n\nThis code defines an object (that I‚Äôm calling mod, but you can call it whatever you want) as a linear model (lm), predicting Narcissism (NPI) from the variable sex, using the mba dataset. Nothing is show, because we have just defined the model.\n\n\n\nCode\ncoef(mod)\n\n\n(Intercept)     sexmale \n  3.0138235   0.2628015 \n\n\n\nThe coef() function asks R to report the coefficients from this new object. R reports the intercept (3.01) and a slope (0.26). Note that R has assigned this slope to one of the groups (male) of the categorical variable.\n\nThe linear model that we have defined with this categorical independent is doing the same thing that our linear model with a numeric IV did - making predictions about the dependent from changes in the independent variable.¬†\nThe slope is the key statistic here, since it tells us how our predictions of the dependent variable should change as the independent variable changes. When the independent variable was numeric, it could theoretically take any value. We could, for example, calculate the narcissism of someone who was 20 years old, 21 years old, 20.5 years old, etc. Of course, it may not be appropriate to calculate the narcissism of someone who was -100 years old, or 1000 years old (since these are nonsensical numbers), or even someone who was 10 years old if all the original data were based on college-age students.¬†\nWhen the independent variable is categorical, it cannot take any value, since the data are constrained to be in a specific group. This means that we have to assign each group some numeric value - something called dummy coding.In our example, researchers have measured sex as a simple binary (Male or Female), the independent variable (sex) can only take two values - Male and Female. Male and Female are not values, so we will assign them values - 0 and 1.\nR defaults to alphabetical order - because F (for Female) comes earlier in the alphabet than M (for Male), when X = 0, we will be referring to the Females in the dataset, and when X = 1, we will be referring to the Males in the dataset.2\n\n\n\nIV Value\nCategorical Factor Level\n\n\n\n\nX = 0\nFemale\n\n\nX = 1\nMale\n\n\n\nLet‚Äôs look at the graph. The intercept is the starting place for our predictions when all X values (the IV) are equal to zero. In this case, an X value of zero means that the individual is NOT male. The only other option in these data if the individual is NOT male is to be female. So the intercept - 3.01 - is the predicted Narcissism for someone who is female.\n\n\nCode\ncoef(mod)\n\n\n(Intercept)     sexmale \n  3.0138235   0.2628015 \n\n\nCode\nplot(mba$NPI, pch = 19, col = mba$sex, ylab = \"Narcissism Score\", xlab = \"Index (Position in Dataset)\",\n     main = \"Plot of Individual Narcissism Scores\\nGrouped By Sex (Red = Male, Black = Female)\")\nabline(h = coef(mod)[1], lwd = 5, col = 'black')\nabline(h = coef(mod)[1] + coef(mod)[2], lwd = 5, col = 'red')\n\n\n\n\n\n\n\n\n\nThe slope is the adjustment we make to our prediction when X changes by 1, which means we refer to the males in the dataset. This means we add 0.26 to our starting place = 3.01 + .26 = 3.27 = where the horizontal red line is drawn = the predicted value of Narcissism for males in the dataset.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#a-simpler-way-to-illustrate-a-model-with-a-categorical-iv-the-plotmeans-function",
    "href": "chapters/7R_CategoricalIV.html#a-simpler-way-to-illustrate-a-model-with-a-categorical-iv-the-plotmeans-function",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "A Simpler Way to Illustrate a Model with a Categorical IV: the plotmeans() function",
    "text": "A Simpler Way to Illustrate a Model with a Categorical IV: the plotmeans() function\nI only use the plot() function for conceptual understanding - there are better (and easier) ways to visualize this linear model in R.\nOne method I like is the plotmeans() function. This function comes from the gplots package. You will need to install this package once, then load it from the library each time you start R.3\nBelow is what it looks like when I install the gplots package (remember you only need to do this once) and then load the gplots library.4\n\n\n\n\n\nOnce I get the gplots library working, I can use the plotmeans() function. This works similar to plot(), in that I define a DV, IV, and dataset. It can also take familiar arguments (like changing the title, axis labels, and axis limits). Below is the default graph you see when I run the most basic code :¬†\n\n\nCode\nlibrary(gplots)\n\n\n\nAttaching package: 'gplots'\n\n\nThe following object is masked from 'package:stats':\n\n    lowess\n\n\nCode\nplotmeans(NPI ~ sex, data = mba)\n\n\n\n\n\n\n\n\n\n\nNPI (Narcissism) scores are on the y-axis. R has limited the range of this variable in order to highlight the slope.¬†\nThe categorical variable sex is defined on the x-axis. I can see the two groups - female and male. Above each label, R has listed the sample size (n) - the number of individuals in each group (there are 34 females and 80 males who gave narcissism data).\nThe small dot for each group is the predicted value of Narcissism for that group. Note that the dot for females is 3.01 (the intercept) and the dot for males is 3.27 (which is .26 higher than female = the slope).\nThe bars above and below the dots are something called ‚Äústandard error bars‚Äù. We will learn about those in a few weeks; but you can basically think of them as an illustration of the ‚Äúmargin of error‚Äù we have when making predictions.\nThe line connecting the two dots is trying to illustrate the slope.However, it‚Äôs a little misleading, since it makes it seem like there are possible predicted values of Narcissism between female and male. While sex is a spectrum, these researchers did not measure sex in a numeric way, so there‚Äôs not data looking at estimates of narcissism for non-cisgendered people / folks on the spectrum, so this line is not appropriate. We can turn the line off with an argument.\n\nBelow is a graph I might run to ‚Äúclean-up‚Äù some of these issues; I‚Äôve removed the line illustrating the slope, expanded the range of the y-axis, and renamed the variables.¬†\n\n\nCode\nplotmeans(NPI ~ sex, data = mba, connect = F, ylab = \"Narcissism Score\", xlab = \"Sex\",\n          ylim = c(1,5))\n\n\nWarning in arrows(x, li, x, pmax(y - gap, li), col = barcol, lwd = lwd, :\nzero-length arrow is of indeterminate angle and so skipped\n\n\nWarning in arrows(x, ui, x, pmin(y + gap, ui), col = barcol, lwd = lwd, :\nzero-length arrow is of indeterminate angle and so skipped\n\n\n\n\n\n\n\n\n\nNotice that when I expand the y-axis range to include the full range of the scale, the difference in narcissism looks a lot smaller than it did when the graph was ‚Äúzoomed‚Äù in. This is a critical media literacy skill - researchers sometimes report ‚Äúzoomed in‚Äù graphs that make the effect look bigger than it really is.¬†\nIf only there was a way to actually define how large an effect is..using numbers! Oh‚Ä¶.do you hear that‚Ä¶..it‚Äôs \\(R^2\\)‚Äôs music!!!!!",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#r-and-the-linear-model-with-a-categorical-iv",
    "href": "chapters/7R_CategoricalIV.html#r-and-the-linear-model-with-a-categorical-iv",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "\\(R^\\) and the Linear Model with a Categorical IV",
    "text": "\\(R^\\) and the Linear Model with a Categorical IV\nThe principle behind \\(R^2\\) for a linear model with a categorical IV is the same - we are looking to see how much less residual error there is when we use the model to make predictions of our DV, compared to when we use the mean when making predictions of our DV.\nYou can try to visualize this decrease in the graphs below.\n\n\nCode\npar(mfrow = c(1,2))\nplot(mba$NPI, pch = 19, ylab = \"Narcissism Score\", xlab = \"Index (Position in Dataset)\",\n     main = \"Residual Errors Using the Mean\")\nabline(h = mean(mba$NPI, na.rm = T), lwd = 5)\nplot(mba$NPI, pch = 19, col = mba$sex, ylab = \"Narcissism Score\", xlab = \"Index (Position in Dataset)\",\n     main = \"Residual Errors Using the Model\")\nabline(h = coef(mod)[1], lwd = 5, col = 'black')\nabline(h = coef(mod)[1] + coef(mod)[2], lwd = 5, col = 'red')\n\n\n\n\n\n\n\n\n\n\nFor the mean (graph on left), the residual errors are the distance between each individual score (dot) and the prediction (black line).\nFor the model (graph on right), the residual errors are the distance between each red dot (males actual narcissism score) and the red line (predicted narcissism for males) AND the distance between each black dot (females actual narcissism score) and the black line (predicted narcissism for females).\n\nI can calculate these residuals, like we did in the last chapter for a linear model with a numeric IV.\n\n\nCode\nresidual &lt;- mba$NPI - mean(mba$NPI, na.rm = T)\ntotal.residual &lt;- sum(residual^2, na.rm = T) # 32.48\ntotal.residual\n\n\n[1] 32.47965\n\n\nCode\nmodel.residual &lt;- sum(mod$residuals^2)\nmodel.residual\n\n\n[1] 30.83179\n\n\nCode\ntotal.residual - model.residual\n\n\n[1] 1.647857\n\n\nIt‚Äôs a pretty small difference in residual errors, and plugging these values into our equation of \\(R^2\\) shows that our model really only reduces residual error by about 5% (compared to the mean).\n\n\nCode\n(total.residual - model.residual)/model.residual\n\n\n[1] 0.0534467\n\n\nCode\nsummary(mod)$r.squared # R^2 the easy way\n\n\n[1] 0.05073507\n\n\nSo yes, male business students say they are more narcissistic than female business students, but differences in sex only explain about 5% of the variation in narcissism. Life is complex. As always.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#re-leveling-a-2-level-factor-variable.",
    "href": "chapters/7R_CategoricalIV.html#re-leveling-a-2-level-factor-variable.",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "Re-Leveling a 2-Level Factor Variable.",
    "text": "Re-Leveling a 2-Level Factor Variable.\nOkay, last thing. Remember how I write that the order of the levels (female = 0, male = 1) is arbitrary, and R defaults to alphabetical order? Sometimes you want to change the order around - in this example, make male = 0 and female = 1.5\nThis is called releveling. When you relevel, the data do not change - just the order of the data changes.\n\n\nCode\nrelevel(mba$sex, ref = \"male\")\n\n\n  [1] male   male   male   male   male   female male   male   male   male  \n [11] male   male   male   male   male   male   male   male   male   male  \n [21] male   male   male   male   male   male   male   male   male   male  \n [31] male   male   male   male   male   male   male   male   male   male  \n [41] male   male   male   male   male   male   male   male   male   female\n [51] female female female female female female female female female female\n [61] female female female female female male   male   male   male   male  \n [71] male   male   male   male   male   male   male   male   male   male  \n [81] male   male   male   male   male   male   male   male   male   male  \n [91] male   male   male   male   male   male   male   male   male   male  \n[101] male   male   male   male   female female female female female female\n[111] female female female female female female female female female female\n[121] female female\nLevels: male female\n\n\nNote that this time at the bottom of the output, R is listing male as the first level, and female as the second level. To save the releveling change, I‚Äôm going to define a new variable (sexR) that is part of the mba dataset. I can then use this new, releveled variable, in my linear model and create a graph.\n\n\nCode\n#|fig-column: margin\nmba$sexR &lt;- relevel(mba$sex, ref = \"male\")\nmodR &lt;- lm(NPI ~ sexR, data = mba)\ncoef(modR)\n\n\n(Intercept)  sexRfemale \n  3.2766250  -0.2628015 \n\n\nCode\nplotmeans(NPI ~ sexR, data = mba)\n\n\n\n\n\n\n\n\n\nCode\nsummary(modR)$r.squared\n\n\n[1] 0.05073507\n\n\nThis graph should look familiar; it‚Äôs the mirror image of what we saw before. The intercept is still the predicted value of narcissism when X = 0, but now X = 0 means the person is NOT female (and therefore is male). This predicted value of 3.27 is the same predicted value we saw before releveling.\nThe slope now is the adjustment in narcissism we make when we go from X = 0 to X = 1, or the difference in narcissism between females and males. This is just the flip of our previous slope, and describes that our prediction is that females will be .26 points less narcissistic than males.\nAnd if I ask R to calculate the R2 value, I get the same result because the model has not really changed; just the order of my levels.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#check-in-to-assess-your-understanding-here",
    "href": "chapters/7R_CategoricalIV.html#check-in-to-assess-your-understanding-here",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "CHECK-IN TO ASSESS YOUR UNDERSTANDING HERE",
    "text": "CHECK-IN TO ASSESS YOUR UNDERSTANDING HERE",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#another-example",
    "href": "chapters/7R_CategoricalIV.html#another-example",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "Another Example",
    "text": "Another Example\nLet‚Äôs practice with another example : Professor wants to know whether there are sex differences in testosterone. Define a linear model to predict testosterone (DV = test) from sex (IV = sex). Graph the linear model, report the slope and R2 value from the linear model, and interpret what you learn.\nTry this on your own. There‚Äôs a key (and video key) below.\n\n\n\n\n\n\nTip\n\n\n\n\n\nDefining the Linear Model and Graphing the Relationship with plotmeans()\n\n\nCode\ntest.mod &lt;- lm(test ~ sex, data = mba)\ncoef(test.mod)\n\n\n(Intercept)     sexmale \n   41.39556    49.28841 \n\n\nGraphing the Relationship: Conceptual Example\n\n\nCode\nplot(mba$test, col = mba$sex)\nabline(h = coef(test.mod)[1], lwd = 5, col = \"black\")\nabline(h = coef(test.mod)[1] + coef(test.mod)[2], lwd = 5, col = \"red\")\n\n\n\n\n\n\n\n\n\nInterpreting R2\n\n\nCode\nsummary(test.mod)$r.squared\n\n\n[1] 0.3469868",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/7R_CategoricalIV.html#experimental-methods",
    "href": "chapters/7R_CategoricalIV.html#experimental-methods",
    "title": "Linear Model Pt 2: Categorical IVs",
    "section": "Experimental Methods",
    "text": "Experimental Methods\nScientists and psychologists often want (or need) to establish causation, and an experiment is the ‚Äúgold standard‚Äù approach for how to do this.\nI‚Äôm guessing y‚Äôall have learned about experiments in many other classes, so won‚Äôt spend pages and pages and pages going over it again here.6\nHere‚Äôs a supplemental chapter on experiments that reviews some key terms you should be familiar with : experimental manipulation; extraneous variables as ‚Äúnoise‚Äù; random assignment; placebo effects; external validity; construct validity; experimenter expectancy effects.\n\nThe Google Experiment\nWhen I worked at Google as an intern for one summer7, corporate PR told a story about their ‚Äúdata driven approach‚Äù, where no decision was left to mere chance. Even something as simple as the color font they used could be the focus of an analytic research question.\n\n\n\n\n\n\n\nGoogle Homepage : Before Experiments\nGoogle Homepage : After Experiments\n\n\n\n\n\n\n\nWatch the video below. You can read more about this study here.\n\n\n\n\n\n\nThen, see if you can identify the different parts of an experiment.\n\nlinear model : DV ~ IV (what was manipulated) + confound variables + error\nmanipulation : what were the treatment and control groups?\nrandom assignment : how were confound variables balanced across conditions?\ndouble-blind : did the study avoid demand characteristics & placebo effects?\ngeneralizability : did the study have external validity? what was the effect size (R2)?\nethics : should researchers do this type of study [predict & control]\n\n\n\n\n\n\n\nAnswers to Google Shade of Blue Experiment\n\n\n\n\n\n\nlinear model : number of ads that peopled clicked on ~ shade of blue people saw + age + location + income + education + media literacy + relevance of the ad + etc + error\nmanipulation : ‚Äúcontrol‚Äù group = shade of blue (existing shade of blue); treatment group = shade of blue.\nrandom assignment : participants were randomly assigned to see links in one shade of blue or another. because this was randomly assigned, all the other differences between people (those variables that might affect the DV, such as age or location) are ‚Äúbalanced out‚Äù.\ndouble-blind : the participant didn‚Äôt know that google was manipulating the shade of blue to get them to click on ads. the website (google) doesn‚Äôt know whats going on.\ngeneralizability : yes, high external validity! Google was changing its own website. an example of low external validity would be printing out a sheet with different shades of blue that users ‚Äúclick‚Äù on with their finger.\nethics : WOULD LOVE TO HEAR FROM Y‚ÄôALL : do you think it‚Äôs ethical for companies like Google to do this research???",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Linear Model Pt 2: Categorical IVs</span>"
    ]
  },
  {
    "objectID": "chapters/8R_Assumptions.html#part-1-the-linear-model-with-a-categorical-ivwith-three-levels",
    "href": "chapters/8R_Assumptions.html#part-1-the-linear-model-with-a-categorical-ivwith-three-levels",
    "title": "More Levels and Experiments",
    "section": "",
    "text": "Video 1 : Defining the Model with the lm() function\n\nhere‚Äôs a link to R Script (as used in the video)\n\n\n\npar(mfrow = c(1,2))\nhist(presto$prestige)\nplot(presto$type)\n\n\n\n\n\n\n\nmod &lt;- lm(prestige ~ type, data = presto)\nmod\n\n\nCall:\nlm(formula = prestige ~ type, data = presto)\n\nCoefficients:\n(Intercept)     typeprof       typewc  \n     35.527       32.321        6.716  \n\n\n\n\nVideo 2 : Interpreting the Model\n\n\nThe Linear Model Equation:\n\ncoef(mod)\n\n(Intercept)    typeprof      typewc \n  35.527273   32.321114    6.716206 \n\n\n\n\nUsing the Equation and Dummy Coding to Generate Predicted Values\n\n\n\n\n\n\n\n\n\n\n\n\n(the intercept)\n35.5\nX1\n(typeprof)\n32.3\nX2\n(typewc)\n6.7\nCalculations\nPredicted Value\n\n\nbc\n1\n0\n0\n35.5 + 32.3*0 + 6.7*0\n= 35.5\n\n\nprof\n1\n1\n0\n35.5 + 32.3*1 + 6.7*0\n= 67.8\n\n\nwc\n1\n0\n1\n35.5 + 32.3*0 + 6.7*1\n= 42.2\n\n\n\n\n\nYes, Professor, A Picture is Worth‚Ä¶.1000 Words.\n\npar(mfrow = c(1,2))\nplot(presto$prestige, col = presto$type, pch = 19)\nabline(h = coef(mod)[1] + coef(mod)[2], col = 'red', lwd = 5)\nabline(h = coef(mod)[1] + coef(mod)[3], col = 'green', lwd = 5)\nabline(h = coef(mod)[1], col = 'black', lwd = 5) # blue collar\n\nplotmeans(prestige ~ type, data = presto, connect = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nVideo 3 : Releveling the Variable\n\n\npresto$typeR &lt;- relevel(presto$type, ref = \"prof\")\nmod2 &lt;- lm(prestige ~ typeR, data = presto)\nplotmeans(prestige ~ typeR, data = presto, connect = FALSE)\n\n\n\n\n\n\n\ncoef(mod2)\n\n(Intercept)     typeRbc     typeRwc \n   67.84839   -32.32111   -25.60491 \n\n\n\n\nVideo 4 : \\(R^2\\) for a Categorical Model\n\n\npar(mfrow = c(1,2))\nplot(presto$prestige, main = \"The Mean as Our Prediction\")\nabline(h = mean(presto$prestige), )\n\nplot(presto$prestige, col = presto$type, pch = 19, main = \"The Model (Job Type) As Our Prediction\")\nabline(h = coef(mod)[1] + coef(mod)[2], col = 'red', lwd = 5)\nabline(h = coef(mod)[1] + coef(mod)[3], col = 'green', lwd = 5)\nabline(h = coef(mod)[1], col = 'black', lwd = 5) # blue collar",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/8R_Assumptions.html#part-2-experimental-methods",
    "href": "chapters/8R_Assumptions.html#part-2-experimental-methods",
    "title": "More Levels and Experiments",
    "section": "Part 2 : Experimental Methods",
    "text": "Part 2 : Experimental Methods\nLast chapter, we learned the ‚Äúfour reasons‚Äù why you might find a ‚Äúpattern in the data‚Äù (another way of saying why ‚Äúcorrelation does not equal causation‚Äù. However, scientists and psychologists often want (or need) to establish causation, and an experiment is the ‚Äúgold standard‚Äù approach for how to do this.\nScientists and psychologists often want (or need) to establish causation, and an experiment is the ‚Äúgold standard‚Äù approach for how to do this.\nI‚Äôm guessing y‚Äôall have learned about experiments in many other classes, so won‚Äôt spend pages and pages and pages going over it again here.1\nHere‚Äôs a supplemental chapter on experiments that reviews some key terms you should be familiar with : experimental manipulation; extraneous variables as ‚Äúnoise‚Äù; random assignment; placebo effects; external validity; construct validity; experimenter expectancy effects.\n\nThe Definition of Causality\n\nThe cause and effect are contiguous in space and time.\nThe cause must be prior to the effect. (no reverse causation)\nThere must be a constant union betwixt the cause and effect. (‚ÄúTis chiefly this quality, that constitutes the relation.‚Äù) (no random chance)\nThe same cause always produces the same effect, and the same effect never arises but from the same cause. (not ‚Äújust‚Äù some third variable) [^1]\n\n[^1] but remember, life is complex and there are often multiple causes of human behavior!\n\n\nThe Google Experiment\nWhen I worked at Google as an intern for one summer2, corporate PR told a story about their ‚Äúdata driven approach‚Äù, where no decision was left to mere chance. Even something as simple as the color font they used could be the focus of an analytic research question.\n\n\n\n\n\n\n\nGoogle Homepage : Before Experiments\nGoogle Homepage : After Experiments\n\n\n\n\n\n\n\nWatch the video below. You can read more about this study here.\n\n\n\n\n\n\nThen, see if you can identify the different parts of an experiment.\n\nlinear model : DV ~ IV (what was manipulated) + confound variables + error\nmanipulation : what were the treatment and control groups?\nrandom assignment : how were confound variables balanced across conditions?\ndouble-blind : did the study avoid demand characteristics & placebo effects?\ngeneralizability : did the study have external validity? what was the effect size (R2)?\nethics : should researchers do this type of study [predict & control]\n\n\n\n\n\n\n\nAnswers to Google Shade of Blue Experiment\n\n\n\n\n\n\nlinear model : number of ads that peopled clicked on ~ shade of blue people saw + age + location + income + education + media literacy + relevance of the ad + etc + error\nmanipulation : ‚Äúcontrol‚Äù group = shade of blue (existing shade of blue); treatment group = shade of blue.\nrandom assignment : participants were randomly assigned to see links in one shade of blue or another. because this was randomly assigned, all the other differences between people (those variables that might affect the DV, such as age or location) are ‚Äúbalanced out‚Äù.\ndouble-blind : the participant didn‚Äôt know that google was manipulating the shade of blue to get them to click on ads. the website (google) doesn‚Äôt know whats going on.\ngeneralizability : yes, high external validity! Google was changing its own website. an example of low external validity would be printing out a sheet with different shades of blue that users ‚Äúclick‚Äù on with their finger.\nethics : WOULD LOVE TO HEAR FROM Y‚ÄôALL : do you think it‚Äôs ethical for companies like Google to do this research???",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/8R_Assumptions.html#footnotes",
    "href": "chapters/8R_Assumptions.html#footnotes",
    "title": "More Levels and Experiments",
    "section": "",
    "text": "I‚Äôll just spend pages going over it. Hah hah.‚Ü©Ô∏é\nwell-fed; gratuitously paid; soul-drained. I was in their ‚ÄúPeople Operations‚Äù (/HR) department, helping them set up longitudinal surveys and do various other research projects on compensation, appreciation, and diversity that helped feed the corporate beast.‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/8R_Assumptions.html#check-in-to-assess-your-understanding-here-no-r-required",
    "href": "chapters/8R_Assumptions.html#check-in-to-assess-your-understanding-here-no-r-required",
    "title": "More Levels and Experiments",
    "section": "CHECK-IN TO ASSESS YOUR UNDERSTANDING HERE [no r required]",
    "text": "CHECK-IN TO ASSESS YOUR UNDERSTANDING HERE [no r required]",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/9R_SamplingError.html#is-this-the-real-life-is-this-just-fantasy-inferential-statistics",
    "href": "chapters/9R_SamplingError.html#is-this-the-real-life-is-this-just-fantasy-inferential-statistics",
    "title": "Sampling Error and Bias",
    "section": "",
    "text": "Samples and Populations\nSo far, the statistics that we‚Äôve done and described have been focused on sample data - the data that a reseracher collects and / or analyzes. For example, when we calculate the mean of a sample, we are reporting the statistic that is closest to all the scores in our sample of data. When we calculate a slope, we are describing how one variable is related to another variable in our sample of data.\nResearchers are rarely interested in only their sample, but instead want to learn about a broader population - that is, all the individuals who might be relevant to a researcher‚Äôs question.\nAs we will discuss, thinking about who would be the population for a research question, and then identifying who is in the sample, is a critical step for understanding and evaluating the interpretation of the data.\nThe sample is always clearly defined and reported in the ‚ÄúMethods‚Äù section, where researchers describe (in detail) the number (sample size = n) and demographic features of the people they studied.\nThe population is not often clearly defined or reported, but can be inferred by thinking about all the possible people who could be affected by, or relevant to, the researcher‚Äôs question.\nBelow are a few examples of reserach questions, populations, and the specific samples that researchers studied.\n\n\n\nResearcher Question\nPopulation\nSample (Example)\n\n\nWhat is the patient‚Äôs white blood cell count.\nAll the blood in a person‚Äôs body.\nThe vial of blood that a phlebotomist collects.\n\n\nIs money related to happiness?\nEveryone in the world who could be happy and have an income.\n‚ÄúParticipants were 33,391 employed adults living in the United States. The median age was 33, the median household income was $85,000/year (25th¬†percentile = $45,000; 75th¬†percentile = $137,500; mean = $106,548; SD = $95,393), 36% were male, and 37% were married.‚Äù\n\n\nYour final project research question.\nWho is in the population?\nWho will be in your sample?\n\n\n\n\n\nWhen the Sample Doesn‚Äôt Equal the Population\nResearchers rarely, if ever, have access to the full population of data, and thus must use the sample to make a guess (or inference) about the population. For example, doctors don‚Äôt drain a person of all their blood in order to learn about the person‚Äôs health, but trust that the sample will give them valid information about what‚Äôs going on in the whole body. That‚Äôs not always the case, however, and an important task for researchers is to consider the possibility that they are wrong.\nThe key question is then, how can we trust that the information we learn from the sample is at all related to the broader population? This is hard to do, and the focus of this chapter. In fact, there are two reasons why we would expect that the sample will not, in fact, equal the population.\nSampling Error describes when the sample is different from the population because of random reasons. A good sample will be random sample, meaning that each individual in the population has an equal chance of being selected for the sample. Even if this is the case, there‚Äôs always going to be some differences between the individuals in the study, and the individuals in the population. As you‚Äôll learn in the section below, researchers use statistics to try and estimate how much sampling error might influence their results, and try to design studies to limit the extent that sampling error can affect their results.\nSampling Bias describes when the sample is different from the population because of predictable (or non-random) reasons. A blood sample would be biased if we knew there was something systematically different about the blood that was drawn from the arm vs.¬†the hand vs.¬†the neck vs.¬†the part of your foot between your toes. Identifying sampling bias requires some critical thinking skills that we will practice in the section below, and our goal as researchers will be to identify possible sources of bias, and minimize their influence (or do new studies to test their influence.)\nLet‚Äôs start with sampling bias, because it‚Äôs a lot shorter and easier to understand :)",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sampling Error and Bias</span>"
    ]
  },
  {
    "objectID": "chapters/9R_SamplingError.html#sampling-error",
    "href": "chapters/9R_SamplingError.html#sampling-error",
    "title": "Sampling Error and Bias",
    "section": "Sampling Error",
    "text": "Sampling Error\n\nThinking Through a Population\nOkay, this may seem a little strange, but I‚Äôll need your full attention for this part of the chapter. Please place your left and right hand thumbs and index fingers together to make a triangle with your two hands. Spread your other fingers forward, so you are using your full hand to make this power triangle.\n\nOkay, now please place your thumbs in between your eyebrows, and stare at the triangle below. While you stare, say ‚Äúna-na-na-na-na-na-na-na-na-na‚Äù (repeating) - starting as quiet as you can, and getting as loud as you feel comfortable for no less than 5 seconds and no more than 15 seconds. I‚Äôll give you a moment to do this.\nWow. Did you feel that power? You did, right?? Yeah. Amazing.\nWhat we‚Äôve done - through the power of triangles (the strongest shape, both physically and psychologically) - is generate a dataset1 that we will consider to be a population of data.\nI‚Äôve named this dataset babby, and it has two variables for 40000 individuals - one IV and one DV.\n\nbabby &lt;- read.csv(\"~/Dropbox/Teaching Datasets/brainwavebabydata.csv\")\nhead(babby)\n\n           IV         DV\n1 -0.72974695  0.7393607\n2  1.55894120 -0.8977654\n3  1.87894858 -0.4780742\n4  0.36830861 -0.9365583\n5  0.02805939  1.5690341\n6  2.18060600 -2.1974925\n\nnrow(babby)\n\n[1] 40000\n\n\nIf we graph these variables, we see that they appear to each be normally distributed.¬†\n\npar(mfrow = c(1,2))\nhist(babby$IV, col = 'black', bor = 'white', main = \"Histogram of IV\", xlab = \"Independent Variable\")\nhist(babby$DV, col = 'black', bor = 'white', main = \"Histogram of DV\", xlab = \"Dependent Variable\")\n\n\n\n\n\n\n\n\nAnd if we plot the relationship between these two variables, we find that there is no relationship between the DV and the IV. Content warning - some students find the image below existentially terrifying. (What do you see in the graph below? What does this say about you and your personality?)\n\npar(mfrow = c(1,1))\nplot(DV ~ IV, data = babby, pch = 19, main = \"Relationship Between DV and IV\", xlab = \"IV\", ylab = \"DV\")\nmod &lt;- lm(DV ~ IV, data = babby)\nabline(mod, lwd = 5, col = 'red')\n\n\n\n\n\n\n\n\nR confirms that there is no relationship between these two variables - the slope for the IV rounds (to ten decimal places) to zero.\n\ncoef(mod)\n\n  (Intercept)            IV \n-1.110223e-18 -6.306146e-16 \n\nround(coef(mod), 10)\n\n(Intercept)          IV \n          0           0 \n\n\n\nSo to recap, we have a population of data (40,000 individuals) for whom the ‚Äútrue‚Äù relationship is zero.\n\n\n\n\nUsing R to Define a ‚ÄúPerfectly Random Sample‚Äù\nAs described above, psychologists will almost never have access to the true population of data. Instead, they take a ‚Äúsample‚Äù from the population. When every individual in the population has an equal chance of being selected for this sample, we can say the sample is a ‚Äúrandom sample‚Äù. When there are certain individuals who are more or less likely to be included in the sample, we say the sample has ‚Äúbias‚Äù.\nMost samples in psychology are biased; taking a random sample from the population as a psychological researcher is incredibly difficult, if not impossible. However, even if you were to take a perfectly random sample from the population, you should expect your sample to differ at least a little from the broader population.\nWe can illustrate this in R. R has a built-in function called sample(), which takes a random sample2 of whatever numbers you give it. For example, here‚Äôs a fun game - think of a number between 1 and 10. Then ask R to sample() a random number between 1 and 10 and see if you are vibing with R. I am thinking of the number FOUR.\nIn the code below, I‚Äôm asking R to define the numbers 1 through 10, and then draw ONE number from this set.3\n\nset.seed(42)\nsample(1:10, 1)\n\n[1] 1\n\n\nR chose the number 1. We are not vibing. But every time I run the sample() function again, I‚Äôll get a new random number every time.\n\nsample(1:10, 1)\n\n[1] 5\n\nsample(1:10, 1)\n\n[1] 1\n\nsample(1:10, 1)\n\n[1] 9\n\nsample(1:10, 1)\n\n[1] 10\n\nsample(1:10, 1)\n\n[1] 4\n\n\nOkay, go ahead and try this yourself - think of a number, and let us know on Discord how many times it took you to run the sample(1:10, 1) function before R chose your number. (Or not.)\nWe can use this function to ask R to take a ‚Äúperfect‚Äù random sample from our population. I‚Äôm going to adapt the code a bit to draw a random sample from the babby dataset.\n\nbabby[sample(1:nrow(babby), 10), ]\n\n               IV           DV\n8826   0.98527631 -0.518293954\n16740 -0.55196783  0.056675257\n7700   1.10483168  0.005026792\n36722  0.09618142  0.117929657\n9091  -0.07852571 -0.552495893\n33700 -1.00134328  1.441827817\n13610 -1.33371387 -1.064411326\n28559  0.18542185 -0.461931331\n22725  0.47526546 -0.617396883\n11224  0.73776812 -2.402637937\n\n\n\nbabby[ , ] # this code indexes the babby dataset. the dataset is two dimensional; I can instruct R to select specific rows before the comma, and columns after the comma.\nsample(1:nrow(babby), 10) # this code instructs R to select specific rows (since it comes before the comma), and tells R to take a random sample of 10 numbers, starting with the number 1 and going through however many rows babby has (in this case, 40,000).¬†¬†\nafter the comma, I have no code, which tells R to give me all the columns (in this case two - the IV and DV)\n\nAs you can see in the above output, R has drawn a random sample of 10 individuals from the list of 40,000. If I run this code again, R will select another 10 individuals from the list of 40,000.\n\nbabby[sample(1:nrow(babby), 10), ]\n\n               IV          DV\n33713  0.08619728  1.63778479\n37126 -0.42197038 -0.65012382\n12418 -0.38048978  0.61041238\n15765 -2.07429669 -0.89532671\n9207   0.54379840 -0.02403073\n31418 -1.52499812  1.27384500\n24609  0.81390193 -0.56375600\n103   -0.29130008 -1.44600496\n10349  0.17771080 -1.27641647\n36940 -0.46201091 -0.67224917\n\n\nIf I want to SAVE this sample (and use it later), I need to give it a name so R remembers what the sample is (and doesn‚Äôt keep creating new samples).¬†\n\nsampy &lt;- babby[sample(1:nrow(babby), 10), ]\nsampy\n\n              IV         DV\n5897   0.8485550 -0.2524885\n20003  0.6540785 -0.1779805\n16     0.4508883  0.2223145\n33756  1.2866107  0.6269824\n14232 -1.0166493  0.3983281\n25490  1.3144997 -0.7714008\n149    0.9310813 -1.3942383\n29671  0.3357943  0.4989499\n35218  0.5225263 -1.7209132\n23309  0.8328597  1.2089172\n\nsampy\n\n              IV         DV\n5897   0.8485550 -0.2524885\n20003  0.6540785 -0.1779805\n16     0.4508883  0.2223145\n33756  1.2866107  0.6269824\n14232 -1.0166493  0.3983281\n25490  1.3144997 -0.7714008\n149    0.9310813 -1.3942383\n29671  0.3357943  0.4989499\n35218  0.5225263 -1.7209132\n23309  0.8328597  1.2089172\n\n\n\n\nOur ‚ÄúPerfect‚Äù Sample Has ‚ÄúError‚Äù\nOkay, we finally have a perfectly random sample of the population - sampy. If we were researchers, we would use this sample to learn something about what the population is like and, like before, define a linear model to examine the relationship between the DV and IV.\n\nplot(DV ~ IV, data = sampy, pch = 19, main = \"Relationship Between DV and IV in SAMPY\", xlab = \"IV (from sampy)\", ylab = \"DV (from Sampy)\")\nmodS &lt;- lm(DV ~ IV, data = sampy)\nabline(modS, lwd = 5, col = 'green')\n\n\n\n\n\n\n\nround(coef(modS), 5)\n\n(Intercept)          IV \n    0.02525    -0.26201 \n\nsummary(modS)$r.squared\n\n[1] 0.03484331\n\n\nOur sample has error - it is not showing us the true nature of the population.\n\nIndeed, we could ask R to generate 10 random samples of 10 individuals, and see these errors repeat.\n\npar(mfrow = c(2,5))\nfor(i in c(1:20)){\n  sampy &lt;- babby[sample(1:nrow(babby), 10), ]\n  plot(DV ~ IV, data = sampy, pch = 19, main = \"Another Sampy\", xlab = \"IV\", ylab = \"DV\")\n  modS &lt;- lm(DV ~ IV, data = sampy)\n  abline(modS, lwd = 5, col = 'green')\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncoef(modS)\n\n(Intercept)          IV \n 0.69109563 -0.02107053",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sampling Error and Bias</span>"
    ]
  },
  {
    "objectID": "chapters/9R_SamplingError.html#sampling-bias",
    "href": "chapters/9R_SamplingError.html#sampling-bias",
    "title": "Sampling Error and Bias",
    "section": "Sampling Bias",
    "text": "Sampling Bias\n\nEvaluating Whether Sampling Bias Exists\nThere are three questions to consider when evaluating whether sampling bias is influencing the results.\n\nWhat is the research question, who is the population relevant to this question, and who is in the sample? This first question (‚Ä¶okay, technically three questions) asks you to define the key features of the study (as described above.)\nIs the sample representative of the population, or is there a systematic bias? The second question asks you to evaluate whether the people in the sample are predictably different from the people in the population. This will almost always be true - most psychological research questions are relevant to people across the world, and it‚Äôs very difficult to ensure that everyone in the world has an equal chance of participating in the study.\nIs this bias related to the dependent variable? (Will the bias influence the results?) The final question is the hardest, and most important, to consider.\n\n\n\nObama Polling Example : Sampling Bias\nBelow are data from 20121, when Barack Obama was running against Mitt Romney in the US Presidential Election. Look over the data, and think about the answers to the three questions to evaluate sampling bias.\n\n\n\n\n\n\n\nWhat is the research question, who is the population relevant to this question, and who is in the sample?\n\n\n\n\n\n\nthe question : who are people going to vote for US President in 2012?\nthe population : all voters / likely voters in the US.\nthere are multiple samples : some polls only sample people without cell-phones by randomly calling people who have landline phones. other polls sample people with landlines or cell-phones.\n\n\n\n\n\n\n\n\n\n\nIs the sample representative of the population, or is there a systematic bias?\n\n\n\n\n\n\nno! the sample is not representative of the population. not all voters have landline phones (or cell-phones, but more folks have cell-phones these days). So while both samples are biased, the samples that only include landline phone owners are more biased than the samples that include both landlines and cell-phone owners.\n\n\n\n\n\n\n\n\n\n\nIs this bias related to the dependent variable? (Will the bias influence the results?)\n\n\n\n\n\n\nthe bias is related to the dependent variable / research question. landline phone owners will tend to be older, and older voters tend to vote more conservative.\nYou can see this bias in the data; Obama (the more liberal candidate) was predicted to win by less in the studies that only sampled landline phone owners.\n\n\n\n\n\n\nTypes of Sampling Bias\nThe sampling bais in this example would be labeled exclusion bias; below are a few other common types of biases.\n\nSelf-Selection Bias : People volunteer to be in a study, and there‚Äôs likely something different about someone who might choose to be in a study compared to someone who may not want to be in a study in ways that might influence the results.\nSurvivor Bias : Participants often drop out of a study, especially those where you are following the participant over a long period of time. Researchers therefore are only collecting data from a specific group of people who ‚Äúlasted‚Äù through the study. I experience this with my check-ins; the students who rate how the class is going are biased, because they are the ones who haven‚Äôt quit out of boredom or anxiety.\nWEIRD Samples. Read the short article ‚ÄúA WEIRD View of Human Nature‚Äù that describes how most psychologists get samples for their studies. Focus on the following key ideas: the definition of WEIRD; the frequency and influence of cross-cultural research on sampling biases.\n\n\n\nAnother Example\n\nWhat is the POPULATION for ‚ÄúRate My Professor‚Äù (a website where students rate the quality of a professor they have had)?\n\nAll the people in the world.\nAll the students in the world.\nAll the students who have taken a specific professor‚Äôs course.\nAll the students who wrote a review about the course.\nAll the students who read the reviews.\n\nWhat is the SAMPLE for ‚ÄúRate My Professor‚Äù (a website where students rate the quality of a professor they have had)?\n\nAll the people in the world.\nAll the students in the world.\nAll the students who have taken a specific professor‚Äôs course.\nAll the students who wrote a review about the professor‚Äôs course.\nAll the students who read the reviews.\n\nWhat does WEIRD stand for?\n\nWhite, Educated, Individualistic, Rich, Democratic\nWestern, Educated, Industrial, Rich, Democratic\nA statistical term that describes participants who are more than three standard deviations from the average of a variable.\nThis is a term that psychologists no longer use because it is dehumanizing\nNone of the above.\n\nAccording to the article on cross-cultural differences in psychology‚Ä¶\n\nEffects that are ‚Äúfundamental‚Äù do not differ across cultures.\nCertain areas of psychology, like visual perception, do not differ across cultures.\nMost psychological researchers put effort into examining cross-cultural differences.\nAll of the above.\nNone of the above.\n\nDr.¬†Researcher wants to study people‚Äôs attitudes about marijuana. According to the Professor‚Äôs video in the reading notes, which of the following would be an example of sampling bias?\n\nDr.¬†Researcher surveys people living in the Bay Area (where people tend to have more positive attitudes about marijuana than people living in other places).\nDr.¬†Researcher surveys people living in Lytle, Texas (where people tend to have more negative attitudes about marijuana than people living in other places).\nDr.¬†Researcher surveys people wearing white t-shirts (a factor that is unrelated to attitudes about marijuana).\nBoth A and B\nall of the above.\n\n\n¬†Piff, P. K., Dietze, P., Feinberg, M., Stancato, D. M., & Keltner, D. (2015). Awe, the small self, and prosocial behavior. Journal of personality and social psychology, 108(6), 883. LINK TO FULL ARTICLE",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sampling Error and Bias</span>"
    ]
  },
  {
    "objectID": "chapters/9R_SamplingError.html#footnotes",
    "href": "chapters/9R_SamplingError.html#footnotes",
    "title": "Sampling Error and Bias",
    "section": "",
    "text": "source : https://fivethirtyeight.com/features/obamas-lead-looks-stronger-in-polls-that-include-cellphones/‚Ü©Ô∏é\nYou can access the fake dataset here if you want to follow along in R, but this is not necessary and I think reading these notes should suffice.‚Ü©Ô∏é\nThere are different ways that computers can take ‚Äúrandom samples‚Äù, each with different merits. The default method R uses is ‚Äú‚ÄúMersenne-Twister‚Äù From Matsumoto and Nishimura (1998). This stuff goes way beyond my pay grade; I imagine there are a few explanations on the internet. Let me know if you find a good one!\n\n‚Ü©Ô∏é\nNote that when I use the set.seed() function before the sample() function, I‚Äôm telling R to ‚Äúfix‚Äù the random number generator it uses. This gives me a consistent result time it runs the ‚Äúrandom‚Äù sample() function. And if you also run set.seed(42) before you run sample(1:10, 1) you should also get the same answer of 1. You can specify any number within set.seed(), and only want to use this function when you want others to get the same answer as you (like when sharing code). Most of the time, we don‚Äôt want to use this function because we want things to be ‚Äúrandom‚Äù. Let me know if this is confusing! I can try to clarify.‚Ü©Ô∏é\nA sample size of 150 may still seem small, but it‚Äôs around the average in fields like social and personality psychology (Fraley et al., 2022) and well above the average in other fields like neuroscience (Button et al., 2013).‚Ü©Ô∏é\n¬†This conceptual equation won‚Äôt give you what R calculates, because R will use something called the pooled variance in its calculation of the standard deviation (since the null hypothesis assumes no relationship between the DV and IV, it‚Äôs better to calculate a weighted average of the DV and IV for your estimate of the standard deviation. There‚Äôs a long equation to calculate this that I used to students and have them do ‚Äúby hand‚Äù. However, over the years I realize that this does not help students learn, and that even the complicated equation is an oversimplification of a much more involved proof which you can learn about in more advanced classes if you want.‚Ü©Ô∏é\n¬†This is called Type I error (a false positive) - when we incorrectly reject the null hypothesis. The probability of committing Type I error is defined by the p-value you set to reject the null hypothesis, typically .05 = 5%. Type II error is when you incorrectly reject the alternative hypothesis (false negative). we won‚Äôt cover how to calculate Type II error this semester (or the related concept of Statistical Power - which is an estimate of the probability you can correctly support your theory as a researcher), but they are important ideas. Here‚Äôs an okay video that seems to give a good overview of these types of error for those students who are interested, and here‚Äôs a video walking through how to do this in R. Let me know if you have questions / find better videos!‚Ü©Ô∏é\nThe exact range of the 95% confidence interval will not always be within ¬±1.96 standard errors of the slope - that‚Äôs the theoretical range based on a normal distribution. In practice, the range will depend on certain features of your sample and model (much like the t-distribution we discussed), but will approach 1.96 as your sample size increases; and if you want to be more conservative, you can round up to 2*SEb as long as your sample size is &gt; 30.\n\n‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sampling Error and Bias</span>"
    ]
  },
  {
    "objectID": "chapters/9R_SamplingError.html#sampling-error-conceptual",
    "href": "chapters/9R_SamplingError.html#sampling-error-conceptual",
    "title": "Sampling Error and Bias",
    "section": "Sampling Error (Conceptual)",
    "text": "Sampling Error (Conceptual)\n\nThinking Through a Population\nOkay, this may seem a little strange, but I‚Äôll need your full attention for this part of the chapter. Please place your left and right hand thumbs and index fingers together to make a triangle with your two hands. Spread your other fingers forward, so you are using your full hand to make this power triangle.\n\nOkay, now please place your thumbs in between your eyebrows, and stare at the triangle below. While you stare, say ‚Äúna-na-na-na-na-na-na-na-na-na‚Äù (repeating) - starting as quiet as you can, and getting as loud as you feel comfortable for no less than 5 seconds and no more than 15 seconds. I‚Äôll give you a moment to do this.\n\n\n\n\n\nWow. Did you feel that power? You did, right?? Yeah. Amazing.\nWhat we‚Äôve done - through the power of triangles (the strongest shape, both physically and psychologically) - is generate a dataset2 that we will consider to be a population of data.\nI‚Äôve named this dataset babby, and it has two variables for 40000 individuals - one IV and one DV.\n\nbabby &lt;- read.csv(\"~/Dropbox/Teaching Datasets/brainwavebabydata.csv\")\nhead(babby)\n\n           IV         DV\n1 -0.72974695  0.7393607\n2  1.55894120 -0.8977654\n3  1.87894858 -0.4780742\n4  0.36830861 -0.9365583\n5  0.02805939  1.5690341\n6  2.18060600 -2.1974925\n\nnrow(babby)\n\n[1] 40000\n\n\nIf we graph these variables, we see that they appear to each be normally distributed.¬†\n\npar(mfrow = c(1,2))\nhist(babby$IV, col = 'black', bor = 'white', main = \"Histogram of IV\", xlab = \"Independent Variable\")\nhist(babby$DV, col = 'black', bor = 'white', main = \"Histogram of DV\", xlab = \"Dependent Variable\")\n\n\n\n\n\n\n\n\nAnd if we plot the relationship between these two variables, we find that there is no relationship between the DV and the IV. Content warning - some students find the image below existentially terrifying. (What do you see in the graph below? What does this say about you and your personality?)\n\npar(mfrow = c(1,1))\nplot(DV ~ IV, data = babby, pch = 19, main = \"Relationship Between DV and IV\", xlab = \"IV\", ylab = \"DV\")\nmod &lt;- lm(DV ~ IV, data = babby)\nabline(mod, lwd = 5, col = 'red')\n\n\n\n\n\n\n\n\nR confirms that there is no relationship between these two variables - the slope for the IV rounds (to ten decimal places) to zero.\n\ncoef(mod)\n\n  (Intercept)            IV \n-1.110223e-18 -6.306146e-16 \n\nround(coef(mod), 10)\n\n(Intercept)          IV \n          0           0 \n\n\n\nSo to recap, we have a population of data (40,000 individuals) for whom the ‚Äútrue‚Äù relationship is zero.\n\n\n\n\nUsing R to Define a ‚ÄúPerfectly Random Sample‚Äù\nAs described above, psychologists will almost never have access to the true population of data. Instead, they take a ‚Äúsample‚Äù from the population. When every individual in the population has an equal chance of being selected for this sample, we can say the sample is a ‚Äúrandom sample‚Äù. When there are certain individuals who are more or less likely to be included in the sample, we say the sample has ‚Äúbias‚Äù.\nMost samples in psychology are biased; taking a random sample from the population as a psychological researcher is incredibly difficult, if not impossible. However, even if you were to take a perfectly random sample from the population, you should expect your sample to differ at least a little from the broader population.\nWe can illustrate this in R. R has a built-in function called sample(), which takes a random sample3 of whatever numbers you give it. For example, here‚Äôs a fun game - think of a number between 1 and 10. Then ask R to sample() a random number between 1 and 10 and see if you are vibing with R. I am thinking of the number FOUR.\nIn the code below, I‚Äôm asking R to define the numbers 1 through 10, and then draw ONE number from this set.4\n\nset.seed(42)\nsample(1:10, 1)\n\n[1] 1\n\n\nR chose the number 1. We are not vibing. But every time I run the sample() function again, I‚Äôll get a new random number every time.\n\nsample(1:10, 1)\n\n[1] 5\n\nsample(1:10, 1)\n\n[1] 1\n\nsample(1:10, 1)\n\n[1] 9\n\nsample(1:10, 1)\n\n[1] 10\n\nsample(1:10, 1)\n\n[1] 4\n\n\nOkay, go ahead and try this yourself - think of a number, and let us know on Discord how many times it took you to run the sample(1:10, 1) function before R chose your number. (Or not.)\nWe can use this function to ask R to take a ‚Äúperfect‚Äù random sample from our population. I‚Äôm going to adapt the code a bit to draw a random sample from the babby dataset.\n\nbabby[sample(1:nrow(babby), 10), ]\n\n               IV           DV\n8826   0.98527631 -0.518293954\n16740 -0.55196783  0.056675257\n7700   1.10483168  0.005026792\n36722  0.09618142  0.117929657\n9091  -0.07852571 -0.552495893\n33700 -1.00134328  1.441827817\n13610 -1.33371387 -1.064411326\n28559  0.18542185 -0.461931331\n22725  0.47526546 -0.617396883\n11224  0.73776812 -2.402637937\n\n\n\nbabby[ , ] # this code indexes the babby dataset. the dataset is two dimensional; I can instruct R to select specific rows before the comma, and columns after the comma.\nsample(1:nrow(babby), 10) # this code instructs R to select specific rows (since it comes before the comma), and tells R to take a random sample of 10 numbers, starting with the number 1 and going through however many rows babby has (in this case, 40,000).¬†¬†\nafter the comma, I have no code, which tells R to give me all the columns (in this case two - the IV and DV)\n\nAs you can see in the above output, R has drawn a random sample of 10 individuals from the list of 40,000. If I run this code again, R will select another 10 individuals from the list of 40,000.\n\nbabby[sample(1:nrow(babby), 10), ]\n\n               IV          DV\n33713  0.08619728  1.63778479\n37126 -0.42197038 -0.65012382\n12418 -0.38048978  0.61041238\n15765 -2.07429669 -0.89532671\n9207   0.54379840 -0.02403073\n31418 -1.52499812  1.27384500\n24609  0.81390193 -0.56375600\n103   -0.29130008 -1.44600496\n10349  0.17771080 -1.27641647\n36940 -0.46201091 -0.67224917\n\n\nIf I want to SAVE this sample (and use it later), I need to give it a name so R remembers what the sample is (and doesn‚Äôt keep creating new samples).¬†\n\nsampy &lt;- babby[sample(1:nrow(babby), 10), ]\nsampy\n\n              IV         DV\n5897   0.8485550 -0.2524885\n20003  0.6540785 -0.1779805\n16     0.4508883  0.2223145\n33756  1.2866107  0.6269824\n14232 -1.0166493  0.3983281\n25490  1.3144997 -0.7714008\n149    0.9310813 -1.3942383\n29671  0.3357943  0.4989499\n35218  0.5225263 -1.7209132\n23309  0.8328597  1.2089172\n\nsampy\n\n              IV         DV\n5897   0.8485550 -0.2524885\n20003  0.6540785 -0.1779805\n16     0.4508883  0.2223145\n33756  1.2866107  0.6269824\n14232 -1.0166493  0.3983281\n25490  1.3144997 -0.7714008\n149    0.9310813 -1.3942383\n29671  0.3357943  0.4989499\n35218  0.5225263 -1.7209132\n23309  0.8328597  1.2089172\n\n\n\n\nOur ‚ÄúPerfect‚Äù Sample Has ‚ÄúError‚Äù\nOkay, we finally have a perfectly random sample of the population - sampy. If we were researchers, we would use this sample to learn something about what the population is like and, like before, define a linear model to examine the relationship between the DV and IV.\n\nplot(DV ~ IV, data = sampy, pch = 19, main = \"Relationship Between DV and IV in SAMPY\", xlab = \"IV (from sampy)\", ylab = \"DV (from Sampy)\")\nmodS &lt;- lm(DV ~ IV, data = sampy)\nabline(modS, lwd = 5, col = 'green')\n\n\n\n\n\n\n\nround(coef(modS), 5)\n\n(Intercept)          IV \n    0.02525    -0.26201 \n\nsummary(modS)$r.squared\n\n[1] 0.03484331\n\n\nOur sample has error - it is not showing us the true nature of the population.\n\nIndeed, we could ask R to generate 10 random samples of 10 individuals, and see these errors repeat.\n\npar(mfrow = c(2,5))\nfor(i in c(1:20)){\n  sampy &lt;- babby[sample(1:nrow(babby), 10), ]\n  plot(DV ~ IV, data = sampy, pch = 19, main = \"Another Sampy\", xlab = \"IV\", ylab = \"DV\")\n  modS &lt;- lm(DV ~ IV, data = sampy)\n  abline(modS, lwd = 5, col = 'green')\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncoef(modS)\n\n(Intercept)          IV \n 0.69109563 -0.02107053 \n\n\nIn none of these samples does the slope equal exactly zero - which as we know is the ‚Äútrue‚Äù slope of our population. Some may be close, but none are exact - they all have some degree of error. Sampling error. (Whoa.)\n\n\n\nImproving the Quality of These Samples\n‚ÄúBut wait, Professor‚Ä¶‚Äù I can hear you scream in your mind (actively engaged while reading this text), ‚Äúthese are not very good samples! The sample size was only 10! We can get a better estimate of the population if we survey more people!‚Äù\nYes, my dear actively engaged student, you are correct. And yet, there will still be sampling error. We can increase the size of the random sample that R takes by changing the code to define sampy such that it is a random sample of 150 individuals from babby : sampy &lt;- babby[sample(1:nrow(babby), 150), ]\nHere are 10 more linear models from 10 random samples of babby, each with a sample size of 1505.¬†\nWhat do you notice when looking at these different linear models?\n\n## Random Samples: n = 150\npar(mfrow = c(2,5))\nfor(i in c(1:20)){\n  sampy &lt;- babby[sample(1:nrow(babby), 150), ]\n  plot(DV ~ IV, data = sampy, pch = 19, main = \"Big Sampy\", xlab = \"IV\", ylab = \"DV\")\n  modS &lt;- lm(DV ~ IV, data = sampy)\n  abline(modS, lwd = 5, col = 'green')\n  #print(coef(modS))\n  #print(summary(modS)$r.squared)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI notice a few things :\n\nEach sample, as instructed, has 150 individuals in the dataset. I can see there are more dots in each scatterplot. Good to know that R did what I asked.\nNone of the lines appear to have a slope of exactly zero, like our population does. A few are close (the third linear model on the top row has a slope = 0.003 and an R2 = 0.000011 - close to zero but not exaclty zero! there is still some error!!!)\nI can see that there‚Äôs less variation in the steepness of the lines. Some slopes (like top row fourth column) appear steeper than others, but I see less extremes in the variation in these slopes when I have a sample size = 150 than when I have a sample size = 10. (I can see this because the green lines are more similar to each other when n = 150 than when n = 10.)\n\nThis last point is a critical idea : we can ‚Äúvisualize‚Äù sampling error by thinking about how much the slopes from multiple samples differ from each other.\n\nA small amount of sampling error would mean that each sample is very similar to the ‚Äútruth‚Äù of our population. If sampling error is small, we‚Äôd expect to see very little variation in our slopes across different samples.¬†\nA large amount of sampling error would mean that each sample is VERY DIFFERENT from the ‚Äútruth‚Äù of our population. If sampling error is large, we‚Äôd expect to see a lot of variation in our slopes across different samples.\n\nBelow, I illustrate sampling error by asking R to take a random sample from my population (where the ‚Äútrue‚Äù slope = 0), save the value of the slope from this sample, and then repeat this process 1000 times.\nThe graphs below show histograms of these 1000 slopes for a sample size of n = 10 (on the left) and n = 150 (on the right). I‚Äôll walk through the graphs below in more detail, but at first glance you can hopefully see that there‚Äôs less variation in our slopes when the sample size is 150 than when the sample size is 10.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe graph on the left reports the slopes of 1000 samples when the sample size = 10.\nThe graph on the right reports the slopes of 1000 samples when the sample size = 150.\n\n\n\nThe range of these random samples (n = 10) was between -1.56 and 1.46.\nThe standard deviation of these 1000 slopes is .37, which tells us that the ‚Äúaverage‚Äù random sample differs from the mean by about .37.\nThe mean of these 1000 slopes is zero (which is the ‚Äútrue‚Äù population mean!!!).\n\n\nThe range of these random samples (n = 150) was between -0.24 and 0.26.\nThe standard deviation of these 1000 slopes is .08, which tells us that the ‚Äúaverage‚Äù random sample differs from the mean by about .08.\nThe mean of these 1000 slopes is zero (which is the ‚Äútrue‚Äù population mean!!!)\n\n\n\n\n\n\nSPOOKY : Distribution of ‚ÄúRandom‚Äù Sample Estimates Will Alwasy Be Normally Distributed and Centered Over the Population Mean.\nWhen taking a random sample from the population, we always expect to see a ‚Äúnormal‚Äù / symmetrical distribution that is centered over the mean of the population. (This is called the Central Limit Theorem.)\nThe distribution of sample estimates (what happens to the slope if we ask R to take a random sample of the population) will always be normally distributed, since a) each estimate is determined by multiple individuals (‚ÄúThere are multiple explanations for why the variation occurs (life is complex!)‚Äù and b)‚Äúthese multiple explanations occur randomly‚Äù (since R is using very good randomization techniques.)¬†\nTLDR : IF we are drawing random samples from a population, we can expect that the distribution of estimates from multiple samples (the many slopes that we find) will be normally distributed. We care about this because if we can predict what random sampling will look like, it will allow us to estimate the amount of variation caused by random sampling error. And we can then build that estimate of sampling error into our model, and try to estimate how ‚Äúwrong‚Äù our sample might be. To be clear, all of this is made up - a replication is the best thing to do if you really want to know whether your sample is representative of the population. But replications can be expensive in terms of time and money, and the ‚Äúpublish or perish‚Äù beast must be fed.\nIn the next part, you‚Äôll learn about a very common way researchers try to estimate sampling error.",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sampling Error and Bias</span>"
    ]
  },
  {
    "objectID": "chapters/9R_SamplingError.html#estimating-sampling-error-with-null-hypothesis-significance-testing-nhst",
    "href": "chapters/9R_SamplingError.html#estimating-sampling-error-with-null-hypothesis-significance-testing-nhst",
    "title": "Sampling Error and Bias",
    "section": "Estimating Sampling Error With Null Hypothesis Significance Testing (NHST)",
    "text": "Estimating Sampling Error With Null Hypothesis Significance Testing (NHST)\nThe goal of NHST is to estimate how much sampling error might be influencing the results. Again - we are making things up here - without repeatedly taking samples from the data, we don‚Äôt actually know how much sampling error might be influencing the results. But in theory, it‚Äôs better to have an estimate of sampling error (even if it‚Äôs wrong) than just pretend that our sample is THE TRUTH‚Ñ¢.\n\nNHST : A Written Explanation\n\nNull Hypothesis Significance Testing : An Assumption that the Null Hypothesis is ‚ÄúTrue‚Äù\nNull Hypothesis Significance Testing (NHST) starts with the assumption that the null hypothesis is ‚Äútrue‚Äù. You can remember this important detail by noting the phrase starts with ‚ÄúNull Hypothesis‚Äù.\nIf the null hypothesis is ‚Äútrue‚Äù, then you would not expect to find a relationship between the two variables (since researchers‚Äô theory - the alternative hypothesis - is often predicting that some relationship between two variables exists).¬†\nIn other words, if the null hypothesis were true, you‚Äôd expect to find a slope of zero - no relationship.\nIf you DID NOT find a slope of zero in your study, then there are two possibilities :\n\nYour study found a real relationship between two variables - the null hypothesis is NOT TRUE.\nYour study experienced some sampling error - the null hypothesis IS TRUE, but you drew a random sample from the population that made it seem like there‚Äôs a relationship between these two variables.¬†\n\nIn order to evaluate whether the non-zero slope you found is due to 1) some real relationship between the two variables or 2) sampling error, you need to determine how much sampling error might be influencing your results.¬†\nMany replications would be the best way to do this. As discussed, replications are costly in terms of time and money (paying for participants, grad student salaries, fMRI machine time, etc.)\nSo researchers have developed methods of estimating sampling error. One method is described below.\n\n\nThe ‚ÄúStandard Error‚Äù : Estimating Sampling Error With NHST\nThe ‚ÄúStandard Error‚Äù is the name given to the NHST approach to estimating sampling error. The ‚Äúconceptual‚Äù equation6 to estimate standard error is as follows :\n\\[\n\\huge \\text{standard error (SE)} = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nRemember that \\(\\sigma\\) is the standard deviation and \\(n\\) is the sample size. Based on this equation, you can determine that the standard error will increase as the standard deviation increases, or when the sample size decreases. Remember that standard error is an estimate of sampling error; you can think of the standard error like standard deviation. However, whereas standard deviation describes how much the average individual score differs from the mean, the standard error estimates how much the average individual samples might differ from the estimated slope (the slope you found in your study). Again, we are making this up - we don‚Äôt know what the sampling error actually will be, or whether the estimate from our sample is a good estimate of the population. But it‚Äôs all we have.\nSo we expect that we will have MORE sampling error when :¬†\n\n‚Ä¶.our standard deviation increases. A larger standard deviation means that individuals are very different from each other (individual scores differ a lot from the mean). If individuals differ a lot from each other, than which individuals are in our sample will matter more (and create more sampling error) than if everyone was the same. Imagine doing a study of robots who are all programmed to give the same answer - I could study one robot, and probably learn about ALL the robots.\n‚Ä¶.our sample size decreases. The more people we have in our study, the smaller we expect sampling error to be. We saw this when we took larger sample sizes of babby. Asking two students what they think of these notes will give me more error than if I ask half the class, or even better, the entire class.\n\nTo be clear - our estimate of sampling error is ENTIRELY MADE UP. We do not actually know how much sampling error there is in our study - we would need to do multiple replications in order to determine this, which would be costly in terms of time and money. So the standard error is a GUESS about sampling error, and a way to help us better understand the slope that we found.\n\nAs a pretend example. Let‚Äôs say I‚Äôm a researcher who found a slope of .50 with a sample size of 200 and a pooled standard deviation of 2.83. My estimate of sampling error would be .2, which would mean that if the null hypothesis were true, I‚Äôd draw a random sample that would (on average) have a slope of .2 or -.2 (even though the ‚Äútrue‚Äù slope was zero).\n\n\nThe ‚Äút-value‚Äù : Contextualizing the difference between your slope and the null (slope = zero).\nNow that we have our estimate of sampling error (the standard error), we want to compare this value to something. Is this sampling error a lot? A little? We can compare this sampling error to the slope that we found. This comparison is called the t-value, and the equation is below :¬†\n\\[\n\\huge t = \\frac{b}{SE}\n\\]\nAll the t-value does is evaluate how large the slope from your study (b = the slope) is, compared to the ‚Äúaverage‚Äù slope you might find due to random sampling error (se = the standard error).¬†\n\n\n\n\n\n\nPop Quiz. As a researcher hoping to show that your slope is ‚Äúreal‚Äù, would you want the t-value to be LARGE or SMALL?\n\n\n\n\n\nYou would want the t-value to be LARGE, since this means that your slope is a lot bigger than the ‚Äúaverage slope‚Äù you might find due to sampling error if the null hypothesis were true (the standard error).\n\n\n\nThe standard error is critical for evaluating the size of your slope. A researcher could find a very large slope - let‚Äôs say a correlation of r = .6. But if the researcher finds that the sampling error is also high (r = .6), then the slope they found could easily be found due to chance random sampling from a population where the true slope is equal to zero. In other words, the standard error helps researchers evaluate whether the slope they found is different enough from the average sampling error they might find if they were taking samples from a population where the slope was zero.\nAs a pretend example : let‚Äôs say that I‚Äôm a researcher who found a slope of .5, with a standard error of .2. My t-value would be .5 / .2 = 2.5 = my slope is 2.5 times as large as the average slope I might find due to random sampling if the null hypothesis were true.\n\n\nThe ‚Äúp-value‚Äù : estimating the probability of observing a t-value this large (or larger) if the Null Hypothesis Were ‚ÄúTrue‚Äù.\nThe Central Limit Theorem (see above) allows us to expect that our random samples from the population will be normally distributed. As a reminder, the normal distribution describes a range of possible scores that differ from the mean, and assigns a probability to these scores. For example, we can use the chart below to estimate that 50% of the scores will be above the mean, that 13.59 + 2.14 + .13% = 15.86% of scores will be above 1 standard deviation, that 64.26% of scores will be between -1 and +1 standard deviations of the mean, that .13% of scores will be below 4 standard deviations of the mean, and so on.\nNote that the graph below reports percentages. But it is also common to report these numbers as percentiles. So a 34.13% would be written as a percentile as .3413.\n\n\nThe p-value, then, describes the probability that you would observe a t-value as large (or larger) than the one that you observed if the null hypothesis were true. Practically, the p-value is the percentage of scores that fall further away from the mean from your t-value. A few examples, using the chart above¬† :\n\nA t-value of -3 would have a p-value of .0013, which means that there is a .13% chance that you would observe a t-value of -3 or more extreme if the null hypothesis were true.\nA t-value of -1 would mean that our slope is as large as the sampling error that we found (the negative sign just means that our slope is negative), and would have a p-value of .1586. This means that we would expect 15.86% of random samples to be as large (or larger) than the slope that we found.¬†\nA t-value of +2 means that our slope is twice as large as the sampling error that we found, and would have a p-value of .0227, which means that we would expect 2.27% of random samples to be as large (or larger) than the slope that we found.¬†\n\nWhen R reports the p-value, it‚Äôs actually calculating the p-value for both sides of the distribution. That is, if your slope had a t-value of 3-standard errors below the mean, R would report a p-value of .026 or 2.6%, since it‚Äôs calculating the probability of the curve that falls to the left of 3 standard deviations below the mean, and also the probability of the curve that falls to the right of 3 standard deviations above the mean.\nThis is called a two-tailed test, and the logic of doing this by default is :¬†\n\nIf we are really pretending to live in the world of the null hypothesis, then the slope we found in our sample is random. And if it‚Äôs random, we could have found a slope this extreme in either the positive OR negative direction. So when estimating the probability of this ‚Äúrandom‚Äù slope occurring, it‚Äôs good to¬†\nA two-tailed test is more conservative, since you are doubling the p-value which increases the probability you report of finding a random slope due to chance. It‚Äôs good practice to be more conservative when reporting statistics, since people are biased to find results in their favor.¬†\n\nSome researchers report a one-tailed test - in R, you would just divide the reported p-value in R in half. The logic in doing this is that researchers claim if they have a strong prediction that their result will be positive (or negative) in direction, they can ignore the other side of the distribution. This has never made sense to me, since NHST is about random sampling (and not the alternative hypothesis) and I‚Äôm always a little suspicious of doing things that make it easier to show your hypothesis was supported.\n\nBack to my pretend example : with a slope of .5, a standard error of .2, and a t-value of 2.5, R would report my p-value (two sided test) to be p = 0.0132. This means there is a 1.3% chance that I would observe a slope as different from zero as .5 (in either a positive or negative direction) due to random sampling error if the null hypothesis were true. This is a low probability! It is unlikely to happen due to random chance (if the null hypothesis were true). And I could say that it was a significant effect.\n\n\nA ‚ÄúSignificant‚Äù Effect\nOkay, time to bring this together. IF the null hypothesis is true, then we expect to find a slope of zero. But we also know that we may not find a slope of zero all the time because of random sampling error. So the question is - how do we know whether our non-zero slope that we found in OUR study is due to sampling error (from a population where the true slope is zero), OR is due to some REAL RELATIONSHIP between the two variables????¬†\nThe answer is that statisticians made up an arbitrary threshold of 5% (or a p-value of .05). If the probability of observing your slope, relative to your estimate of sampling error, is less than 5%, then it means it is UNLIKELY that you observed this slope because of taking some random sample from a population where the slope is zero (sampling error) and MORE LIKELY that you observed this slope because you took a random sample from a population where the slope is not zero.¬†\nIn other words, as a researcher looking to support your theory, you ‚Äúneed‚Äù to find that the p-value is small, because this is the probability that you observed your slope IF THE NULL HYPOTHESIS were ‚Äútrue‚Äù. When this happens, researchers say the effect is ‚Äústatistically significant‚Äù.¬†\nHowever - we need to be careful here! A ‚Äúsignificant effect‚Äù only means that our made-up estimate of sampling error is much smaller than the slope that we observed in our study, and that this gives us a made-up sense of confidence that we can reject the null hypothesis and say that the data supports our theory.\nA significant effect DOES NOT mean :¬†\n\nthe effect we found in our study is real. we don‚Äôt have access to the truth, and are still making a guess about what the population is like based on our limited sample. so just because an effect is significant doesn‚Äôt make it real.\nthe effect we found in our study is not due to chance. there is still a chance that we are making a mistake in our estimate of sampling error. and even a small p-value of .000001 means there is a chance that we observed this slope due to random sampling error7.\nthe effect we found in our study is important. a ‚Äúsignificant effect‚Äù doesn‚Äôt mean the effect is important or meaningful. That‚Äôs a question for your critical thinking brain : are these results important to society or me? How will this knowledge be used?\nthe study used valid methodology. a bad study designed with poorly defined and unreliable measures, a biased sample, or an improper experimental method that is ‚Äúsignificant‚Äù is still a bad study.¬†\n\nSo what does a significant effect mean again? A significant effect means : ‚ÄúWe are unlikely to observe the slope we found in our sample (or one more extreme) if we were to draw a random sample from a population under conditions of the null hypothesis.‚Äù\n\n\nThe 95% Confidence Interval\nTo help ensure that the reader understands the slope found in the study is not the absolute truth, but instead is an estimate that might change from sample to sample, psychologists will often report the slope that they found, along with a range of slopes based on their expected sampling error. If you‚Äôve ever seen a political poll reporting a ‚Äúmargin of error‚Äù, this is an estimate of sampling error.\nTypically, researchers report the 95% Confidence Interval - this defines 95% of the distribution of sample estimates they might expect if they were to experience sampling error around the slope that they found. The 95% confidence interval is an area around the estimate of the original slope, and is defined by the following equation.\n\\[\n\\huge \\text{95% Confidence Interval} = b\\pm 1.96 * SE_b\n\\]\nPositive and Negative 1.96 are the values of the normal distribution that contain 95% of the scores8. Multiplying this value by the estiamted standard error of the slope (which describes how much the slope might vary due to random sampling error) translates these boundaries into the same units as your slope. You can visualize the 95% Confidence Interval below.\n\nSo, back to my pretend example. With a slope of .5, a standard error of .2, and a t-value of 2.5, and a p-value of 0.0132, my 95% confidence interval would be calculated as :¬†\n\n.5 + 1.96*.2 = .892 = this is the upper limit of my estimated 95% confidence interval\n.5 - 1.96*.2 = .108 = this is the lower limit of my estimated 95% confidence interval\n\nNote that a ‚Äúsignificant effect‚Äù should show the upper and lower limits in the same direction as your original slope. So if your slope is positive, the 95% confidence interval should contain all positive numbers. If the 95% confidence interval contains zero (or a mix of positive and negative numbers) than the effect is not considered statistically significant.\nI would then write this as : ‚ÄúI observed a significant and positive relationship between the DV and IV (b = .50, 95% CI = [.11, .89], t(200) = 2.5, p (two-tailed) = .0132).‚Äù¬†\nWHEW!!!\n\n\n\nCalculating NHST in R : Very Easy!\nY‚Äôall will like this - it is very easy to do all the NHST stuff in R. First, you start with a linear model. I‚Äôm going to draw from the MBA study we‚Äôve used before, and examine the relationship between Narcissism (NPI) and Age (age).\n\nmba &lt;- read.csv(\"~/Dropbox/!WHY STATS/Class Datasets/hormone_data.csv\", stringsAsFactors = T)\nage.mod &lt;- lm(NPI ~ age, data = mba)\npar(mfrow = c(1,1))\nplot(NPI ~ age, data = mba, pch = 19, xlab = \"Age\", ylab = \"Narcissism (NPI)\")\nabline(age.mod, lwd = 5, col = 'red')\n\n\n\n\n\n\n\n\nIf I look at the coefficients of the model :\n\ncoef(age.mod)\n\n(Intercept)         age \n 4.74855460 -0.05651782 \n\n\nSomeone with an age of 0 is predicted to have a Narcissism score of 4.7. These data don‚Äôt make sense, since our data were only collected on adults.\nFor every year someone ages, we predict their narcissism to go down by .0565. I can see this as negative slope I drew on the graph.\n\nTo do all the NHST stuff, all I need to run is the summary() function on the model that I defined; in this case I would run summary(age.mod) and get the following output :\n\nsummary(age.mod)\n\n\nCall:\nlm(formula = NPI ~ age, data = mba)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.25302 -0.34583  0.00417  0.27644  1.41394 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.74855    0.61722   7.693  7.8e-12 ***\nage         -0.05652    0.02217  -2.549   0.0122 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5219 on 106 degrees of freedom\n  (14 observations deleted due to missingness)\nMultiple R-squared:  0.05778,   Adjusted R-squared:  0.04889 \nF-statistic:   6.5 on 1 and 106 DF,  p-value: 0.01222\n\n\n\nformula : hey, that‚Äôs my model!\nresiduals : these describe some descriptive statistics for the residuals in my model.\ncoefficients : these will report the intercept and slope, along with the NHST statistics for these terms. You can ignore the intercept for now and just focus on the columns for the slope (age) :¬†\n\nage (estimate) : = - .057 = this is the estimate of the slope for age. There‚Äôs a negative relationship between these two variables.\nstd. error = .02217 = this is my estimate of the standard error (sampling error) for age. If the null hypothesis were true and the ‚Äútrue slope‚Äù was 0, I‚Äôd expect to find an average slope of .02 or -.02 just due to sampling error.\nt-value = -2.55 = my slope is 2.55 times larger than the standard error. I can confirm that -.057 / .02217 = 2.55. Note that when reporting the t-value, it‚Äôs also important to look up the degrees of freedom (which is the sample size - the number of things in your model.) R reports these degrees of freedom next to the residual standard error.\np-value = 0.0122 = if the null were true, I‚Äôd expect to sample a slope of -.057 (or +.057) or more extreme about 1.22% of the time. This is a low probability and less than .05 (or 5%) so I get my little star and can say that I reject the null hypothesis - the relationship between age and narcissism is unlikely to be due to random sampling error from a null distribution.\n95% Confidence Interval : this is not calculated, but I can do a rough estimate by taking my slope (-.057) and adding and subtracting 1.96 * .02, so the 95% CI = [-0.0962, -0.0178]. Note that this range does not include zero, so it‚Äôs another way of showing the effect is significant.\n\\(R^2\\): hey look, it‚Äôs our good friend R2! Go ahead and focus on the ‚Äúmultiple R-squared‚Äù = .05778.\n\n\nI would write this up as the following : ‚ÄúI observed a small but significant negative relationship between age and narcissism (b = -0.05, 95% CI = [-0.0962, -0.0178], R2 = .06, t(106) = -2.55, p = .01).\n\n\nNHST : Video Explanation\nFor the YouTube fans.",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sampling Error and Bias</span>"
    ]
  },
  {
    "objectID": "chapters/9R_SamplingError.html#check-out-statistical-significance",
    "href": "chapters/9R_SamplingError.html#check-out-statistical-significance",
    "title": "Sampling Error and Bias",
    "section": "Check-Out: Statistical Significance",
    "text": "Check-Out: Statistical Significance\nThis shit is confusing, so here are some questions on NHST to assess your understanding. We will review answers to these in our next lecture, so save your work so we can review!!!\nThanks for reading! Lemme know if you have questions on Discord :)",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Sampling Error and Bias</span>"
    ]
  },
  {
    "objectID": "chapters/10R_NHSTPower.html#the-purpose-of-multiple-regression",
    "href": "chapters/10R_NHSTPower.html#the-purpose-of-multiple-regression",
    "title": "Multiple Regression",
    "section": "",
    "text": "Examining the unique effects of variables : the first benefit of a multiple linear regression is that we can test whether the effect of one variable (IV1) on another (DV) is unique to that variable, or whether that relationship is also explained by some other variable (IV2). We‚Äôll talk more about this idea throughout this document.\nExamining the dependent effects of variables : another benefit of the multiple linear regression is that we can examine whether the relationship between one independent variable (IV1) and the dependent variable (DV) depends on another variable (IV2). This idea is called an interaction effect - we will talk about this in a separate lecture.",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/10R_NHSTPower.html#multivariate-linear-regression-a-more-complex-model",
    "href": "chapters/10R_NHSTPower.html#multivariate-linear-regression-a-more-complex-model",
    "title": "Multiple Regression",
    "section": "Multivariate Linear Regression : A More Complex Model",
    "text": "Multivariate Linear Regression : A More Complex Model\nIn order to better understand the complexity of human life, we‚Äôll need to define a more complex model that explains some dependent variable as a function of multiple independent variables. This is called a multivariate (multiple variables) linear regression model, or a multiple regression for short. In a multiple linear regression, we are going to use‚Ä¶wait for it‚Ä¶multiple independent variables to make predictions about the dependent variable.¬†\nWe‚Äôll now write our model out like this :\n\\[\\huge y_i = a + b_1*X_{1i} + b_2*X_{2i} + ... + b_k*X_{ki} + {\\epsilon}_i\\]\nAt first, this model may look scary, but it‚Äôs actually quite familiar - we are making predictions about some specific individual‚Äôs score on some specific variable (y), but now are using information in multiple variables (X1 and X2) to update our predictions of y. The ‚Äôk‚Äôs indicate that you can build a model with as many predictors as you want (this will create complications that we‚Äôll talk about later‚Ä¶).\nBelow is a model where we predict prestige from both education and job type. Spend a few minutes looking at this output, and see if you can interpret it. (Don‚Äôt worry, we‚Äôll get to the NHST stuff later.)\n\nmod4 &lt;- lm(prestige ~ education + type, data = Prestige)\ncoef(mod4)\n\n(Intercept)   education    typeprof      typewc \n  -2.698159    4.572793    6.142444   -5.458495 \n\n\nAlright, hopefully you felt like a lot of the output from this multivariate linear regression model was somewhat familiar. If not, that‚Äôs okay‚Ä¶the good news is that much of this output can be interpreted in the SAME WAY that we interpreted the output from a bivariate relationship.¬†\nComponents of the Multivariate Linear Regression\nThis more complex model is comprised of the following components :¬†\n\nthe intercept : I say intercept, you say‚Ä¶.3 The intercept in this model describes the predicted prestige for someone with zero years of education, who is NOT a professional, and is NOT a white collar worker - in other words an uneducated blue collar worker. Because no one in the sample actually had less than six years of education, an education of zero does not make sense, which is why the prestige is below zero.\nthe slope of education : this describes the relationship between education and prestige - for every year of education, we add 4.6 prestige points. Critically, this is the relationship between education and prestige controlling for the effect of job type (the unique effect of education.)\nthe slope of professional : this coefficient describes the change in our predictions between the reference level (blue collar workers - defined by the intercept) and professionals, controlling for the effect of education (the unique effect of being a professional worker). When accounting for the effect of education in the model, professionals have 6.1 more prestige points than blue collar workers.\nthe slope of white collar : this coefficient describes the change in our predictions between the reference level (blue collar workers - defined by the intercept) and white collar workers, controlling for the effect of education. When accounting for the effect of education in the model, white collar workers are predicted to have 5.6 less prestige points than blue collar workers.\n\nWe can use this model to make predictions for specific individuals : ≈∂ ~ -2.7 + 4.6(Xeducation) + 6.1(Xprof) - 5.5 (Xwc)\nPop Quiz : Use this model to calculate the predicted values of Y for‚Ä¶.\n\na blue collar worker with 10 years of education?\na white collar worker with 12 years of education?\na professional worker with 12 years of education?\n\nHere are the answers. No peeking!4\n\nComparing Models : The Regression Table.\nBecause your multivariate model will contain two different independent variables, it‚Äôs likely that the scale of your two IVs will be different. To assist in comparing the change between models, or comparing the slopes within one multivariate model, it‚Äôs important to scale (standardize or z-score) your variables.\nWe did this before, when we used the scale function to transform each variable in the model.\nBut there‚Äôs a better way to do this, AND to export our analyses. All in one handy-dandy table.\nIf you are reading this far, go ahead and try a new function - export_summs() from the jtools library. You‚Äôll need to install this new package install.packages(\"jtools\"), and then load this to your library.\nWe can use the export_summs() function to export the summary of multiple models, and then ask R to transform both the response (DV) and IVs.\n\n# install.packages(\"jtools\")\nlibrary(jtools)\nexport_summs(mod1, mod2, mod4, transform.response = T, scale = T, center = T, binary.factors = T)\n\n\n\nModel 1Model 2Model 3\n\n(Intercept)-0.69 ***0.00¬†¬†¬†¬†-0.04¬†¬†¬†¬†\n\n(0.08)¬†¬†¬†(0.05)¬†¬†¬†(0.12)¬†¬†¬†\n\ntypeprof1.89 ***¬†¬†¬†¬†¬†¬†¬†0.36¬†¬†¬†¬†\n\n(0.13)¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†(0.25)¬†¬†¬†\n\ntypewc0.39 **¬†¬†¬†¬†¬†¬†¬†¬†-0.32 *¬†¬†\n\n(0.14)¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†(0.16)¬†¬†¬†\n\neducation¬†¬†¬†¬†¬†¬†¬†0.85 ***0.74 ***\n\n¬†¬†¬†¬†¬†¬†¬†(0.05)¬†¬†¬†(0.11)¬†¬†¬†\n\nN98¬†¬†¬†¬†¬†¬†¬†102¬†¬†¬†¬†¬†¬†¬†98¬†¬†¬†¬†¬†¬†¬†\n\nR20.70¬†¬†¬†¬†0.72¬†¬†¬†¬†0.80¬†¬†¬†¬†\n\nAll continuous variables are mean-centered and scaled by 1 standard deviation.  *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nWhat‚Äôs lovely about this kind of table is we can look across each row, and see how the coefficients for each variable change across our models. Remember - the reason we were doing a multivariate regression is to see how the bivariate relationships between the independent and dependent variables change when you account for redundant covariation.\n\n\nTypes of Changes Between the Multivariate and Bivariate Models\nThere are three different ways that the relationships can change from the bivariate to multivariate model - I‚Äôm simplifying these concepts a bit for the sake of this introductory class. Links to more information if you want to learn more about the precise definition and application of the terms.¬†\n\nIndependent Effects : The relationship between IV1 and the DV does not substantially change when IV2 is included in the model. This means that the relationship between IV1 and the DV is not explained by IV2. If your goal is to show that there is a significant relationship between IV1 and the DV, and that relationship does not go away when you include IV2 in your model, then this is what you are hoping to find.\nMediation Effects : The relationship between IV1 and the DV is weakened (which is called partial mediation) or goes away completely (which is called full mediation) when IV2 is included in the model. This means that the relationship between IV1 and the DV is dependent on the other variable. You can read more about this here.¬†\nSuppressor Effect : The relationship between IV1 and the DV is strengthened (or changes direction) when IV2 is included in the model. You can read more about this here.¬†\n\n\n\n\n\n\n\nACTIVITY : Look over the models. How do the slopes change from Model 1 to Model 3? From Model 2 to Model 3?\n\n\n\n\n\nThe difference (slope) between professionals and blue collar workers that we saw in Model 1 (√ü = 1.89) goes down and becomes non-significant (√ü = .36; this is called mediation). The the difference (slope) between white collar and blue collar workers in Model 1 (√ü = .39) changes in direction in Model 3 to become (√ü = -.32; this is called a suppressor effect).\nThe effect of education as seen in the bivariate model (Model 2 √ü = .85) remains about the same in Model 3 (√ü = .74; this is called an independent effect, since the effect of education is not influenced by the addition of job type in the model).\n\n\n\n\n\nReasons Why The Relationship Changes Between Models\nRemember, there are always two reasons why we‚Äôd see a change.\n\nchance : the change in the slope was just due to some kind of sampling error; the difference between the models is really just random chance.\nsome real effect. IV2 really does change the relationship between IV1 and the DV : that is, there is some real relationship between IV2, IV1, and the DV that changes the slopes in your model.\n\n\nThere are various ways to test for whether the change in slopes is large enough to be important / statistically significant. One method is is something called bootstrapping - I‚Äôll eventually put this in a supplemental chapter, but the basic idea is that you run a for-loop to resample the data, estimate the slope in a bivariate vs.¬†multivariate model (from a new dataset), and then save the difference in slopes to ‚Äúbucket‚Äù (or whatever you have named the array), and then repeat the process 1000 times. Another method to test for the difference is called the ‚ÄúSobel Test‚Äù; you can read about it here or here if you want. Or not!",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/10R_NHSTPower.html#more-practice",
    "href": "chapters/10R_NHSTPower.html#more-practice",
    "title": "Multiple Regression",
    "section": "More Practice",
    "text": "More Practice\nOkay, that was a lot! A few more resources to help and test your understanding.\n\nA MULTIPLE REGRESSION VIDEO :\nHey, do you like my disembodied voice explaining things on top of an R screenshot? Well good news, in this video I go through another example of multiple regression in R.\n\nHere‚Äôs the R script I used; the data come from the ‚Äúhormone‚Äù dataset, posted to bCourses.\n\n\n\n\nCheck-In : Here‚Äôs a Practice Quiz\nUse the check-in to practice and prepare for your quiz this week. See the answer key videos below, but try on your own first.\n\nProfessor Does the Check-In (Part 1)\n\n\n\nProfessor Does the Check-In (Part 2)\n\n\n\n\nCheck-Out\nhow‚Äôs it going and what should I focus on for our lecture next week.\nYEAH!",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/10R_NHSTPower.html#footnotes",
    "href": "chapters/10R_NHSTPower.html#footnotes",
    "title": "Multiple Regression",
    "section": "",
    "text": "since this is written. har har.‚Ü©Ô∏é\nwe‚Äôll talk about this point (an interaction effect) in the next set of lecture notes.‚Ü©Ô∏é\nTHE PREDICTED VALUE OF Y WHEN ALL X VALUES ARE ZERO‚Ü©Ô∏é\n43.3, 47, and 58.6.‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/8R_3PlusLevelsExperiments.html",
    "href": "chapters/8R_3PlusLevelsExperiments.html",
    "title": "More Levels and Experiments",
    "section": "",
    "text": "Part 1 : The Linear Model with a Categorical IV‚Ä¶with THREE+ Levels\nIn Chapter 7, we showed how the linear model could be adapted to predict a numeric DV when the IV was a categorical variable with two levels. And guess what? When the IV has more than three levels, we can use the same linear model. Hooray! The only difference is now you have multiple levels that differ from the intercept (or ‚Äúreference group‚Äù).\nLet‚Äôs mix it up, and see if some good ol‚Äô fashioned YOUTUBE VIDEOS OF A DISEMBODIED VOICE can explain this.",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/8R_3PlusLevelsExperiments.html#part-1-the-linear-model-with-a-categorical-ivwith-three-levels",
    "href": "chapters/8R_3PlusLevelsExperiments.html#part-1-the-linear-model-with-a-categorical-ivwith-three-levels",
    "title": "More Levels and Experiments",
    "section": "",
    "text": "Video 1 : Defining the Model with the lm() function\n\nhere‚Äôs a link to R Script (as used in the video)\n\n\n\npar(mfrow = c(1,2))\nhist(presto$prestige)\nplot(presto$type)\n\n\n\n\n\n\n\nmod &lt;- lm(prestige ~ type, data = presto)\nmod\n\n\nCall:\nlm(formula = prestige ~ type, data = presto)\n\nCoefficients:\n(Intercept)     typeprof       typewc  \n     35.527       32.321        6.716  \n\n\n\n\nVideo 2 : Interpreting the Model\n\n\nThe Linear Model Equation:\n\ncoef(mod)\n\n(Intercept)    typeprof      typewc \n  35.527273   32.321114    6.716206 \n\n\n\n\nUsing the Equation and Dummy Coding to Generate Predicted Values\n\n\n\n\n\n\n\n\n\n\n\n\n(the intercept)\n35.5\nX1\n(typeprof)\n32.3\nX2\n(typewc)\n6.7\nCalculations\nPredicted Value\n\n\nbc\n1\n0\n0\n35.5 + 32.3*0 + 6.7*0\n= 35.5\n\n\nprof\n1\n1\n0\n35.5 + 32.3*1 + 6.7*0\n= 67.8\n\n\nwc\n1\n0\n1\n35.5 + 32.3*0 + 6.7*1\n= 42.2\n\n\n\n\n\nYes, Professor, A Picture is Worth‚Ä¶.1000 Words.\n\npar(mfrow = c(1,2))\nplot(presto$prestige, col = presto$type, pch = 19)\nabline(h = coef(mod)[1] + coef(mod)[2], col = 'red', lwd = 5)\nabline(h = coef(mod)[1] + coef(mod)[3], col = 'green', lwd = 5)\nabline(h = coef(mod)[1], col = 'black', lwd = 5) # blue collar\n\nplotmeans(prestige ~ type, data = presto, connect = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nVideo 3 : Releveling the Variable\n\n\npresto$typeR &lt;- relevel(presto$type, ref = \"prof\")\nmod2 &lt;- lm(prestige ~ typeR, data = presto)\nplotmeans(prestige ~ typeR, data = presto, connect = FALSE)\n\n\n\n\n\n\n\ncoef(mod2)\n\n(Intercept)     typeRbc     typeRwc \n   67.84839   -32.32111   -25.60491 \n\n\n\n\nVideo 4 : \\(R^2\\) for a Categorical Model\n\n\npar(mfrow = c(1,2))\nplot(presto$prestige, main = \"The Mean as Our Prediction\")\nabline(h = mean(presto$prestige), )\n\nplot(presto$prestige, col = presto$type, pch = 19, main = \"The Model (Job Type) As Our Prediction\")\nabline(h = coef(mod)[1] + coef(mod)[2], col = 'red', lwd = 5)\nabline(h = coef(mod)[1] + coef(mod)[3], col = 'green', lwd = 5)\nabline(h = coef(mod)[1], col = 'black', lwd = 5) # blue collar",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/8R_3PlusLevelsExperiments.html#check-in-to-assess-your-understanding-here-no-r-required",
    "href": "chapters/8R_3PlusLevelsExperiments.html#check-in-to-assess-your-understanding-here-no-r-required",
    "title": "More Levels and Experiments",
    "section": "CHECK-IN TO ASSESS YOUR UNDERSTANDING HERE [no r required]",
    "text": "CHECK-IN TO ASSESS YOUR UNDERSTANDING HERE [no r required]",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/8R_3PlusLevelsExperiments.html#part-2-experimental-methods",
    "href": "chapters/8R_3PlusLevelsExperiments.html#part-2-experimental-methods",
    "title": "More Levels and Experiments",
    "section": "Part 2 : Experimental Methods",
    "text": "Part 2 : Experimental Methods\nLast chapter, we learned the ‚Äúfour reasons‚Äù why you might find a ‚Äúpattern in the data‚Äù (another way of saying why ‚Äúcorrelation does not equal causation‚Äù. However, scientists and psychologists often want (or need) to establish causation, and an experiment is the ‚Äúgold standard‚Äù approach for how to do this.\nScientists and psychologists often want (or need) to establish causation, and an experiment is the ‚Äúgold standard‚Äù approach for how to do this.\nI‚Äôm guessing y‚Äôall have learned about experiments in many other classes, so won‚Äôt spend pages and pages and pages going over it again here.1\nHere‚Äôs a supplemental chapter on experiments that reviews some key terms you should be familiar with : experimental manipulation; extraneous variables as ‚Äúnoise‚Äù; random assignment; placebo effects; external validity; construct validity; experimenter expectancy effects.\n\nThe Definition of Causality\n\nThe cause and effect are contiguous in space and time.\nThe cause must be prior to the effect. (no reverse causation)\nThere must be a constant union betwixt the cause and effect. (‚ÄúTis chiefly this quality, that constitutes the relation.‚Äù) (no random chance)\nThe same cause always produces the same effect, and the same effect never arises but from the same cause. (not ‚Äújust‚Äù some third variable) [^1]\n\n[^1] but remember, life is complex and there are often multiple causes of human behavior!\n\n\nThe Google Experiment\nWhen I worked at Google as an intern for one summer2, corporate PR told a story about their ‚Äúdata driven approach‚Äù, where no decision was left to mere chance. Even something as simple as the color font they used could be the focus of an analytic research question.\n\n\n\n\n\n\n\nGoogle Homepage : Before Experiments\nGoogle Homepage : After Experiments\n\n\n\n\n\n\n\nWatch the video below. You can read more about this study here.\n\n\n\n\n\n\nThen, see if you can identify the different parts of an experiment.\n\nlinear model : DV ~ IV (what was manipulated) + confound variables + error\nmanipulation : what were the treatment and control groups?\nrandom assignment : how were confound variables balanced across conditions?\ndouble-blind : did the study avoid demand characteristics & placebo effects?\ngeneralizability : did the study have external validity? what was the effect size (R2)?\nethics : should researchers do this type of study [predict & control]\n\n\n\n\n\n\n\nAnswers to Google Shade of Blue Experiment\n\n\n\n\n\n\nlinear model : number of ads that peopled clicked on ~ shade of blue people saw + age + location + income + education + media literacy + relevance of the ad + etc + error\nmanipulation : ‚Äúcontrol‚Äù group = shade of blue (existing shade of blue); treatment group = shade of blue.\nrandom assignment : participants were randomly assigned to see links in one shade of blue or another. because this was randomly assigned, all the other differences between people (those variables that might affect the DV, such as age or location) are ‚Äúbalanced out‚Äù.\ndouble-blind : the participant didn‚Äôt know that google was manipulating the shade of blue to get them to click on ads. the website (google) doesn‚Äôt know whats going on.\ngeneralizability : yes, high external validity! Google was changing its own website. an example of low external validity would be printing out a sheet with different shades of blue that users ‚Äúclick‚Äù on with their finger.\nethics : WOULD LOVE TO HEAR FROM Y‚ÄôALL : do you think it‚Äôs ethical for companies like Google to do this research???",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/8R_3PlusLevelsExperiments.html#footnotes",
    "href": "chapters/8R_3PlusLevelsExperiments.html#footnotes",
    "title": "More Levels and Experiments",
    "section": "",
    "text": "I‚Äôll just spend pages going over it. Hah hah.‚Ü©Ô∏é\nwell-fed; gratuitously paid; soul-drained. I was in their ‚ÄúPeople Operations‚Äù (/HR) department, helping them set up longitudinal surveys and do various other research projects on compensation, appreciation, and diversity that helped feed the corporate beast.‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Predicting People",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>More Levels and Experiments</span>"
    ]
  },
  {
    "objectID": "chapters/10R_MultipleRegression.html",
    "href": "chapters/10R_MultipleRegression.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "The Purpose of Multiple Regression\nKey Questions : What is redundant covariation and how does this relate to the idea of a 3rd variable?\n‚ÄúThe Whole is Greater Than the Sum of Its Parts‚Äù\nI like the above work by Max Ernst; like all evocative art it manages to transcend the individual brush strokes and colors to express a sense of terror. But if you were to isolate each line and color into its separate components - canvas; blue; brown; red - the sum of those different parts wouldn‚Äôt equal the work as a whole.\nThe idea behind a multiple regression is the same - by combining two separate independent variables into one integrated model, researchers can understand more about the phenomenon than they would understand if they just examined the results of two separate bivariate models.\nSpecifically, there are two main benefits to the multiple regression :\nThis first benefit to a multiple regression may sound familiar; we talked about it (briefly) in the beginning of the semester in the context of confound vs.¬†control variables.\nConfound vs.¬†Control Variables\nThe basic idea was that many variables explain human life, and it‚Äôs hard to know whether the relationships we find between one independent variable and the dependent variable are specific to that one independent variable, or whether there‚Äôs some other variable that might be influencing the relationship. We talked about this earlier in the semester when we talked about the idea behind a confound variable - a variable that is not part of your model, but would influence the results. The classic example is that ice cream sales are related to murder rates. Of course, ice cream does not really contribute to people getting murdered. There‚Äôs a confound variable - heat - that is related to both how much ice cream is sold (the more heat, the more people eat ice cream) and murder (the hotter it is, the more likely people are to kill each other‚Ä¶apparently.) And if you account for that confound variable by including it in your model, then you‚Äôd find that the relationship between ice cream and murder goes away‚Ä¶it‚Äôs explained by the relationship between heat and murder.\nRecap : The Principle of Covariation\nOur goal with multiple linear regression is the same goal we‚Äôve been working with so far this semester - to explain complexity. To achieve this goal, we‚Äôve been relying on something that I think of as the ‚Äúprinciple of covariation‚Äù. With a bivariate linear regression (what we‚Äôve been doing so far this semester), this involves explaining variation on one psychological dimension (the dependent variable) based on variation on another psychological dimension (the independent variable). In other words, making predictions about Y based on information in X.\nWe wrote out this bivariate model like so :\n\\[\\huge y_i = a + b_1*X_{1i} + {\\epsilon}_i\\]\nTo make sure we are all on the same page1, let‚Äôs recap what‚Äôs going on with this model. On the left-hand side, we are making predictions for some variable (y : the dependent variable) - specifically an individual‚Äôs score on that variable (yi : the tiny i represents some specific individual in the dataset). On the right-hand side of the equation, we have a starting place for our predictions (a : the intercept), and then a slope (b1) that describes how we adjust our predictions of Y based on the individual‚Äôs specific value of some other variable (X1i : the first independent variable). And since human life is complex, our predictions will not be perfect, but will have error (ei) which we define as the difference between the individual‚Äôs actual score (yi) and our predictions for that person‚Äôs score (a + b1X1i). Neat.\nSo far, we‚Äôve used the linear model to make predictions of continuous variables based on categorical variables. For example, in the Prestige dataset (download HERE) we predicted prestige from job type (a categorical factor with three levels - blue collar, professional, and white collar).\nlibrary(car)\n\nLoading required package: carData\n\nlibrary(gplots)\n\n\nAttaching package: 'gplots'\n\n\nThe following object is masked from 'package:stats':\n\n    lowess\n\nmod1 &lt;- lm(prestige ~ type, data = Prestige)\nplotmeans(prestige ~ type, data = Prestige, connect = F, ylab = \"Prestige\", xlab = \"Job Type\")\n\n\n\n\n\n\n\nsummary(mod1)\n\n\nCall:\nlm(formula = prestige ~ type, data = Prestige)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.2273  -7.1773  -0.0854   6.1174  25.2565 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   35.527      1.432  24.810  &lt; 2e-16 ***\ntypeprof      32.321      2.227  14.511  &lt; 2e-16 ***\ntypewc         6.716      2.444   2.748  0.00718 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.499 on 95 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.6976,    Adjusted R-squared:  0.6913 \nF-statistic: 109.6 on 2 and 95 DF,  p-value: &lt; 2.2e-16\nWe also used this linear model to make predictions of continuous variables (e.g., prestige) based on other continuous variables (e.g., education).\nmod2 &lt;- lm(prestige ~ education, data = Prestige)\nplot(prestige ~ education, data = Prestige, xlab = \"Years of Education\", ylab = \"Prestige\")\nabline(mod2, lwd = 5, col = 'red')\n\n\n\n\n\n\n\nsummary(mod2)\n\n\nCall:\nlm(formula = prestige ~ education, data = Prestige)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.0397  -6.5228   0.6611   6.7430  18.1636 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -10.732      3.677  -2.919  0.00434 ** \neducation      5.361      0.332  16.148  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.103 on 100 degrees of freedom\nMultiple R-squared:  0.7228,    Adjusted R-squared:   0.72 \nF-statistic: 260.8 on 1 and 100 DF,  p-value: &lt; 2.2e-16\nRedundant Covariation\nWe could go through life (and statistics) by considering simple relationships between two variables. These kinds of bivariate models are a good (and necessary) place to start our inquiry. But no psychological phenomenon is entirely explained by any one variable. Instead, human life is explained by multiple variables that are often related to each other and sometimes work together2 in order to influence behavior. We saw this in the example above, where prestige appears to be separately explained both by job type and education. But the situation gets more complicated, because as a quick test in R reveals, job type and education are also related to each other.\nmod3 &lt;- lm(education ~ type, data = Prestige)\nsummary(mod3)\n\n\nCall:\nlm(formula = education ~ type, data = Prestige)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.99419 -0.80932  0.08947  0.61392  2.57068 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   8.3593     0.1800  46.446  &lt; 2e-16 ***\ntypeprof      5.7249     0.2799  20.450  &lt; 2e-16 ***\ntypewc        2.6624     0.3072   8.667 1.16e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.194 on 95 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.8153,    Adjusted R-squared:  0.8114 \nF-statistic: 209.6 on 2 and 95 DF,  p-value: &lt; 2.2e-16\n\nplotmeans(education ~ type, data = Prestige, connect = F, xlab = \"Job Type\", ylab = \"Years of Education\")\nCompare this output (and graph) to the output (and graph) where we predicted prestige from job type. Spoiler alert - the effects are pretty similar. Blue collar workers are predicted to have the lowest level of education (8.35 years), professionals have 5.72 years of education more than blue collar workers (a significant difference), and white collar workers have 2.66 years of education more than blue collar workers (also a significant difference).\nThat job type, education, and prestige are all related to each other represents redundant covariation and raises an important possibility - the relationship between job type and prestige could really be due to the relationship between education and prestige. That is, since jobs with more education are rated as having more prestige, and blue collar workers have the least education (on average), the reason why blue collar jobs have the least amount of prestige could be better explained by differences in education. Similarly, professionals might be rated as having the most prestige because they have the most education. Of course, it‚Äôs also possible that education is related to prestige because of the type of job that workers have.\nWith separate bivariate models, it‚Äôs impossible to know whether these two independent variables are uniquely related to prestige or whether one variable is more related to prestige than another because we are only looking at one relationship at a time. The multivariate regression - one that predicts prestige simultaneously from both education and job type - will help sort out this issue.",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/10R_MultipleRegression.html#the-purpose-of-multiple-regression",
    "href": "chapters/10R_MultipleRegression.html#the-purpose-of-multiple-regression",
    "title": "Multiple Regression",
    "section": "",
    "text": "Examining the unique effects of variables : the first benefit of a multiple linear regression is that we can test whether the effect of one variable (IV1) on another (DV) is unique to that variable, or whether that relationship is also explained by some other variable (IV2). We‚Äôll talk more about this idea throughout this document.\nExamining the dependent effects of variables : another benefit of the multiple linear regression is that we can examine whether the relationship between one independent variable (IV1) and the dependent variable (DV) depends on another variable (IV2). This idea is called an interaction effect - we will talk about this in a separate lecture.",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/10R_MultipleRegression.html#multivariate-linear-regression-a-more-complex-model",
    "href": "chapters/10R_MultipleRegression.html#multivariate-linear-regression-a-more-complex-model",
    "title": "Multiple Regression",
    "section": "Multivariate Linear Regression : A More Complex Model",
    "text": "Multivariate Linear Regression : A More Complex Model\nIn order to better understand the complexity of human life, we‚Äôll need to define a more complex model that explains some dependent variable as a function of multiple independent variables. This is called a multivariate (multiple variables) linear regression model, or a multiple regression for short. In a multiple linear regression, we are going to use‚Ä¶wait for it‚Ä¶multiple independent variables to make predictions about the dependent variable.¬†\nWe‚Äôll now write our model out like this :\n\\[\\huge y_i = a + b_1*X_{1i} + b_2*X_{2i} + ... + b_k*X_{ki} + {\\epsilon}_i\\]\nAt first, this model may look scary, but it‚Äôs actually quite familiar - we are making predictions about some specific individual‚Äôs score on some specific variable (y), but now are using information in multiple variables (X1 and X2) to update our predictions of y. The ‚Äôk‚Äôs indicate that you can build a model with as many predictors as you want (this will create complications that we‚Äôll talk about later‚Ä¶).\nBelow is a model where we predict prestige from both education and job type. Spend a few minutes looking at this output, and see if you can interpret it. (Don‚Äôt worry, we‚Äôll get to the NHST stuff later.)\n\nmod4 &lt;- lm(prestige ~ education + type, data = Prestige)\ncoef(mod4)\n\n(Intercept)   education    typeprof      typewc \n  -2.698159    4.572793    6.142444   -5.458495 \n\n\nAlright, hopefully you felt like a lot of the output from this multivariate linear regression model was somewhat familiar. If not, that‚Äôs okay‚Ä¶the good news is that much of this output can be interpreted in the SAME WAY that we interpreted the output from a bivariate relationship.¬†\nComponents of the Multivariate Linear Regression\nThis more complex model is comprised of the following components :¬†\n\nthe intercept : I say intercept, you say‚Ä¶.3 The intercept in this model describes the predicted prestige for someone with zero years of education, who is NOT a professional, and is NOT a white collar worker - in other words an uneducated blue collar worker. Because no one in the sample actually had less than six years of education, an education of zero does not make sense, which is why the prestige is below zero.\nthe slope of education : this describes the relationship between education and prestige - for every year of education, we add 4.6 prestige points. Critically, this is the relationship between education and prestige controlling for the effect of job type (the unique effect of education.)\nthe slope of professional : this coefficient describes the change in our predictions between the reference level (blue collar workers - defined by the intercept) and professionals, controlling for the effect of education (the unique effect of being a professional worker). When accounting for the effect of education in the model, professionals have 6.1 more prestige points than blue collar workers.\nthe slope of white collar : this coefficient describes the change in our predictions between the reference level (blue collar workers - defined by the intercept) and white collar workers, controlling for the effect of education. When accounting for the effect of education in the model, white collar workers are predicted to have 5.6 less prestige points than blue collar workers.\n\nWe can use this model to make predictions for specific individuals : ≈∂ ~ -2.7 + 4.6(Xeducation) + 6.1(Xprof) - 5.5 (Xwc)\nPop Quiz : Use this model to calculate the predicted values of Y for‚Ä¶.\n\na blue collar worker with 10 years of education?\na white collar worker with 12 years of education?\na professional worker with 12 years of education?\n\nHere are the answers. No peeking!4\n\nComparing Models : The Regression Table.\nBecause your multivariate model will contain two different independent variables, it‚Äôs likely that the scale of your two IVs will be different. To assist in comparing the change between models, or comparing the slopes within one multivariate model, it‚Äôs important to scale (standardize or z-score) your variables.\nWe did this before, when we used the scale function to transform each variable in the model.\nBut there‚Äôs a better way to do this, AND to export our analyses. All in one handy-dandy table.\nIf you are reading this far, go ahead and try a new function - export_summs() from the jtools library. You‚Äôll need to install this new package install.packages(\"jtools\"), and then load this to your library.\nWe can use the export_summs() function to export the summary of multiple models, and then ask R to transform both the response (DV) and IVs.\n\n# install.packages(\"jtools\")\nlibrary(jtools)\nexport_summs(mod1, mod2, mod4, transform.response = T, scale = T, center = T, binary.factors = T)\n\n\n\nModel 1Model 2Model 3\n\n(Intercept)-0.69 ***0.00¬†¬†¬†¬†-0.04¬†¬†¬†¬†\n\n(0.08)¬†¬†¬†(0.05)¬†¬†¬†(0.12)¬†¬†¬†\n\ntypeprof1.89 ***¬†¬†¬†¬†¬†¬†¬†0.36¬†¬†¬†¬†\n\n(0.13)¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†(0.25)¬†¬†¬†\n\ntypewc0.39 **¬†¬†¬†¬†¬†¬†¬†¬†-0.32 *¬†¬†\n\n(0.14)¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†(0.16)¬†¬†¬†\n\neducation¬†¬†¬†¬†¬†¬†¬†0.85 ***0.74 ***\n\n¬†¬†¬†¬†¬†¬†¬†(0.05)¬†¬†¬†(0.11)¬†¬†¬†\n\nN98¬†¬†¬†¬†¬†¬†¬†102¬†¬†¬†¬†¬†¬†¬†98¬†¬†¬†¬†¬†¬†¬†\n\nR20.70¬†¬†¬†¬†0.72¬†¬†¬†¬†0.80¬†¬†¬†¬†\n\nAll continuous variables are mean-centered and scaled by 1 standard deviation.  *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nWhat‚Äôs lovely about this kind of table is we can look across each row, and see how the coefficients for each variable change across our models. Remember - the reason we were doing a multivariate regression is to see how the bivariate relationships between the independent and dependent variables change when you account for redundant covariation.\n\n\nTypes of Changes Between the Multivariate and Bivariate Models\nThere are three different ways that the relationships can change from the bivariate to multivariate model - I‚Äôm simplifying these concepts a bit for the sake of this introductory class. Links to more information if you want to learn more about the precise definition and application of the terms.¬†\n\nIndependent Effects : The relationship between IV1 and the DV does not substantially change when IV2 is included in the model. This means that the relationship between IV1 and the DV is not explained by IV2. If your goal is to show that there is a significant relationship between IV1 and the DV, and that relationship does not go away when you include IV2 in your model, then this is what you are hoping to find.\nMediation Effects : The relationship between IV1 and the DV is weakened (which is called partial mediation) or goes away completely (which is called full mediation) when IV2 is included in the model. This means that the relationship between IV1 and the DV is dependent on the other variable. You can read more about this here.¬†\nSuppressor Effect : The relationship between IV1 and the DV is strengthened (or changes direction) when IV2 is included in the model. You can read more about this here.¬†\n\n\n\n\n\n\n\nACTIVITY : Look over the models. How do the slopes change from Model 1 to Model 3? From Model 2 to Model 3?\n\n\n\n\n\nThe difference (slope) between professionals and blue collar workers that we saw in Model 1 (√ü = 1.89) goes down and becomes non-significant (√ü = .36; this is called mediation). The the difference (slope) between white collar and blue collar workers in Model 1 (√ü = .39) changes in direction in Model 3 to become (√ü = -.32; this is called a suppressor effect).\nThe effect of education as seen in the bivariate model (Model 2 √ü = .85) remains about the same in Model 3 (√ü = .74; this is called an independent effect, since the effect of education is not influenced by the addition of job type in the model).\n\n\n\n\n\nReasons Why The Relationship Changes Between Models\nRemember, there are always two reasons why we‚Äôd see a change.\n\nchance : the change in the slope was just due to some kind of sampling error; the difference between the models is really just random chance.\nsome real effect. IV2 really does change the relationship between IV1 and the DV : that is, there is some real relationship between IV2, IV1, and the DV that changes the slopes in your model.\n\n\nThere are various ways to test for whether the change in slopes is large enough to be important / statistically significant. One method is is something called bootstrapping - I‚Äôll eventually put this in a supplemental chapter, but the basic idea is that you run a for-loop to resample the data, estimate the slope in a bivariate vs.¬†multivariate model (from a new dataset), and then save the difference in slopes to ‚Äúbucket‚Äù (or whatever you have named the array), and then repeat the process 1000 times. Another method to test for the difference is called the ‚ÄúSobel Test‚Äù; you can read about it here or here if you want. Or not!",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/10R_MultipleRegression.html#more-practice",
    "href": "chapters/10R_MultipleRegression.html#more-practice",
    "title": "Multiple Regression",
    "section": "More Practice",
    "text": "More Practice\nOkay, that was a lot! A few more resources to help and test your understanding.\n\nA MULTIPLE REGRESSION VIDEO :\nHey, do you like my disembodied voice explaining things on top of an R screenshot? Well good news, in this video I go through another example of multiple regression in R.\n\nHere‚Äôs the R script I used; the data come from the ‚Äúhormone‚Äù dataset, posted to bCourses.\n\n\n\n\nCheck-In : Here‚Äôs a Practice Quiz\nUse the check-in to practice and prepare for your quiz this week. See the answer key videos below, but try on your own first.\n\nProfessor Does the Check-In (Part 1)\n\n\n\nProfessor Does the Check-In (Part 2)\n\n\n\n\nCheck-Out\nhow‚Äôs it going and what should I focus on for our lecture next week.\nYEAH!",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/10R_MultipleRegression.html#footnotes",
    "href": "chapters/10R_MultipleRegression.html#footnotes",
    "title": "Multiple Regression",
    "section": "",
    "text": "since this is written. har har.‚Ü©Ô∏é\nwe‚Äôll talk about this point (an interaction effect) in the next set of lecture notes.‚Ü©Ô∏é\nTHE PREDICTED VALUE OF Y WHEN ALL X VALUES ARE ZERO‚Ü©Ô∏é\n43.3, 47, and 58.6.‚Ü©Ô∏é",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Multiple Regression</span>"
    ]
  },
  {
    "objectID": "chapters/11R_InteractionFX.html",
    "href": "chapters/11R_InteractionFX.html",
    "title": "Interaction Effects",
    "section": "",
    "text": "Hi! Stay tuned for reading materials. Thanks!",
    "crumbs": [
      "List of R Code",
      "Predicting Reality",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Interaction Effects</span>"
    ]
  },
  {
    "objectID": "index.html#who-is-this-book-for",
    "href": "index.html#who-is-this-book-for",
    "title": "Why Statistics?",
    "section": "Who Is This Book For?",
    "text": "Who Is This Book For?\nThis book - Why Statistics? - is being written to support students‚Äô learning of the statistics, R programming skills, and research methods that are required of modern psychological scientists. Whew!\nI‚Äôve learned over the years that students approach statistics with a variety of intense emotions - many of them negative. For what it‚Äôs worth, I have been happy to see most students thrive in the class, and will do my best to support y‚Äôall and make this class (and book) a positive learning experienceTM.\nTo that end, please fill out this form (or talk to me in class) if you are confused or overwhelmed; this class work as well as it does because of past and present generations of students like you, and I hope that it will continue to improve thanks to present and future generations of students. If you want to use this text in your own class, reach out and I can send my lesson plans and assignments if they might be helpful.",
    "crumbs": [
      "List of R Code",
      "Hello (An Introduction)!"
    ]
  },
  {
    "objectID": "index.html#whats-in-this-book",
    "href": "index.html#whats-in-this-book",
    "title": "Why Statistics?",
    "section": "What‚Äôs In This Book?",
    "text": "What‚Äôs In This Book?\nThis book is organized into three sections. You can view these sections (and the chapters inside) by looking at the Table of Contents to the left.\n\nDescribing People : This first section focuses on how psychologists, we‚Äôll discuss both how and why psychologists seek to learn what people (or non-human animals) are like (Chapter 1), the different types of data that psychologists collect on people (Chapter 2), the fancy terms that psychologists use to describe how people differ (Chapter 3), the methods they use to try and turn complex psychological states like happiness, statistics anxiety, or love into numbers (Chapter 4), and the ways that they try to give context to these numbers (Chapter 5). We will also learn about some of the research methods required to develop your own research ideas, and fit these ideas in the past research that has been done (or not done!) on the topic.\nPredicting People : This section focuses on the ways that psychologists try and use statistics to make predictions (educated guesses) about what people are like. We‚Äôll discuss how psychologists use the information they learn about people to make predictions about a person based on some other information (Chapter 6), how they make these predictions based on the categorical group the person belongs to (Chapter 7), how they try to make a guess about all people even though they are just studying a few (Chapter 8), and how they try to (Chapter 9). We will also learn about some of the research methods required to critically evaluate some of the important assumptions about research, to better understand how much faith to place in the results of a psychological study.\nPeople Are Complex : The final section goes deeper into some of the more advanced statistics and methods that psychologists use to understand people in their full complexity. Specifically, we will discuss how psychologists use multiple bits of information to update their predictions about people (Chapter 10), how our predictions can change depending on other features of the person or situation (Chapter 11), and how researchers adapt their statistics to account for different types of data (Chapter 12). Finally, we‚Äôll conclude with some rambling thoughts about the whole endeavor of statistics and research in psychology, and reflect on the friends we made along the way on this journey (Chapter 13).\n\nThere are three parts to every chapter; when you click on a chapter, you‚Äôll see another table of contents appear that organizes these parts.\n\nStatistics : You‚Äôll learn how and why psychologists analyze data (i.e., use math) to learn about people (or non-human animals).\nR Programming : You‚Äôll learn how to use the programming language R to work with these data. We will go over examples, and there will be some helpful videos to watch.\nResearch Methods : You‚Äôll learn more about the decisions psychologists make when collect, analyzing, interpreting, and reporting data on people, and how these decisions can impact our understanding.",
    "crumbs": [
      "List of R Code",
      "Hello (An Introduction)!"
    ]
  },
  {
    "objectID": "index.html#goals-of-the-book",
    "href": "index.html#goals-of-the-book",
    "title": "Why Statistics?",
    "section": "Goals of the Book",
    "text": "Goals of the Book\nI hope that by the end of this book, you‚Äôll feel confident in your ability to do the kinds of authentic tasks that a psychological researcher might do :\n\nAnalyze Data. I‚Äôll provide you a dataset and / or statistical output, and you‚Äôll use your knowledge of statistics, R, and research methods to answer questions about the dataset. What do we learn from the data? Why should we care?\nConduct an Independent Study. You will identify a research question that you care about, and then design a study, collect and analyze the data, and write up a report to share with us what you learned about the question you had (and what other questions remain).\n\nWe will talk much more about these assignments throughout the semester, and you will be well prepared for them if you follow along with the readings, quizzes, and homework assignments each week.",
    "crumbs": [
      "List of R Code",
      "Hello (An Introduction)!"
    ]
  },
  {
    "objectID": "index.html#how-will-i-use-this-book-for-our-class",
    "href": "index.html#how-will-i-use-this-book-for-our-class",
    "title": "Why Statistics?",
    "section": "How Will I Use This Book for Our Class?",
    "text": "How Will I Use This Book for Our Class?\nThis semester, we‚Äôll be taking a flipped classroom approach to our learning.\n\nBefore lecture you‚Äôll read and watch some videos to be introduced to the content that we will then cover more deeply in lecture. You‚Äôll also take a short quiz (no time limit, open-note, and you can take as many times as you‚Äôd like) that will encourage you to do the readings, and let me know what topics are still confusing to students.\nDuring lecture we will start with a review of concepts you learned from the pre-readings, go over any common questions that students still have, and then use the remaining time to practice and discussing the skills and concepts. We will work on the homework assignment together\nAfter lecture you‚Äôll complete any homework that we didn‚Äôt finish in class, and then read for the next week‚Äôs lecture.\n\nThe flipped classroom approach requires y‚Äôall to do the readings and watch the videos before class, and requires me to write text and record videos that are engaging and helpful for the students in the class.\nPlease take a look at the syllabus (on our course page) for more information about assignments, grading, and other course policies. However, the TLDR is that this course is designed for YOU to learn, so let me know if something is not working (but know that you will also need to do the work and can expect some level of struggle, since that‚Äôs an important part of the learning process).",
    "crumbs": [
      "List of R Code",
      "Hello (An Introduction)!"
    ]
  },
  {
    "objectID": "index.html#who-is-writing-these-words-that-i-am-reading",
    "href": "index.html#who-is-writing-these-words-that-i-am-reading",
    "title": "Why Statistics?",
    "section": "Who Is Writing These Words That I Am Reading?",
    "text": "Who Is Writing These Words That I Am Reading?\nMy name is Arman Daniel Catterson, and I‚Äôm very very very lucky to be a professor in the Bay Area at Diablo Valley College (tenured) and at UC Berkeley (continuing lecturer), who has been teaching some version of this class since Summer 2015. Feel free to say ‚Äúhi‚Äù if you see me on campus :) or hit that ‚ÄúSUBSCRIBE‚Äù button on YouTube. Thank you for reading.",
    "crumbs": [
      "List of R Code",
      "Hello (An Introduction)!"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#part-1-why-statistics-in-psychology",
    "href": "chapters/1R_WhyStats.html#part-1-why-statistics-in-psychology",
    "title": "Why Statistics?",
    "section": "",
    "text": "1¬†¬†One of the reasons I love teaching in the Bay Area is y‚Äôall are hella complex.\n\nStatistics as a Language\nStatistics is a language that scientists use to describe this complexity. While psychology uses this language to better understand differences in people (or non-human animals), other scientific disciplines focus on their own domains; physicists seek to understand differences (and similarities) in matter and energy, chemists seek to understand differences (and similarities) in elements and compounds, botanists seek to understand differences in plants, and economists seek to understand money.\n\nVariables and Variation\nVariation is at the heart of statistics, and is defined by differences, change, and complexity.\n\n\n\n\n\n\n\nBetween-Person Variation describes how individuals differ from each other. Think about ways that you differ from others; not everybody wears glasses, has the same level of silliness / seriousness / desire to cause mischief / fascination with horses.\n\n\n\nWithin-Person Variation describes how one individual changes over time or across different situations. Think about the person you are today - are you exactly the same as you were yesterday? A year ago? You‚Äôve changed (varied) in ways both small (hunger, exhaustion, number of words you‚Äôve read for this class) and large (personality, love interests, identity, etc.)\n\n\n\nNo variation would describe a situation in which everyone is exactly the same. I can‚Äôt think of too many situations where there is no variation; let me know on Discord if you can think of one? And while there‚Äôs no theoretical limit to the amount of variation that there can be, one major task of this class will be to learn to quantify the amount of variation that we observe in our role as psychologists.\n\nüåûüåûüåû\nüåûüåûüåû\n\n\n\n\nA Variable is a label for some psychological phenomenon that has variation. I‚Äôm not sure where I first heard this, but psychologists often focus on what they call the ‚ÄúABCs‚Äù.¬†\n\nA is for Affect = the emotions that you feel.\nB is for Behavior = the actions that you do.\nC is for cognition = the thoughts you have.\n\nThese are not rigid categories, and psychologists often debate the definitions of these terms. But they can be useful ways to think about how to think about people, and help break down a complex phenomenon into more specific components.\n\n\nPractice : Variables and Variation\nFor example, think about how affect, behavior, and cognition might be relevant if I ask you to think about an upcoming exam (your first exam is in just a few weeks!)\n\n\n\n\n\n\n\n\nhighlight the cells below to see my ideas / check your understanding\n\n\nAffect Example\nthe feeling of anxiety or dread you have thinking about being assessed, or maybe a feeling of excitement about the opportunity to demonstrate your hard work / effort / knowledge!\n\n\nBehavior Example\nimmediately checking your calendar to see when exams are; or maybe avoiding your classes with a nice procrastination session on the ol‚Äô infinite scroll machine.\n\n\nCognition Example\nthinking about all the work you have to do; wondering why the professor would choose this example when he could have thought about the ways that affect, behavior, and cognition would be triggered when you see a puppy or kitten or something like that‚Ä¶\n\n\n\nHere‚Äôs a cat video I like for students needing a distraction from thinking about exams. I promise your exams in this class will be chill and I‚Äôll do my best to prepare y‚Äôall.\n\n\nLanguage is More than Vocabulary\nStatistics is a language that scientists use to describe this complexity. While psychology uses this language to better understand variation in people (or non-human animals), other scientific disciplines focus on their own domains; physicists seek to understand differences (and similarities) in matter and energy, chemists seek to understand differences (and similarities) in elements and compounds, botanists seek to understand differences in plants, and economists seek to understand money.\n\nVocabulary. Equations like ‚Äúthe mean‚Äù or ‚Äústandard deviation‚Äù or ‚Äúcronbach‚Äôs alpha‚Äù or ‚Äúp-value‚Äù are precise vocabulary terms that define some feature of variation. Some of these vocabulary words are easier to understand and remember than others, and like all languages, sometimes people disagree on the definition, and sometimes misuse these words.\nGrammar and Syntax. The way we organize words also matters when learning languages. Saying ‚Äúthe professor graded the students‚Äú has a very different meaning than ‚Äúthe students graded the professor‚Äù, even though these share the exact same words. Statistics (and research methods) also requires precision in the way we organize the ideas, terms, and processes. We‚Äôll learn more about this as we discuss the scientific method (a highly structured and organized approach to doing research), but also as we learn how to navigate doing data analysis.\nCultural Immersion. A good language class will also help students to understand the ways that the language is connected to people, places, and history2. In this class, we‚Äôll think about the ways we can immerse ourselves in the culture of statistics and research methods, from the cultural practices that inform which methods or tools to use, to the ways that the culture of statistics and research might needlessly create barriers for certain types of people or studies.\nPractice and Past Experiences. And yes, in order to gain fluency in a language, you need to practice! Attendance and regular engagement with this class will ensure that you are able to get the practice that you need. It‚Äôs also good to note that people differ in terms of their past experiences with computers and math, and are bringing those experiences (for better or worse) with them into this class.\n\n2¬†And usually food, though I‚Äôm not sure if there‚Äôs cultural food norms about statistics or research methods.\n\nCulture in Statistics : Me-Search\n\n\nHiya folks! Everyone‚Äôs favorite Open-Source Mickey Mouse here. I‚Äôll be popping up in the book from time to time to critically engage with the idea that statistics has a culture that is socially constructed by people like you!\n\nAll psychologists are interested in questions sparked by their own observations or experiences. This is sometimes called ‚Äúme-search‚Äù - the idea that a person‚Äôs research interests reflect their own experience.\nMe-search can be an important way for researchers to use their statistics and research methods training to address questions and issues that are relevant to their lives and communities.\nBelow are a few examples of research questions that are related to a person‚Äôs real-life experiences.\n\n\n\nReal Life Experience\nResearch Question\n\n\nA researcher develops vision problems due to his studies of light, and had to live in a completely darkened room, where he became completely isolated from most of reality.3\nDoes reality exist, or can it only be known through our perceptions?\n\n\nA black graduate student at the University of Chicago realizes that white people cross the street to avoid him, and finds himself whistling classical music to signal that he does not fit their negative stereotypes of a black male.4\nHow do people respond and react to others‚Äô negative stereotypes?\n\n\n\n3¬†This happened to Gustav Fechner, one of the early psychologists who pioneered the study of psychophysics, which tested theories that our perceptions do not always match reality (seen in many examples, such as the dress). FWIW I see it as blue and black.4¬†This anecdote (as reported here) inspired Claude Steele‚Äôs research on stereotype threat.Me-search also serves as a form of potential bias in research - not only will a researcher‚Äôs own biases and beliefs influence the way they conduct research, but the types of questions that are asked will be influenced by the types of people doing research.\nFor example, a survey of over 26,000 research articles in psychology documented just how rarely the topic of race is studied in psychology.\n\n\n\n\n\nAs we‚Äôll discuss throughout this class, life is complex and there is never one explanation for any phenomenon. However, it‚Äôs important to note that psychology as a field has historically been dominated by white authors (researchers who write scientific papers) and white editors (researchers who decide what papers get published or not).\n\n\n\n\n\nThese trends are important to reflect on, because they reveal a bias in who becomes a psychologist, and what types of questions these researchers are interested in pursuing.\nIt‚Äôs also a goal of this class to not only highlight the important contributions of non-white researchers and statisticians, but also make sure that all students in this diverse classroom feels empowered to use statistics, research methods, and R skills to ask (and answer) research questions that matter to them!5\n5¬†This is the purpose of your final project! We‚Äôll talk more about this throughout the class.\n\n\nPsychology as a REAL SCIENCE ‚Ñ¢\nPsychology uses statistics because, in part, it wants to establish itself as a real science, like physics and chemistry. You don‚Äôt have to take my word for it, just look at the definitions of some common sources of psychological knowledge - introductory textbooks:\n\n‚ÄúToday, we define psychology as the science of behavior and mental processes.‚Äù (Myers, 2011)\n‚Äú‚Ä¶the science of behavior and the mind.‚Äù (Grey, 2010)\n‚Äú‚Ä¶the scientific study of mind, brain, and behavior.‚Äù (Gazzaniga, 2010)\n‚Äú‚Ä¶We now define psychology as the science of behavior and mental processes.‚Äù (Myers & DeWall, 2018)\n\nI‚Äôm probably showing my age looking to textbooks, so let‚Äôs check in with ChatGPT6 to see whether the algorithmic summary of large piles of data suggests that psychology is, in fact, a ‚Äúreal science‚Äù :¬†\n6¬†See the syllabus for the course ChatGPT policy. You may also be interested to read on the ethical and environmental issues surrounding this emerging technology.\nPerhaps more authoritatively, the American Psychological Association (APA) confirms that psychology is, ‚Äúthe study of the mind and behavior‚Ä¶a diverse scientific discipline comprising several major branches of research.‚Äù (APA, 2024).\nThe consistent emphasis on science (and ‚Äúrigorous‚Äù methods!) in these definitions is an attempt to elevate psychology through language to the status of other ‚Äúhard‚Äù sciences, like physics and chemistry. But inclusion of the term ‚Äúscience‚Äù also seeks to differentiate psychology from its less scientific heritage and past, defend itself from accusations from other scientists / talking heads (if not some of your friends in STEM majors‚Ä¶or parents) that it is not actually REAL SCIENCE ‚Ñ¢.¬†\n\nWhat is Science? Prediction (and Error)\nOne of the most important goals of science is to form predictions, and then use these predictions in order to influence outcomes (a form of power).\nA prediction is an educated guess you have about the future. Educated means that the guess comes from some knowledge (either your experiences, beliefs, something you learned in a textbook, or the results of a scientific study). A prediction can have two outcomes :\n\nValid : your prediction is right\nError : your prediction is wrong.\n\nOf course, things are rarely as simple as ‚Äúright‚Äù or ‚Äúwrong‚Äù, and a large part of this class will be learning how to quantify exactly how much error there is in our scientific predictions.\nAs an example, let‚Äôs look to the stars.\n\n\n\n\nAstronomers have developed knowledge about celestial bodies - gravity, orbits, mass (I know very little about this).\nBut I trust this science because astronomers are able to use it to make very valid predictions about giant space rocks and when they will come close to the earth.7\nI can use this knowledge to plan a stargazing trip, or plan to watch all the rich people leave earth when the ‚Äúbig one‚Äù comes for the rest of us.\n\n\n\n7¬†You can see when scientists predict Halley‚Äôs comet to come closest to earth here. While this is fairly accurate, I‚Äôve seen the exact prediction change over the years - there is still some error in this prediction.As another example, on the day I‚Äôm writing these words, I do not predict that it will rain outside. I am making this prediction based on the following information :\n\nit did not rain yesterday\nit is not currently raining\nI live in Oakland, where it rarely rains in August.\nthe air doesn‚Äôt have that feeling of rain; that smell.\nI looked at the weather forecast app and it said we had a week of sunny weather ahead.\nNobody was carrying an umbrella today.\nthere are no clouds.\n\nBecause I predict it will not rain, I‚Äôm not too worried that the tarp is not covering my bike locked outside. Of course, my prediction could be wrong.\n\n\n It sometimes rains when sunny, as on Puffin Rock, where we‚Äôll be here come rain or shine.\nFor our first lecture, start thinking of some predictions that you have made. What knowledge informed the prediction? Did you use this prediction to influence your future behavior in some way? What kinds of predictions do psychologists make? We will chat more about these ideas in class :) but it‚Äôs a core focus on why psychologists use predictions.\nAnd so, here we are. In this document, in this required class for the psychology major, learning how to DO REAL SCIENCE. With statistics.\n\n\nLinear Models to Organize Our Predictions\nThe linear model a simple formula that helps researchers to make, and quantify, their predictions. We will talk much more about linear models in our class - they are one of the most important concepts we will cover and a foundation of modern statistics - but for now let‚Äôs just focus on the basics :\nA linear model takes the following form: 8\n8¬†I can already feel some of y‚Äôalls math anxiety rising across time and space. But remember, stats is just a language with some vocabulary we need to learn.\\[\nDV \\sim IV_1 + IV_2 + ... + IV_k + \\epsilon\n\\]\nBelow is a description of terms in the model :\n\nDV = dependent variable. This is the variable that you want to predict. It‚Äôs up to the researcher what variable is the dependent variable. More complicated models can have more than one DV, but for this class we will just focus on one DV at a time.\nIV = independent variable. This is a different variable that you think will help you make predictions. Again, it‚Äôs up to the researcher to choose what variables they will include to try and make predictions of the DV.\nk = any number. This is a way of saying that there can be many IVs. Life is complex, and so in order to predict one variable, we will need to use information from lots of other variables.\n~ = a squiggly line / tilde. I like to use the squiggly line to reinforce the idea that our model is uncertain and squiggly (this is not an exact prediction where an equal sign would be used). R also uses the tilde for defining a model, so it‚Äôs nice to start practicing stretching our pinkie finger to reach that upper left corner of the keyboard.\n\\(\\epsilon\\) = error = this term always concludes our written model, and accounts for the many other reasons why our predictions might be wrong. This could be because we haven‚Äôt included certain variables that are important to make predictions (either because we can‚Äôt measure them in our study, don‚Äôt think they are important enough to study, or don‚Äôt know that we should study them), or because we are measuring our variables with some amount of error9.\n\n9¬†We will learn more about measurement error in Chapter 4.For example, I could write out my prediction about rain as the following linear model :\n\nrain ~ clouds + umbrellas + weather app status + smell + air pressure + season + location + temperature + error\n\nWe read a model as : ‚Äúthe DV is a function of‚Ä¶‚Äù or sometimes ‚Äúthe DV depends on‚Ä¶‚Äù. So I‚Äôd read this model as ‚Äúrain is a function of clouds, umbrellas, the weather app status‚Ä¶etc.‚Äù And it‚Äôs good practice to leave the variables neutral (e.g., just ‚Äúclouds‚Äù, not ‚Äústorm clouds‚Äù).10\n10¬†Later we will talk about ways to account for the fact that more umbrellas increases the chance it will rain in our model.Error in this model would represent the fact that I haven‚Äôt accounted for some important variables that we know we should include (like humidity, coastal pressure systems, or palnetary waves), the fact that some of my variables were probably measured with error (was no one really carrying an umbrella???), and the fact that there are some things that we don‚Äôt know about rain, and what predicts it (this is what weather scientists are trying to learn more about.)\nOnce we add numbers and data to a linear model11, we can quickly see :\n11¬†We will get to this in Chapter 6!\nwhich variables allow us to make the best predictions, and which variables do not improve our predictions (e.g., is the number of umbrellas others are carrying a good predictor of whether it‚Äôs going to rain or not?)\nthe direction of the relationship between each IV and the DV (e.g., is it that more umbrellas = more rain, or more umbrellas = less rain?)\nthe amount of error in our predictions (e.g., how good, exactly, is this model at predicting the rain?)\n\n\nPractice Writing A Model\nImagine a researcher wants to better understand why people differ in happiness, and believes that playing music, drinking more water, and eating ice cream sandwiches are important factors to consider. How would you write this out as a linear model?\n\n\n\n\n\n\nClick Here to See The Answer\n\n\n\n\n\nhappiness ~ music playing + water intake + ice cream consumption + error\nFor this model, note that I‚Äôve organized the focus of the researcher‚Äôs question on the left-hand side of the equation; listed the three other variables to the right (and tried to be neutral about how I describe them (e.g., not ‚Äúdrinking more water‚Äù); included error at the end of my model to account for the fact that some people who play music, drink water, and eat ice cream are, in fact, not happy. I also didn‚Äôt add other varibles that might be related to happiness, since these were not part of the researcher‚Äôs statement.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#part-2-why-r",
    "href": "chapters/1R_WhyStats.html#part-2-why-r",
    "title": "Why Statistics?",
    "section": "Part 2 : Why R?",
    "text": "Part 2 : Why R?\nThis semester, we will also learn how to use the computer programming language R to work with data, conduct analyses, and make graphs. R can be intimidating to work with at first, and is more confusing than it needs to be sometimes (as you‚Äôll quickly find out‚Ä¶), but I promise you will learn!12 It‚Äôs totally okay (and expected) for you to feel frustrated at times; this is part of the learning process. So please embrace the ‚ÄúI HAVE NO IDEA WHAT I‚ÄôM DOING‚Äù dog meme energy (and look how happy the doggy looks!) as you embark on your R journey.\n\n12¬†In fact, that‚Äôs the point of this class.\n\n\n\n\n\n\n\n\nInstalling R\nUse this link to Download and Install the Programs R and RStudio Desktop\nNote : You must download both R and RStudio Desktop (these are two separate programs). Make sure to download the most recent version of R and RStudio to avoid issues in the future.\n\nR is the powerful, free, and somewhat intimidating computer program that we will use to analyze data in this class. This website is not super friendly - choose the operating system you have (Windows, MacOS, or Linux) and then download the ‚Äúlatest release‚Äù on the next page. If you have a chromebook or iPad / tablet, you will need to use posit.cloud.\nRStudio is an Integrated Development Environment (IDE) - basically a ‚Äúhome‚Äù for R to live in, with rooms and this program is not 100% necessary, but makes it a little easier to navigate R. Note that you will need to install R first in order for RStudio to work.\n\nHaving trouble getting these programs to work?\n\nHere‚Äôs one YouTube video someone made to show you how to download and install.\nTry posit.cloud. This is a web-based version of RStudio, and has a free option but limits your hours of work each month. There‚Äôs a paid option for $5/month that you can use if you sign up with your student e-mail address; former students also pointed out that you can always create a new ‚Äúfree‚Äù account if you run over the 15-hour limit.\nAsk for help! The professor, other students, or a tutor / your TA can help get everything working properly.\n\n\n\nNavigating R\nWatch the two videos below for a quick introduction to R - the program we will be using to analyze data.\n\nVIDEO : Navigating R\n\n\nwhat R looks like when you open it\nbasic math in the¬†console\nindexing and output\n\n\n\nVIDEO : Navigating RStudio\n\n\nwhat RStudio/Posit looks like; navigating the program\nbasic math in the console\nthe¬†source file¬†(makes life easier and saves your work!)",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#part-3-why-science",
    "href": "chapters/1R_WhyStats.html#part-3-why-science",
    "title": "Chapter 1 | Why?",
    "section": "Part 3 : Why Science?",
    "text": "Part 3 : Why Science?",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Chapter 1 \\| Why?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#the-scientific-method-in-5-easy-steps",
    "href": "chapters/1R_WhyStats.html#the-scientific-method-in-5-easy-steps",
    "title": "Chapter 1 | Why?",
    "section": "The Scientific Method in 5 Easy Steps",
    "text": "The Scientific Method in 5 Easy Steps\nSo, you‚Äôve defined a research question you are interested in? Yeah! The Scientific Method is used to help science progress toward valid (accurate, ‚Äútrue‚Äù) predictions and avoid biases. This is the same scientific method you may have learned about in a previous science class or used for a science fair project8. There are five parts, described below.\n8¬†¬†¬†Do elementary school students still do those science fair projects with the tri-fold posters? Adult scientists do the same kinds of science fairs, except they are called ‚Äúconferences‚Äù, involve a little more math, and use flat posters. I also don‚Äôt think anyone gets ribbons (status among scientists takes other less concrete forms). Some of the largest conferences include that held by the American Psychological Association or the Association of Psychological Science. The Western Psychological Association has a more local conference, and there are literally hundreds of other conferences based on research topic (for example, the Society of Personality and Social Psychology). If you are interested in learning more about conferences, ask your GSI what conferences they attend. And you even might be able to present your project in this class as a conference poster - no tri-fold needed.\nStep 1 : Identify a Question\nFirst, a researcher starts with a question about the variable that they want to predict or the psychological phenomenon they are interested in. In Part 1 of this chapter, we talked about how these questions are often informed by the researcher‚Äôs own observations or experiences.¬†\nStill looking for a project topic? A few ideas to consider :\n\nThink about why you become a psychology major. Was it because you were interested in people, find dreams fascinating, wonder if you could get good at detecting people‚Äôs lies? Think about these interests, then think about what variables might be relevant. For example, while you won‚Äôt have access to an fMRI machine (or the required statistics) in order to reconstruct images people see during their dreams, you might study people‚Äôs beliefs about the importance of their dreams, or the extent to which they have dreams.\nFocus on a problem you‚Äôve encountered or observed in real-life. Notice that something in the world could be better? How would you label that as a variable? For example, maybe you want to better understand people‚Äôs attitudes about capitalism or racism or housing costs.\nLook at faculty webpages, and see what they (and / or their graduate students) are studying. Does anything seem interesting to you? Who looks like they might be cool to work with? What aspects of their research question might you study with this project?\nChase the latest trends of today. What‚Äôs capitalism care about these days? AI?\n\nBut you don‚Äôt have to take my word for it. Here‚Äôs another guide that might offer some help, or ask for help in the class discord / office hours / lecture!\nStep 2 : Develop a Theory\nA scientific theory is one that is comprehensive, explanatory, and supported by evidence. For example, the theory of evolution is comprehensive (it relates to all nature, not just plants or animals or finches), it is explanatory (it‚Äôs why we and cats both narrow our eyes when we are scared and angry), and it is supported (by over 100 years of evidence9).¬†\n9¬†From fossil records to observations of fruit flies and plansMost scientists refrain from saying that a theory is ‚Äúproven‚Äù or ‚Äútrue‚Äù for two reasons:\n\nFirst, the scientific method is a process - our knowledge and ideas are continually updated. So it‚Äôs likely that the theory of evolution will be updated as we learn more about the complex ways genes replicate and interact with the environment. Saying that a theory is ‚Äúproven‚Äù is a common mistake - watch out for it!¬†\nSecond, most scientists (and psychologists) draw from Karl Popper‚Äôs philosophy of science, which adheres to a requirement for science called falsifiability - the ability to find evidence that rejects a theory (‚Äúability to falsify‚Äù). This means a theory is never ‚Äòproven‚Äô because scientists are continually looking for evidence to reject the theory. It also means that a belief that cannot be tested or rejected would be rejected as a scientific belief - you have to be able to test your belief in some observable way. Falsifiability is where I think science separates from religious belief - someone with faith doesn‚Äôt need evidence, and that‚Äôs okay! It just doesn‚Äôt make the belief scientific under science‚Äôs narrow definition.¬†\n\nHypotheses are specific predictions that researchers make about what they expect to see in the data if their theory is supported or is not supported by data.¬†\n\nThe alternative hypothesis (sometimes written HA) is the researcher‚Äôs own belief. It may seem strange to label your belief ‚Äúalternative‚Äù when this word is used for things that are supposed to be different (‚Äúalternative rock = it‚Äôs not your parent‚Äôs rock & roll!‚Äù), and we are so used to thinking that our beliefs are the default that to call them alternative seems wrong. This is an example of previous beliefs bias, and the decision to label our beliefs as the ‚Äúalternative‚Äù is an example of science trying to correct this bias. It‚Äôs a small and symbolic correction, but it‚Äôs better than nothing.\nThe null hypothesis (sometimes written H0) is the label given for whatever evidence would not support the researcher‚Äôs belief.\n\nEXAMPLE : Let‚Äôs say you believe that smoking cannabis hurts a person‚Äôs memory. What‚Äôs the alternative hypothesis? What‚Äôs the null?\n\nNull Hypothesis : People who smoke cannabis will perform BETTER or NO DIFFERENT on a memory test than people who do not smoke marijauna.\nAlternative Hypothesis : People who smoke cannabis will perform WORSE on a memory test than people who do not smoke marijauna.\nMany students forget to include the ‚ÄúNO DIFFERENT‚Äù in the null hypothesis example above. However remember that the null hypothesis is everything that your theory is not. So if your theory is that smoking cannabis HURTS memory, then finding no difference in the memory of pot smokers vs.¬†non-smokers would not support your theory, and is thus part of the null hypothesis. (Note : some of y‚Äôall may have missed this because you are remembering learning about ‚Äúdirectional‚Äù vs ‚Äúnon-directional‚Äù hypotheses - we will discuss this more in Lecture 8.)\n\nPractice : Identifying Models, Null, and Alternative Hypotheses. Let‚Äôs review with a quick check-in to practice identifying models based on research questions and theories, and identifying the null and alternative hypotheses based on a given theory.\n\n\nStep 3 : Collect Data\nAs described above, scientific theories are supported by evidence called data. How researchers collect data is something we will discuss in more detail over the next few weeks. In general, researchers have to figure out how to measure the variables they are interested in studying (e.g., ‚Äúhow will I know if someone is happy or not?‚Äù), and then find participants (people or animals) to study (e.g., ‚Äúwhose happiness should I study‚Äù).¬†\nFor example, in our smoking cannabis example the decisions about how to measure memory (a music memory game or a word recognition task?) or how much cannabis (a little or a lot?) or who to study (Berkeley students or your grandparents?) in the study would likely influence the results.\nThe decisions that researchers make about how to define their measures and the participants they will study are very important, and will influence the results of the study (and thus our knowledge of the topic), so stay tuned for more discussion!\n\n\nStep 4 : Use Data to Test Theories\nFinally, researchers look to see if the data they collected supports or rejects their theory (and evaluate how strongly their theory is supported or rejected). We‚Äôll talk much more about using data to test theories this semester.\nIn our smoking cannabis example, the researcher would look to see which group did better on the memory test, and if the smokers did worse, then their theory would be supported (by this one study, at least).\n\n\nStep 5 : Repeat\nOnce a study is completed, researchers repeat the scientific method in two different ways.\nResearchers will sometimes repeat the exact same steps a second time - something called replication. Replication is critical to science.\nScientists also repeat the scientific method with a new question that is based on the results from their first study. Science is a process, and researchers are never done learning about how to better predict & control the world. There‚Äôs always more research to do. For example, after identifying a pattern between smoking cannabis and memory, a researcher might ask whether the type or dosage of cannabis intake would influence memory, whether abstinence could reverse the effects of memory impairment, or whether cannabis and coffee together might lead to a different result. Note that this is not an example of replication, since researchers are not testing the same question they had - but it‚Äôs repeating the scientific method for a new question inspired by the old. This is good, and part of scientific progress. But the problem is that the incentives for scientific publication focused almost entirely on ‚Äúnew‚Äù research, and not really making sure that the ‚Äúold‚Äù research was valid.\n\n\nIt‚Äôs Never Actually Easy\nScience is hard, and people are very complex, which makes psychological science very hard. Unfortunately, psychology is in a bit of a Replication Crisis. This crisis is two-fold a) researchers tend not to seek to replicate their (or others‚Äô) results, and b) systematic attempts to do so have suggested that the majority of results in psychology do not replicate10.\n10¬†You can go deeper into some of the drama surrounding the replication project here. lemme know what you think on the discord thread for this week.",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Chapter 1 \\| Why?</span>"
    ]
  },
  {
    "objectID": "chapters/1R_WhyStats.html#part-3-how-science-the-scientific-method-in-five-easy-steps",
    "href": "chapters/1R_WhyStats.html#part-3-how-science-the-scientific-method-in-five-easy-steps",
    "title": "Why Statistics?",
    "section": "Part 3 : How Science? The Scientific Method in Five Easy Steps",
    "text": "Part 3 : How Science? The Scientific Method in Five Easy Steps\nThe Scientific Method is used to help science progress toward valid (accurate, ‚Äútrue‚Äù) predictions and avoid biases. This is the same scientific method you may have learned about in a previous science class or used for a science fair project13.\n13¬†¬†¬†Do elementary school students still do those science fair projects with the tri-fold posters? Adult scientists do the same kinds of science fairs, except they are called ‚Äúconferences‚Äù, involve a little more math, and use flat posters. I also don‚Äôt think anyone gets ribbons (status among scientists takes other less concrete forms). Some of the largest conferences include that held by the American Psychological Association or the Association of Psychological Science. The Western Psychological Association has a more local conference, and there are literally hundreds of other conferences based on research topic (for example, the Society of Personality and Social Psychology). If you are interested in learning more about conferences, ask your GSI what conferences they attend. And you even might be able to present your project in this class as a conference poster - no tri-fold needed.I like to organize the scientific method into five broad parts, described below.\n\nStep 1 : Identify a Question\nFirst, a researcher starts with a question about the variable that they want to predict or the psychological phenomenon they are interested in. In Part 1 of this chapter, we talked about how these questions are often informed by the researcher‚Äôs own observations or experiences.\nLooking for a project topic? A few ideas to consider :\n\nThink about why you become a psychology major. Was it because you were interested in people, find dreams fascinating, wonder if you could get good at detecting people‚Äôs lies? Think about these interests, then think about what variables might be relevant. For example, while you won‚Äôt have access to an fMRI machine (or the required statistics) in order to reconstruct images people see during their dreams, you might study people‚Äôs beliefs about the importance of their dreams, or the extent to which they have dreams.\nFocus on a problem you‚Äôve encountered or observed in real-life. Notice that something in the world could be better? How would you label that as a variable? For example, maybe you want to better understand people‚Äôs attitudes about capitalism or racism or housing costs.\nLook at faculty webpages, and see what they (and / or their graduate students) are studying. Does anything seem interesting to you? Who looks like they might be cool to work with? What aspects of their research question might you study with this project?\nChase the latest trends of today. What‚Äôs capitalism care about these days? AI?\n\nBut you don‚Äôt have to take my word for it. Here‚Äôs another guide that might offer some help, or ask for help in the class discord / office hours / lecture!\n\n\nStep 2 : Develop a Theory\nA scientific theory is one that is comprehensive, explanatory, and supported by evidence. For example, the theory of evolution is comprehensive (it relates to all nature, not just plants or animals or finches), it is explanatory (it‚Äôs why we and cats both narrow our eyes when we are scared and angry), and it is supported (by over 100 years of evidence14).¬†\n14¬†From fossil records to observations of fruit flies and plansMost scientists refrain from saying that a theory is ‚Äúproven‚Äù or ‚Äútrue‚Äù for two reasons:\n\nFirst, the scientific method is a process - our knowledge and ideas are continually updated. So it‚Äôs likely that the theory of evolution will be updated as we learn more about the complex ways genes replicate and interact with the environment. Saying that a theory is ‚Äúproven‚Äù is a common mistake - watch out for it!¬†\nSecond, most scientists (and psychologists) draw from Karl Popper‚Äôs philosophy of science, which adheres to a requirement for science called falsifiability - the ability to find evidence that rejects a theory (‚Äúability to falsify‚Äù). This means a theory is never ‚Äòproven‚Äô because scientists are continually looking for evidence to reject the theory. It also means that a belief that cannot be tested or rejected would be rejected as a scientific belief - you have to be able to test your belief in some observable way. Falsifiability is where I think science separates from religious belief - someone with faith doesn‚Äôt need evidence, and that‚Äôs okay! It just doesn‚Äôt make the belief scientific under science‚Äôs narrow definition.¬†\n\nHypotheses are specific predictions that researchers make about what they expect to see in the data if their theory is supported or is not supported by data.¬†\n\nThe alternative hypothesis (sometimes written HA) is the researcher‚Äôs own belief. It may seem strange to label your belief ‚Äúalternative‚Äù when this word is used for things that are supposed to be different (‚Äúalternative rock = it‚Äôs not your parent‚Äôs rock & roll!‚Äù), and we are so used to thinking that our beliefs are the default that to call them alternative seems wrong. This is an example of previous beliefs bias, and the decision to label our beliefs as the ‚Äúalternative‚Äù is an example of science trying to correct this bias. It‚Äôs a small and symbolic correction, but it‚Äôs better than nothing.\nThe null hypothesis (sometimes written H0) is the label given for whatever evidence would not support the researcher‚Äôs belief.\n\nEXAMPLE : Let‚Äôs say you believe that smoking cannabis hurts a person‚Äôs memory. What‚Äôs the alternative hypothesis? What‚Äôs the null?\n\nNull Hypothesis : People who smoke cannabis will perform BETTER or NO DIFFERENT on a memory test than people who do not smoke marijauna. 15\nAlternative Hypothesis : People who smoke cannabis will perform WORSE on a memory test than people who do not smoke marijauna.\n\n15¬†Many students forget to include the ‚ÄúNO DIFFERENT‚Äù in the null hypothesis example above. However remember that the null hypothesis is everything that your theory is not. So if your theory is that smoking cannabis HURTS memory, then finding no difference in the memory of pot smokers vs.¬†non-smokers would not support your theory, and is thus part of the null hypothesis. (Note : some of y‚Äôall may have missed this because you are remembering learning about ‚Äúdirectional‚Äù vs ‚Äúnon-directional‚Äù hypotheses - we will discuss this more in Lecture 8.)Practice : Identifying Models, Null, and Alternative Hypotheses. Here‚Äôs a quick practice quiz to review identifying models based on research questions and theories, and identifying the null and alternative hypotheses based on a given theory.\n\n\nStep 3 : Collect Data\nAs described above, scientific theories are supported by evidence called data. How researchers collect data is something we will discuss in more detail over the next few weeks. In general, researchers have to figure out how to measure the variables they are interested in studying (e.g., ‚Äúhow will I know if someone is happy or not?‚Äù), and then find participants (people or animals) to study (e.g., ‚Äúwhose happiness should I study‚Äù).¬†\nFor example, in our smoking cannabis example the decisions about how to measure memory (a music memory game or a word recognition task?) or how much cannabis (a little or a lot?) or who to study (Berkeley students or your grandparents?) in the study would likely influence the results.\nThe decisions that researchers make about how to define their measures and the participants they will study are very important, and will influence the results of the study (and thus our knowledge of the topic), so stay tuned for more discussion!\n\n\nStep 4 : Use Data to Test Theories\nFinally, researchers look to see if the data they collected supports or rejects their theory (and evaluate how strongly their theory is supported or rejected). We‚Äôll talk much more about using data to test theories this semester.\nIn our smoking cannabis example, the researcher would look to see which group did better on the memory test, and if the smokers did worse, then their theory would be supported (by this one study, at least).\n\n\nStep 5 : Repeat\nOnce a study is completed, researchers repeat the scientific method in two different ways.\nResearchers will sometimes repeat the exact same steps a second time - something called replication. Replication is critical to science.\nScientists also repeat the scientific method with a new question that is based on the results from their first study. Science is a process, and researchers are never done learning about how to better predict & control the world. There‚Äôs always more research to do. For example, after identifying a pattern between smoking cannabis and memory, a researcher might ask whether the type or dosage of cannabis intake would influence memory, whether abstinence could reverse the effects of memory impairment, or whether cannabis and coffee together might lead to a different result. Note that this is not an example of replication, since researchers are not testing the same question they had - but it‚Äôs repeating the scientific method for a new question inspired by the old. This is good, and part of scientific progress. But the problem is that the incentives for scientific publication focused almost entirely on ‚Äúnew‚Äù research, and not really making sure that the ‚Äúold‚Äù research was valid.\n\n\nIt‚Äôs Never Actually Easy\nScience is hard, and people are very complex, which makes psychological science very hard. Unfortunately, psychology is in a bit of a Replication Crisis. This crisis is two-fold a) researchers tend not to seek to replicate their (or others‚Äô) results, and b) systematic attempts to do so have suggested that the majority of results in psychology do not replicate16.\n16¬†You can go deeper into some of the drama surrounding the replication project here. lemme know what you think on the discord thread for this week.We will chat more about this in our next lecture. But I think that‚Äôs enough reading for now?",
    "crumbs": [
      "List of R Code",
      "Describing People",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Why Statistics?</span>"
    ]
  }
]