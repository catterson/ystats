abline(lm(self.skills ~ learn.r, data = d), lwd = 5)
mod1 <- lm(self.skills ~ learn.r, data = d)
plot(jitter(self.skills) ~ learn.r, # dv is jittered
data = d,
main = "Jittered Data",
xlim = c(1,5), ylim = c(1,5))
abline(mod1, lwd = 5, col = 'red')
coef(mod1)
# intercept = 1.46 = the predicted value of Y when ALL X values are ZERO.
# slope = .46 = relationship between learn.r and our DV (self.skills)
### as learn.r increase by ONE, then self.skills will increase by .46
### these units are in the original unit of measurement (1-5 likert scale.)
mod1$residuals # R does the residual calculation for us. what will happen if we add this up?
sum(mod1$residuals) # they add to....
SSE <- sum(mod1$residuals^2) # so I square them
SSE # the total squared error when I use my model to make predictions.
## Visualizing Our Errors. (distance between actual scores and the line).
par(mfrow = c(1,2))
plot(d$self.skills,
ylab = "Self-Perception of Skills",
xlab = "Index", main = "Mean as Model \n(SST = Total Sum of Squared Errors)")
abline(h = mean(d$self.skills, na.rm = T), lwd = 5)
plot(jitter(self.skills) ~ learn.r, data = d, main = "Linear Model \n(SSE = Sum of Squared Errors When Model Making Predictions)",
xlim = c(1,5)) # jittered
abline(mod1, lwd = 5, col = 'red')
SST <- sum((d$self.skills - mean(d$self.skills))^2) # defining the total error
SST - SSE # a difference in errors when using the mean vs. our model
(SST - SSE)/SST # the relative difference in errors = R^2 (R-squared.)
summary(mod1)$r.squared # R does this for us. But good to do "by hand" to understand.
names(d) # what other (numeric, for now) variable might predict self.skills?
fakey <- rnorm(10000000, mean = 100, sd = 30)
truthbucket <- array()
for(i in c(1:1000)){
lilfakey <- fakey[sample(1:length(fakey), 10)] # ten random individuals from fakey.
truthbucket[i] <- mean(lilfakey)
}
length(truthbucket)
hist(truthbucket)
mean(truthbucket)
fakey <- rnorm(10000000, mean = 100, sd = 30)
hist(fakey)
abline(v = mean(fakey), lwd = 5)
mean(fakey)
truthbucket <- array()
for(i in c(1:1000)){
lilfakey <- fakey[sample(1:length(fakey), 10)] # ten random individuals from fakey.
truthbucket[i] <- mean(lilfakey)
}
length(truthbucket)
hist(truthbucket)
abline(v = mean(truthbucket), lwd = 5, col = 'red')
mean(truthbucket)
sd(truthbucket)
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/Personality and Random Numbers/personality_random_number_data.csv", stringsAsFactors = T)
names(d)
head(d)
## R1	What is a number between 1 and 100?
d$R1
hist(d$R1)
## Look at the variable E1
hist(d$E1)
d$E1
mean(d$E1)
sd(d$E1)
summary(d$E1)
abline(v = mean(d$E1, lwd = 5))
abline(v = mean(d$E1), lwd = 5)
abline(v = mean(d$E1) + sd(d$E1), lwd = 5, lty = "dashed")
abline(v = mean(d$E1) - sd(d$E1), lwd = 5, lty = "dashed")
d == 0
d[d == 0]
d[d == 0] <- NA # replaces with zero
summary(d)
d[d == 0] # finds these zeros in the dataset.
hist(d$E1)
mean(d$E1)
mean(d$E1, na.rm = T)
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/Personality and Random Numbers/personality_random_number_data.csv", na.strings="0", stringsAsFactors=TRUE)
View(d)
hist(d$E2)
hist(d$E2, main = "I don't talk a lot") #
hist(6-d$E2, main = "I [don't] don't talk a lot") # now extraversion
hist(d$E3)
hist(d$E4)
hist(d$E4)
hist(d$E5)
# STEP 1: ORGANIZING THE ITEMS INTO A DATA.FRAME ...
names(d)
d[,22:31]
names(d)[22:31]
extra.df <- d[,22:31] # using the codebook to index the 10 extraversion items
head(extra.df) # checking to make sure I did this correctly
## ...AND CHECKING THE ALPHA RELIABILITY
alpha(extra.df) # r is warning me that some are negatively keyed...
library(psych)
library(psych) # DLC...extra tools to install and load from a library
alpha(extra.df) # r is warning me that some are negatively keyed...
alpha(extra.df, check.keys = T) # seeing that some are negatively keyed...
## look at the codebook and confirm these are negatively keyed
extraPOS <- extra.df[,c(1,3,5,7,9)] # defining the positively keyed items
extraNEG <- extra.df[,c(2,4,6,8,10)] # defining the negatively keyed items
extraNEG <- 6-extraNEG # reverse scoring my negatively keyed items
extraCLEAN <- cbind(extraPOS, extraNEG)
head(extraCLEAN)
alpha(extraCLEAN) # high alpha; hooray.
head(extraCLEAN)
d$EXTRA <- rowMeans(extra.df,     # 10 items into one variable.
na.rm = TRUE) # still calculate if there’s missing data
d$EXTRA
d$EXTRA <- rowMeans(extraCLEAN,     # 10 items into one variable.
na.rm = TRUE) # still calculate if there’s missing data
d$EXTRA
hist(d$EXTRA)                     # What do you learn / observe?
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/Personality and Random Numbers/personality_random_number_data.csv", stringsAsFactors = T)
par(mfrow = c(2,5))
for(i in c(22:31)){
hist[d,i]
}
par(mfrow = c(2,5))
for(i in c(22:31)){
hist(d[,i])
}
paste(c("Histogram of E", i), sep = "")
paste("Histogram of E", i, sep = "")
par(mfrow = c(2,5))
for(i in c(22:31)){
hist(d[,i],
main = paste("Histogram of E", i, sep = ""))
}
par(mfrow = c(2,5))
for(i in c(22:31)){
hist(d[,i],
main = paste("Histogram of E", i-21, sep = ""))
}
par(mfrow = c(2,5))
for(i in c(22:31)){
hist(d[,i], xlab = "",
main = paste("Histogram of E", i-21, sep = ""))
}
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/Personality and Random Numbers/personality_random_number_data.csv", stringsAsFactors = T, na.strings = "0")
par(mfrow = c(2,5))
for(i in c(22:31)){
hist(d[,i], xlab = "",
main = paste("Histogram of E", i-21, sep = ""))
}
par(mfrow = c(2,5))
for(i in c(22:31)){
hist(d[,i], xlab = "", col = "black", bor = "white",
main = paste("Histogram of E", i-21, sep = ""))
}
library(psych) # DLC...extra tools to install and load from a library
extra.df <- d[,22:31] # using the codebook to index the 10 extraversion items
extraPOS <- extra.df[,c(1,3,5,7,9)] # defining the positively keyed items
extraNEG <- extra.df[,c(2,4,6,8,10)] # defining the negatively keyed items
extraNEG <- 6-extraNEG # reverse scoring my negatively keyed items
extraCLEAN <- cbind(extraPOS, extraNEG)
head(extraCLEAN)
alpha(extraCLEAN) # high alpha; hooray.
alpha(extra.df) # r is warning me that some are negatively keyed...
d$EXTRA <- rowMeans(extraCLEAN,     # 10 items into one variable.
na.rm = TRUE) # still calculate if there’s missing data
d$EXTRA
hist(d$EXTRA)                     # What do you learn / observe?
hist(d$EXTRA, main = "Extraversion Scale",
xlab = "Extraversion Scores",
col = "black", bor = "white")                     # What do you learn / observe?
par(mfrow = c(1,1))
hist(d$EXTRA, main = "Extraversion Scale",
xlab = "Extraversion Scores",
col = "black", bor = "white")                     # What do you learn / observe?
hist(d$EXTRA, main = "Extraversion : Likert Scale (alpha = .89)",
xlab = "Extraversion Scores",
col = "black", bor = "white")                     # What do you learn / observe?
d <- read.csv("~/Dropbox/!WHY STATS/Professor Datasets/Climate Psychology Collaboration/data_notimers.csv", stringsAsFactors = T)
names(d)
psych::alpha(reNARC.df) # psych comes before alpha() so R doesn't get confused and try to use the ggplot2 alpha() function, which is about colors.
psych::alpha(reNARC.df)[1:5]
n <- read.csv("~/Dropbox/!GRADSTATS/Datasets/Narcissism/data.csv", stringsAsFactors = T,
na.strings = 0) # removing zero values
head(n) # looks good
nrow(n) # seems right
n$elapse[n$elapse > 60*60*12] <- NA
hist(n$elapse)
summary(n$elapse)
sd(n$elapse, na.rm = T)
n$elapse[n$elapse < 45] # haven't removed them yet; just looking.
#| echo: true
#| output: false
n$elapse[n$elapse < 45 | n$elapse > 3600] # finding the outliers in the variable.
n[n$elapse < 45 | n$elapse > 3600, ] # finding the outliers in the dataset
# n[n$elapse < 45 | n$elapse > 3600, ] <- NA # I get an error message when I run this! Stupid missing values. Had to comment this out because Quarto wouldn't render an error message. SIGH.
n[c(n$elapse < 45 | n$elapse > 3600) & !is.na(n$elapse), ] # finding just the missing values.
## gotta reload the data cuz I've removed some missing values already to explore, and want a total count.
n <- read.csv("~/Dropbox/!GRADSTATS/Datasets/Narcissism/data.csv", stringsAsFactors = T,
na.strings = 0) #
toolong <- n[c(n$elapse < 45 | n$elapse > 3600) & !is.na(n$elapse), ]
nrow(toolong) # 81 folks will be removed.
n[c(n$elapse < 45 | n$elapse > 3600) & !is.na(n$elapse), ] <- NA # exclude missing values from my rule.
hist(n$elapse) # they gone.
par(mfrow = c(1,2))
hist(n$score,
col = 'black', bor = 'white',
xlab = "Narcissism Score (0 - 40)",
main = "Histogram of Narcissistic Personality Inventory")
hist(n$age,
col = 'black', bor = 'white',
xlab = "Age",
main = "Histogram of Age")
n$age[n$age < 18 | n$age > 100] # removing anyone under the age of 18, and over the age of 100
n[c(n$age < 18 | n$age > 100) & !is.na(n$age), ] <- NA # removing the missing data when filtering.
par(mfrow = c(1,2))
hist(n$score,
col = 'black', bor = 'white',
xlab = "Narcissism Score (0 - 40)",
main = "")
hist(n$age,
col = 'black', bor = 'white',
xlab = "Age",
main = "")
library(psych)
describe(n$score)
describe(n$age)
library(ggplot2)
library(ggthemes) # more pretty graphs
ggplot(n, aes(y = score, x = age)) +
geom_point(size = .85) +
geom_smooth(method = "lm") +
ggthemes::theme_tufte() + ylab("Narcissism Score") + xlab("Age")
mod <- lm(score ~ age, data = n)
coef(mod)
summary(mod)$r.squared
bucket <- array()
for(i in c(1:1000)){
n2 <- n[sample(1:nrow(n), nrow(n), replace = T), ] # new sample; based on the old sample
boot.mod <- lm(score ~ age, data = n2) # new model, based on the new sample.
bucket[i] <- coef(boot.mod)[2] # my slope, saved to bucket
}
sd(bucket)
coef(mod)[2] # slope from my original sample
coef(mod)[2] + 1.96*sd(bucket) # upper limit of 95% CI for slope
coef(mod)[2] - 1.96*sd(bucket) # lower limit
NARC.df <- n[,2:41]
head(NARC.df)
summary(NARC.df)[,1:4] # just looking at the first few variables.
ifONE <- c(1:3,6,8,11:14,16,21,24:25,27,29:31,33:34,36:39)
ifTWO <- setdiff(1:40, ifONE)
ifTWO # this looks right. eyes still glazing over.
head(cbind(NARC.df[ifTWO]-1, NARC.df[ifTWO])) # checking my confusing logic to see the changes that I made.
head(cbind(NARC.df[ifONE], 2-NARC.df[ifONE]))
reNARC.df <- data.frame(2-NARC.df[ifONE], NARC.df[ifTWO]-1) # combining my work into one data.frame
head(reNARC.df)
head(reNARC.df)[1:5]
head(reNARC.df)[]
head(reNARC.df)
head(reNARC.df)
psych::alpha(reNARC.df)[1:5] # psych comes before alpha() so R doesn't get confused and try to use the ggplot2 alpha() function, which is about colors.
psych::alpha(reNARC.df)[2]
psych::alpha(reNARC.df)[1:5,2]
psych::alpha(reNARC.df)[2] # psych comes before alpha() so R doesn't get confused and try to use the ggplot2 alpha() function, which is about colors.
psych::alpha(reNARC.df)[1]
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/World Happiness Report - 2024/World-happiness-report-2024.csv", stringsAsFactors = T)
names(d)
hist(d$Social.support)
max(d$Social.support)
max(d$Social.support, na.rm = T)
max(d$Social.support, na.rm = T) - mean(d$Social.support, na.rm = T)
max(d$Social.support, na.rm = T) - mean(d$Social.support, na.rm = T)/sd(d$Social.support, na.rm = T)
(max(d$Social.support, na.rm = T) - mean(d$Social.support, na.rm = T))/sd(d$Social.support, na.rm = T)
names(mini)
mini <- read.csv("../Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", stringsAsFactors = T, na.strings = "")
head(mini)
nrow(mini)
names(mini)
mini <- read.csv("../Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", stringsAsFactors = T, na.strings = "")
head(mini) # it loaded.
head(mini)
head(mini)[,1:5]
d <- read.csv("../Class Datasets/101 - Class Datasets - FA25/interruption_FA25.csv", stringsAsFactors = T)
head(d)[,1:4] # just looking at first four columns so as not to overwhelm this document
nrow(d)
names(d)
hist(mini$insta.followers) # hmm.... an outlier. I'll need to remove.
hist(mini$insta.followers)
mini <- read.csv("../Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", stringsAsFactors = T)
head(mini)[,1:5] # it loaded. Just looking at the first four columns so as not to overwhelm this document.
hist(mini$insta.followers) # hmm.... an outlier. I'll need to remove.
mini$insta.followers[mini$insta.followers > 5000] # a more general rule?
mini$insta.followers[mini$insta.followers > 5000] # a more general rule?
mini$insta.followers[mini$insta.followers > 5000] <- NA
mean(mini$insta.followers, na.rm = T)
median(mini$insta.followers, na.rm = T)
sd(mini$insta.followers, na.rm = T)
range(mini$insta.followers, na.rm = T)
hist(mini$insta.followers) # looks better
mean(mini$insta.followers, na.rm = T)
median(mini$insta.followers, na.rm = T)
sd(mini$insta.followers, na.rm = T)
range(mini$insta.followers, na.rm = T)
hist(mini$insta.followers, col = 'black', bor = 'white',
main = "Histogram of Insta Followers",
xlab = "Number of Followers on Instagram (Self-Reported)")
abline(v = mean(mini$insta.followers, na.rm = T), col = 'red', lwd = 5)
abline(v = median(mini$insta.followers, na.rm = T), col = 'blue', lwd = 5)
abline(v = mean(mini$insta.followers, na.rm = T) +
sd(mini$insta.followers, na.rm = T), col = 'red', lty = 2)
hist(mini$insta.followers, col = 'black', bor = 'white',
main = "Histogram of Insta Followers",
xlab = "Number of Followers on Instagram (Self-Reported)")
abline(v = mean(mini$insta.followers, na.rm = T), col = 'red', lwd = 5)
abline(v = median(mini$insta.followers, na.rm = T), col = 'blue', lwd = 5)
abline(v = mean(mini$insta.followers, na.rm = T) +
sd(mini$insta.followers, na.rm = T), col = 'red', lty = 2)
abline(v = mean(mini$insta.followers, na.rm = T) -
sd(mini$insta.followers, na.rm = T), col = 'red', lty = 2)
hist(d$Social.support)
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/World Happiness Report - 2024/World-happiness-report-2024.csv", stringsAsFactors = T)
names(d)
hist(d$Social.support)
names(d)
d$upperwhisker - d$lowerwhisker
hist(d$upperwhisker - d$lowerwhisker)
min(d$upperwhisker - d$lowerwhisker)
mod <- lm(Ladder.score ~ Social.support, data = d)
plot(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5, col = 'yellow')
d[min(d$upperwhisker - d$lowerwhisker), d$Country.name]
d$upperwhisker - d$lowerwhisker)
d[min(d$upperwhisker - d$lowerwhisker, d$Country.name]
d[min((d$upperwhisker - d$lowerwhisker), d$Country.name]
d$whiskerdiff <- d$upperwhisker - d$lowerwhisker
d[d$whiskerdiff == min(d$whiskerdiff), d$Country.name]
d$whiskerdiff == min(d$whiskerdiff)
d[(d$whiskerdiff == min(d$whiskerdiff)), d$Country.name]
d[(d$whiskerdiff == min(d$whiskerdiff))]
d$whiskerdiff == min(d$whiskerdiff)
d[d$whiskerdiff == min(d$whiskerdiff)]
d[d$whiskerdiff == min(d$whiskerdiff),]
d[d$whiskerdiff == max(d$whiskerdiff),]
names(d)
d[d$whiskerdiff,1]
d[sort(d$whiskerdiff),1]
sort(d$whiskerdiff)
d[d$wiskerdiff == sort(d$whiskerdiff),1]
d$wiskerdiff == sort(d$whiskerdiff)
d$whiskerdiff == sort(d$whiskerdiff)
d[c(d$whiskerdiff == sort(d$whiskerdiff)),1]
d[order(d$whiskerdiff), 1]
order(d$whiskerdiff)
d$whiskerdiff
d$upperwhisker
d$lowerwhisker
d$upperwhisker - d$lowerwhisker
nrow(d)
mod <- lm(Ladder.score ~ Social.support, data = d)
coef(mod)
coef(mod)[1] + coef(mod)[2]*1
coef(mod)[1] + coef(mod)[2]*.25
plot(d$Ladder.score, main = "Mean of Y as Source of Predictions")
abline(h = mean(d$Ladder.score), lwd = 5)
plot(d$Ladder.score ~ d$Social.support,
main = "Mean of Y as Source of Predictions",
ylab = "Happiness Scores")
abline(h = mean(d$Ladder.score), lwd = 5)
par(mfrow = c(1,2))
plot(d$Ladder.score,
main = "Mean of Y as Source of Predictions",
ylab = "Happiness Scores")
abline(h = mean(d$Ladder.score), lwd = 5)
plot(d$Ladder.score ~ d$Social.support,
main = "Mean of Y as Source of Predictions",
ylab = "Happiness Scores")
mod <- lm(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5, col = 'yellow')
plot(d$Ladder.score,
main = "Predicting Happiness from Mean",
ylab = "Happiness Scores")
abline(h = mean(d$Ladder.score), lwd = 5)
plot(d$Ladder.score ~ d$Social.support,
main = "Predicting Happiness form Social Support",
ylab = "Happiness Scores",
xlab = "Social Support Score")
par(mfrow = c(1,2))
plot(d$Ladder.score,
main = "Predicting Happiness from Mean",
ylab = "Happiness Scores")
abline(h = mean(d$Ladder.score), lwd = 5)
plot(d$Ladder.score ~ d$Social.support,
main = "Predicting Happiness form Social Support",
ylab = "Happiness Scores",
xlab = "Social Support Score")
mod <- lm(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5, col = 'yellow')
d[sample(d, nrow(d)), ]
d[sample(1:nrow(d), nrow(d)), ]
d[sample(1:nrow(d), nrow(d)), ]
d[sample(1:nrow(d), nrow(d)), ]
d[sample(1:nrow(d), nrow(d)), ]
plot(d[sample(1:nrow(d), nrow(d)), ]$Ladder.score,
main = "Predicting Happiness from Mean",
ylab = "Happiness Scores")
abline(h = mean(d$Ladder.score), lwd = 5)
d[sample(1:nrow(d), nrow(d)), ]
plot(d[sample(1:nrow(d), nrow(d)), ]$Ladder.score,
main = "Predicting Happiness from Mean",
ylab = "Happiness Scores")
abline(h = mean(d$Ladder.score), lwd = 5)
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/World Happiness Report - 2024/World-happiness-report-2024.csv", stringsAsFactors = T)
par(mfrow = c(1,2))
plot(d[sample(1:nrow(d), nrow(d)), ]$Ladder.score,
main = "Predicting Happiness from Mean",
ylab = "Happiness Scores")
abline(h = mean(d$Ladder.score), lwd = 5)
plot(d$Ladder.score ~ d$Social.support,
main = "Predicting Happiness form Social Support",
ylab = "Happiness Scores",
xlab = "Social Support Score")
mod <- lm(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5, col = 'yellow')
par(mfrow = c(1,2))
plot(d[sample(1:nrow(d), nrow(d)), ]$Ladder.score,
main = "Predicting Happiness \nfrom theMean",
ylab = "Happiness Scores")
abline(h = mean(d$Ladder.score), lwd = 5)
plot(d$Ladder.score ~ d$Social.support,
main = "Predicting Happiness \nfrom Social Support",
ylab = "Happiness Scores",
xlab = "Social Support Score")
par(mfrow = c(1,2))
plot(d$Ladder.score ~ d$Social.support,
main = "Predicting Happiness \nfrom Social Support",
ylab = "Happiness Scores",
xlab = "Social Support Score")
mod <- lm(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5, col = 'yellow')
plot(scale(d$Ladder.score) ~ scale(d$Social.support),
main = "Predicting Happiness \nfrom Social Support",
ylab = "Happiness Scores (Z-Scores)",
xlab = "Social Support Score(Z-Scores)")
modZ <- lm(scale(Ladder.score) ~ scale(Social.support), data = d)
abline(modZ, lwd = 5, col = 'gold')
table(coef(mod), coef(modZ))
cbind(coef(mod), coef(modZ))
cbind("Raw Scores" = coef(mod), "Z Scores" = coef(modZ))
par(mfrow = c(2,2))
plot(mod)
par(mfrow = c(1,1))
hist(mod$residuals)
plot(scale(d$Ladder.score) ~ scale(d$Social.support),
main = "Predicting Happiness \nfrom Social Support",
ylab = "Happiness Scores (Z-Scores)",
xlab = "Social Support Score(Z-Scores)")
modZ <- lm(scale(Ladder.score) ~ scale(Social.support), data = d)
abline(modZ, lwd = 5, col = 'gold')
plot(d$Ladder.score ~ d$Social.support,
main = "Predicting Happiness \nfrom Social Support",
ylab = "Happiness Scores",
xlab = "Social Support Score")
mod <- lm(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5, col = 'yellow')
coef(mod)
summary(mod)$r.squared
hist(d$Social.support)
## "By Hand"
mean.resid <- d$Ladder.score - mean(d$Ladder.score)
SST <- sum(mean.resid^2)
SSE <- sum(mod$residuals^2)
SST - SSE
(SST - SSE) / SST
## VIDEO 1 : Loading and Navigating a Dataset
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/World-happiness-report-2024.csv", stringsAsFactors = T)
names(d)
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", stringsAsFactors = T)
head(d) # checking my data.
nrow(d)
names(d)
d$stoned72
hap.df <- with(d, data.frame(satlife, selfes, is.happy))
alpha(hap.df)
psych::alpha(hap.df)
hap.df
psych::alpha(hap.df)
hap.df <- with(d, data.frame(satlife, selfes, is.happy, 6-bored))
psych::alpha(hap.df)
dd <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_codebook.csv")
head(dd)
dd
dd
dd
dd
dd[c(7,10, 20, 31, 33),]
dd[c(7,10, 20, 31, 33),]
dd[c(7,10, 20, 31, 33),]
1+1
nrow(d)
summary(d$stoned72)
alpha(hap.df)
psych::alpha(hap.df)
range(hap.df)
range(hap.df, na.rm = T)
hap.df <- with(d, data.frame(satlife, selfes, is.happy, 10-bored))
range(hap.df, na.rm = T)
psych::alpha(hap.df)
d$HAPP <- rowMeans(hap.df, na.rm = T)
hist(d$HAPP)
summary(d$HPP)
summary(d$HAPP)
plot(d$insta.follows, main = "Insta Follows in "Raw" Units")
plot(d$insta.follows, main = "Insta Follows in 'Raw' Units")
plot(scale(d$insta.follows), main = "Insta Follows in 'Z-Score' Units")
par(mfrow = c(1,2))
plot(d$insta.follows, main = "Insta Follows in 'Raw' Units")
plot(scale(d$insta.follows), main = "Insta Follows in 'Z-Score' Units")
