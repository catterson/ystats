# Why Research Methods?

In this chapter, you'll learn how psychologists (and scientists) construct and share their knowledge.

# Part 1. The "Normal" Distribution.

## Definition.

The “Normal” (or Gaussian) distribution is a common shape for what distributions of data look like. The shape is often called a “bell curve”, because it looks like the curve of a bell.

While many distributions appear normal, the “Normal Distribution” ™ refers to a distribution that describes an expected probability of a range of scores.

![](images/3_NormalDistributionAnnotated.png){fig-align="center"}

The Normal Distribution is called "normal" because researchers expect to see this type of distribution for variables where two conditions are met:

1.  **There are multiple explanations for why the variation occurs**. This happens very frequently across all science, since life is complex and there are many reasons why individuals differ.
2.  **These multiple explanations occur randomly**. This means that the multiple explanations for variation are mostly independent of one another, and there is not some shared experience among individuals that is influencing their variation.

### Example : Thinking About Distributions

For example, let’s look at one example "normal" distributions - the "self-esteem" variable we saw in Lecture 2. Note that it's not perfectly normal[^3r_description-4], but it's pretty close and representative of the kind of "real world" data that you might encounter.

[^3r_description-4]: good not to hold data to unrealistic body images as well as people.

```{r}
#| include: false
d <- read.csv("../datasets/Self-Esteem Dataset/data.csv", stringsAsFactors = T, na.strings = "0", sep = "\t")
SELFES.df <- data.frame(d[,c(1:2,4,6,7)], 5-d[,c(3,5,8:10)])
d$SELFES <- rowMeans(SELFES.df, na.rm = T)
```

```{r}
hist(d$SELFES, col = 'black', bor = 'white', 
     main = "Histogram of Self-Esteem", 
     xlab = "Self-Esteem Score", breaks = 15)
```

**"Random" explanations for why variation in self-esteem occurs.** Self-esteem is complex, and can be influenced by variables such as: genetics, parental environment, home environment, income, neurotransmitters, whether your crush told you they like you too the day you took the self-esteem survey, etc. These variables are considered random because one does not influence the other, and they differ across participants in the study. That is, someone who had a happy parental environment may not necessarily have a high income. 

**"Non-Random" Explanations.** Careful observers will note that self-esteem appears slightly shifted above the mid-point of the scale (which goes from 1-4, so 2.5 would be the mid-point), and that there's some slight negative skew (meaning more individuals are on the higher end of the distribution). This shift is likely the result of some shared cultural experiences among participants - our society values self-esteem, and people might be biased to self-enhance / self-present a higher self-esteem. This is a non-random influence, since many participants might experience this.

### Example 2 : Thinking About Distributions

Below is another example of a distribution - this one is not random, but is skewed (pop quiz : is it positively or negatively skewed? See here for answer[^3r_description-5].)

[^3r_description-5]: It is negatively skewed, since the tail is on the negative side of the distribution.

![](images/3_RGrades.png){fig-align="center"}

::: {.callout-tip collapse="true"}
#### "Random" Reasons for Variation

Lots of things can influence a student’s score on an exam, such as how much students were motivated to study, how much time they had to study, what was going on in their lives, whether they had a study buddy in the class, whether they were sick or not on the day of the exam, their “test taking” skills and strategies and anxiety levels, etc.
:::

::: {.callout-tip collapse="true"}
#### "Non-Random" Reasons for Variation.

These data are not normally distributed because the students were all part of the same college, in the same classroom, taught by the same professor, at the same time. The professor did his best to prepare these students, and wrote a test that would be based on the kinds of practice they had gone over in lecture. These variables are considered “non random” because they were shared by all students. The data are skewed because these non-random shared experiences helped students do well on the exam.
:::

#### 

::: callout-warning
#### Culture in Statistics : The Normal Curve

+-------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| ![](/images/doff_intro_mickey.png){width="3in"} | That's right folks, it's time for another chat with your friend Open-Source Mickey Mouse! This time, we're gonna chat about the idea that people differ from some average. The idea that you could quantify people as "average" is fairly new - it's hard to pinpoint exactly, but a scientist named Quetelet first extended the statistical methods derived from astronomy to be applied to humans in the 1860s[^3r_description-6]. Quetelet thought the average was an ideal state since it reflected the center of all possible individuals. However, a few years later Francis Galton used Quetelet's ideas to try and "rank" individuals according to some hierarchy of excellence. For Galton, the average was not an ideal state, but rather something to overcome in a desire for greater and greater excellence. Galton was also a racist and father of the eugenics movement, who used distorted statistics as a tool to justify his own pre-existing racist beliefs that white people were superior to everyone else. |
+-------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

But you don't have to take it from me! Here's Galton in his own words :

*To conclude, the range of mental power between—I will not say the highest Caucasian and the lowest savage—but between the greatest and least of English intellects, is enormous. ... I propose in this chapter to range men according to their natural abilities, putting them into classes separated by equal degrees of merit, and to show the relative number of individuals included in the several classes.....The method I shall employ for discovering all this, is an application of the very curious theoretical law of “deviation from an average.” First, I will explain the law, and then I will show that the production of natural intellectual gifts comes justly within its scope. -* Galton, Hereditary Genius (1869). [Linked here](https://galton.org/books/hereditary-genius/text/v5/galton-1869-hereditary-genius-v5.htm).
:::

[^3r_description-6]: see Rose's END OF AVERAGE (2016) or, for a more critical approach, Chapman's (2023) EMPIRE OF NORMALITY.

The point of bringing up some of the racist origins of statistics is two-fold :

1.  Many people like to argue that "good" statistics is objective, and that scientists are free of bias. So it's important to acknowledge that the inventors of many statistics that we use had clear biases and did not behave objectively. Rather than try to be free of bias, I think it's important to acknowledge where and when people are biased, and address those biases up explicitly.
2.  Statistics is a tool, and that tool can be used poorly and dangerously in ways that can cause a lot of pain. Just because something has numbers doens't mean it's correct. For example, Galton's work showing "statistically" that white people were superior in ability to other groups didn't account for other factors like socioeconomic status. And for what it's worth, modern scientists overwhelmingly agree that "race" is a social construct. There are genetic differences that explain different skin tones, however there is more genetic variation in skin tone within a similar “race” than between different “races”. [Read more about this here.](https://www.smithsonianmag.com/smart-news/genetic-study-shows-skin-color-just-skin-deep-180965261/)

Alright, that's all for now! Let me know what you think and see you next time!

## Why This Matters.

The normal distribution is foundational to the statistics we will learn in this class. (And in an advanced statistics class, you'll learn how to adapt techniques if you want to understand non-normal distributions.)

This does not mean that every variable needs to be normally distributed; we'll work with skewed variables and categorical variables (which have their own distributions) in lots of ways. However, the "normal distribution" is an important reference point that we can use to evaluate variables. For example, exam scores are *negatively skewed* because they differ from the normal distribution.

# Part 2. Good Data

Scientists evaluate the quality of their measures in terms of **validity** (“truth” or accuracy) and **reliability** (repeatability or precision). Learn more about these two concepts - and their specific forms - in the two videos below.

## Specific Forms of Validity

-   **Face Validity:** asks us to evaluate whether our measure or result look like what it should look like. This is a superficial (and somewhat subjective) judgment. But it is often a powerful and quick way to assess. For example, if I measure my height and it tells me 100 feet, I know something is wrong because there is no way I'm that tall. Or, when looking at a self-esteem measure, I would want to see items that look like self-esteem questions ("I feel good about myself".) If the self-esteem measure had other questions in it that didn't really seem like they were measuring self-esteem ("I like to look at myself in the mirror") I would have questions about the face-validity of the measure. This seems super obvious, but it's an important check - do the measures used actually look like what they should?

-   **Convergent validity:** asks us to evaluate whether our measure similar to related concepts. When two things converge, they come together, and we want our measure to be similar to things that it should be similar to. For example, a measure of body height should be related to a measure of shoe size or tibia length. A measure of self-esteem should be similar to a measure of self-efficacy or satisfaction with life, since both are about how the person is subjectively seeing themselves. They shouldn't be exactly the same thing, but we'd expect to see a pattern in the data. (We'll talk more about how to quantify these patterns when we learn more about linear models.)

-   **Discriminant validity:** asks about whether our measure is different from unrelated concepts. When two things diverge, they are different from one another. And we WANT our measure to be different from things that we expect them to be different from. For example, a measure of height should be different from a measure of reading speed or how organized a person is. We would expect self-esteem to be different from how social a person is (though maybe there's some relationship since our society values sociability, and people who are social might get more positive messages from others, bolstering their self-esteem.) This is the hardest concept for students to get, but it's a really important test of the validity of a measure. I not only want my measure to be related to concepts it should be related to, but also different from concepts it should be different from.

## Reliability

-   **Test-retest reliability:** asks us to evaluate whether we get the same result if we take multiple measures separated by time. If I think of self-esteem as a stable trait, I should expect to see some similarity in a person's self-esteem at one time point and then the next day. Of course, there will be some change - self-esteem (and other personality variables) can be influenced by the situation and environment. But they shouldn't be radically different if we have a good measure of this core aspect of the self.

-   **Inter-rater / Inter-judge reliability:** asks us to evalute whether multiple observers (or tools) make similar measurements. If I have two rulers made by the same company, I would expect them to give me similar answers for how tall I am. Similarly, two different observers who are reliable should make similar jugments about a person's self-esteem, or the number of interruptions they count. If our measure is not reliable, then we might get different answers from the different people (or tools) making the measurement.

-   **Inter-item reliability:** When we learned about likert scales, we learned about Cronbach's Alpha - a method of assessing how much the different items in a likert scale were related to each other. This is a form of reliability - specific only to likert scales where we have different questions that are all measuring the same thing. If the scale is reliable, we expect to get similar answers across the different items. For example, someone who says "I feel good about myself" should also say "I feel that I have a number of good qualities."

## Example : Validity and Reliability

Think about a scale. How would you evaluate the validity (face, convergent, discriminant) and reliability (test-retest / interjudge) of a bathroom scale? Think about this on your own, then look over the video key / guide below.

::: {.callout-tip collapse="true"}
## Expand To See Answers

Watch the video below to go over some possible answers, or just look over the table.

{{< video https://youtu.be/T9dTk6Sa434 >}}

+---------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
| **face :** does our measure or result look like what it should look like?             | **high :** I have a sense of what my weight should be (e.g, if it says 10 or 1000 i know either the units are wrong or scale is broken.)    |
+---------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
| **convergent :** is our measure similar to related concepts?                          | **high :** my weight according to the scale is (somewhat) related to how much I stress eat, how little I exercise, my parents’ weight, etc. |
+---------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
| **discriminant :** is our measure different from unrelated concepts?                  | **high :** my weight is unrelated to intelligence, how much I love R, whether I wear sandals with or without socks, etc.                    |
+---------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
| **test-retest :** do we get the same result if we take multiple measures?             | **high :** If I step on the scale and get a number, I should be able to step off the scale, step on again, and get the same number.         |
+---------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
| **interrater reliability :** would another observer make the same measurements?       | **high :** a different scale (same model and technology) should give me the same result as my scale.                                        |
+---------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
| **inter-item reliability :** would one item in the likert scale be related to others? | **not relevant.** a bathroom scale is not a likert scale.                                                                                   |
+---------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+
:::

## Bad Data : Phrenology in terms of Validity and Reliability

Watch the video below to review these terms, in the context of phrenology - an example of scientific racism.

![](images/5_PhrenologyHead.png){alt="38322-004-6FE24489.jpg" fig-align="center" width="222"}

{{< video https://youtu.be/DoLK72ueYs8 >}}

Phrenology is no longer considered a valid or reliable science, yet its presence still lingers in psychology, and is often taught as history without reference to its racist origins and consequences[^5r_goodscience-4]. And as we have (and will continue to discuss) there are still many ways in which racism (and sexism, classism, and ableism) occur and affect psychology (and other sciences too).

[^5r_goodscience-4]: For examples, in the common Intro Psych textbook written by Myers & DeWall (2018)

For example, more modern intelligence testing is often criticized for prioritizing White European values and language in the way it assesses supposedly “objective” knowledge. In an important test of this claim, the psychologist Robert Williams (pictured to the right) designed an IQ test that was as **reliable** as the default IQ test, but was “biased” to prioritize and value Black culture.

![](images/5_IQtest.png){fig-align="center"}

::: column-margin
As seen in the table, Black students scored higher on this IQ test than White students - a point he (and others) use to emphasize the inherent biases in intelligence testing. Dr. Williams also came to define the concept of Ebonics, and demonstrate that African American English is as much a complete language as “Standard” English. 

![](images/5_Williams.png){fig-align="center"}
:::

## [**Check-In : Reliability and Validity**](https://docs.google.com/forms/d/e/1FAIpQLSf7fmDMX_o3kOqPblXT_WSnu-6hQRJfX2VEqyQsMSjdSrURBw/viewform?usp=sf_link)**.**

Test your understanding of reliability and validity with the check-in above.

Below is a video to review the check-in answers, since these terms can be tricky :)

{{< video https://youtu.be/95W3DKRGR24 >}}

## Would You Like to Learn More? \[Optional Readings\]

-   **Here’s a [textbook chapter on the same topics](https://kpu.pressbooks.pub/psychmethods4e/chapter/reliability-and-validity-of-measurement/).** Note these authors use three terms to describe what I broadly call “convergent validity”. Internal consistency (a form of reliability) is measured with “alpha reliability” (we will learn about this next week).

-   **Dr. Williams [talks about his research here](https://www.youtube.com/watch?v=SAqHmKIXZBE)** and here’s an episode of the [TV show Good Times](http://dailymotion.com/video/x6fmo36) that Dr. Williams consulted on. Here’s a [link to his full study](https://files.eric.ed.gov/fulltext/ED070799.pdf). Note that Dr. Williams gave his intelligence test a name I don’t feel comfortable using because it is sexist :(. Times change, and it’s good to call out outdated language and update our terms accordingly :)

-   **Learn more about the [racist history of how phrenology was produced and consumed](https://www.theguardian.com/science/blog/2013/feb/05/django-unchained-racist-science-phrenology)** and an article that conducted [more recent research](http://theconversation.com/neuroscientists-put-the-dubious-theory-of-phrenology-through-rigorous-testing-for-the-first-time-88291)to test phrenology’s theories.



# TLDR.

Science on people is hard.
